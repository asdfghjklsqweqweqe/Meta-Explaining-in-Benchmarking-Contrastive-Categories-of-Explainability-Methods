{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKAyMKB9COMHK4kF46rnDg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## ***Adaptations on the Explanations of Instance-based Methods***\n","\n","\n","> Moduled: Accpeting the four GNNs (GCN+GAP, DGCNN, DIFFPOOL, and GIN)\n","\n","\n","---"],"metadata":{"id":"qDhRH6euQ2Xt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"a93oGadc6pdi"},"outputs":[],"source":["\"\"\"\n","The algorithm:\n","Profile each edge's existance in all explanations by source and target node features.\n","Given a threshold, return saliency maps for each class by those of edges which satisfy the thresholding on frequency of appearance\n","on explanations of the target class.\n","\n","This algorithms relaxes instance-specific explanations by ignoring the substructures in the explanations which are not frequently\n","happening on all instances of the entire class.\n","\"\"\"\n"]},{"cell_type":"code","source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install git+https://github.com/rusty1s/pytorch_geometric.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvdNNg5aVT7k","executionInfo":{"status":"ok","timestamp":1715066959761,"user_tz":-120,"elapsed":70096,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"865c510d-060f-4d67-8027-2231ea643747"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.1+cu121\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting git+https://github.com/rusty1s/pytorch_geometric.git\n","  Cloning https://github.com/rusty1s/pytorch_geometric.git to /tmp/pip-req-build-2ljov0g7\n","  Running command git clone --filter=blob:none --quiet https://github.com/rusty1s/pytorch_geometric.git /tmp/pip-req-build-2ljov0g7\n","  Resolved https://github.com/rusty1s/pytorch_geometric.git to commit 61c47ee404f8e26b3a1cd0db56448b6254920d0e\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (3.9.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (3.1.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (1.25.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (2.31.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (1.11.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.6.0) (4.66.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.6.0) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.6.0) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.6.0) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.6.0) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.6.0) (3.5.0)\n"]}]},{"cell_type":"code","source":["import argparse\n","import os\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from math import sqrt\n","import math\n","from torch_geometric.datasets import TUDataset\n","import torch as th\n","import torch\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.nn.parameter import Parameter\n","from torch_geometric.nn import GCNConv\n","import torch.nn.functional as F\n","from torch.nn import Linear, LayerNorm\n","from sklearn import metrics\n","from scipy.spatial.distance import hamming\n","import statistics\n","import pandas\n","from time import perf_counter\n","from IPython.core.display import deepcopy\n","from torch_geometric.nn import MessagePassing\n","import copy\n","from torch.nn import ReLU, Sequential\n","from torch import sigmoid\n","from itertools import chain\n","from time import perf_counter\n","from torch_geometric.data import Data, Batch, Dataset\n","from functools import partial\n","from torch_geometric.utils import to_networkx\n","from torch_geometric.utils import remove_self_loops\n","from typing import Callable, Union, Optional\n","#from torch_geometric.utils.num_nodes import maybe_num_nodes\n","import networkx as nx\n","from typing import List, Tuple, Dict\n","from collections import Counter\n","import statistics\n","import tqdm\n","import csv\n","from statistics import mean\n","from torch_geometric.utils import from_scipy_sparse_matrix\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.loader import DataLoader\n","import torch_geometric.nn as gnn"],"metadata":{"id":"qqSrzNklVWfw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOBB7gUddqf9","executionInfo":{"status":"ok","timestamp":1715066995925,"user_tz":-120,"elapsed":26529,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"5730735a-e6df-4297-ca81-26878e4dd549"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["mutag_dataset = TUDataset(root='data/TUDataset', name='MUTAG')"],"metadata":{"id":"gW7dh3z8VZXz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715066997489,"user_tz":-120,"elapsed":1569,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"e36d621f-8c88-4ed8-c557-9eeb2f1542b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n","Processing...\n","Done!\n"]}]},{"cell_type":"code","source":["Explainability_name = 'TopDown Approach'\n","Task_name = 'Graph Classification'\n","checkpoint_directory_Classifier = \"/content/drive/My Drive/Explainability Methods/\" + str(Explainability_name) + \" on \" + str(Task_name) + \"/Model/model_classifier.pt\"\n","classifier_lr = 0.001\n","classifier_dropout = 0.1\n","classifier_weight_decay = 1e-6\n","classifier_bias = True\n","DataSet_name = \"MUTAG\"\n","\n","#File_Name = Model_name + \" \" + Explainability_name + \" \" + Task_name + \" \" + DataSet_name + \" \""],"metadata":{"id":"8HXVCFpzVcdR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train_dataset, test_dataset = train_test_split(dataset, test_size=0.3, random_state=0, shuffle=True)\n","#print(\"Number of Training Graphs: \", len(train_dataset))\n","#print(\"Number of Test Graphs: \", len(test_dataset))\n","\n","df = pandas.read_csv(\"/content/drive/My Drive/Explainability Methods/Train and Test Indexes on Graph Classification/Experimental Results/train_test_indexes.csv\")\n","\n","read_training_list_indexes__ = df['Train Indexes']\n","read_test_list_indexes__ = df['Test Indexes']\n","read_test_list_indexes__ = read_test_list_indexes__.dropna()\n","read_test_list_indexes = []\n","read_training_list_indexes = []\n","for element in read_test_list_indexes__:\n","    read_test_list_indexes.append(int(element))\n","for element in read_training_list_indexes__:\n","    read_training_list_indexes.append(int(element))\n","\n","\n","print(read_training_list_indexes)\n","print(read_test_list_indexes)\n","\n","mutag_train_dataset = []\n","mutag_test_dataset = []\n","for index in read_training_list_indexes:\n","    mutag_train_dataset.append(mutag_dataset[index])\n","for index in read_test_list_indexes:\n","    mutag_test_dataset.append(mutag_dataset[index])\n","\n","\n","print(f'Number of training graphs: {len(mutag_train_dataset)}')\n","print(f'Number of test graphs: {len(mutag_test_dataset)}')"],"metadata":{"id":"ML3Kro7yVg-Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715067004598,"user_tz":-120,"elapsed":1037,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"cc6beb43-9d71-477a-9858-0f50958ba090"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[51, 142, 143, 10, 4, 141, 125, 23, 3, 79, 28, 117, 136, 156, 83, 128, 109, 70, 31, 58, 7, 148, 14, 187, 20, 162, 123, 13, 91, 185, 169, 102, 32, 55, 119, 25, 161, 175, 52, 121, 152, 108, 113, 65, 39, 103, 131, 42, 166, 110, 160, 68, 90, 89, 64, 172, 159, 72, 170, 18, 122, 29, 179, 49, 171, 178, 9, 74, 96, 48, 181, 127, 126, 87, 12, 163, 88, 53, 94, 146, 5, 158, 16, 67, 6, 59, 164, 151, 34, 47, 54, 46, 100, 112, 93, 182, 66, 106, 124, 19, 186, 133, 45, 15, 40, 167, 174, 98, 105, 153, 61, 63, 132, 116, 43, 80, 33, 147, 165, 69, 135, 86, 76, 57, 173, 115, 138, 140, 134, 180, 95, 22, 38, 41, 24, 120, 145, 26, 21, 50, 176, 107, 78, 17, 85, 154, 60, 92, 184, 129]\n","[0, 1, 2, 8, 11, 27, 30, 35, 36, 37, 44, 56, 62, 71, 73, 75, 77, 81, 82, 84, 97, 99, 101, 104, 111, 114, 118, 130, 137, 139, 144, 149, 150, 155, 157, 168, 177, 183]\n","Number of training graphs: 150\n","Number of test graphs: 38\n"]}]},{"cell_type":"code","source":["class profile_frequencies:\n","    def __init__(self, list_of_saliencies, test_dataset, style):\n","        self.list_of_saliencies = list_of_saliencies\n","        self.edges_profile_by_node_feats = {}\n","        self.edges_profile_by_node_feats_2_proportions = {}\n","        self.test_dataset = test_dataset\n","        self.style = style\n","\n","\n","        self.profile_edges_for_each_explanation()\n","        self.get_proportions()\n","\n","        # for key, value in self.edges_profile_by_node_feats_2_proportions.items():\n","        #     print(\"Key: \", key, \"      \", value)\n","\n","    def profile_edges_for_each_explanation(self):\n","        for expl, graph in zip(self.list_of_saliencies, self.test_dataset):\n","            graph_edges = [(source_index, target_index) for source_index, target_index in graph.edge_index.T.tolist()]\n","            if self.style == \"Edge\":\n","                self.get_paired_features_as_keys_by_edge_saleincy(expl, graph_edges, graph.x)\n","            elif self.style == \"Node\":\n","                self.get_paired_features_as_keys_by_node_saleincy(expl, graph_edges, graph.x)\n","\n","    def get_paired_features_as_keys_by_edge_saleincy(self, expl, edges, node_feats):\n","        for edge_sal, (source_index, target_index) in zip(expl, edges):\n","            if edge_sal == 1:\n","                edge_key = tuple([tuple(node_feats[source_index].tolist()), tuple(node_feats[target_index].tolist())])\n","                if edge_key in self.edges_profile_by_node_feats.keys():\n","                    self.edges_profile_by_node_feats[edge_key] = self.edges_profile_by_node_feats[edge_key] + 1\n","                else:\n","                    self.edges_profile_by_node_feats[edge_key] = 1\n","\n","    def get_paired_features_as_keys_by_node_saleincy(self, expl, edges, node_feats):\n","        for (source_index, target_index) in edges:\n","            if (expl[source_index] == 1) and (expl[target_index] == 1):\n","                edge_key = tuple([tuple(node_feats[source_index].tolist()), tuple(node_feats[target_index].tolist())])\n","                if edge_key in self.edges_profile_by_node_feats.keys():\n","                    self.edges_profile_by_node_feats[edge_key] = self.edges_profile_by_node_feats[edge_key] + 1\n","                else:\n","                    self.edges_profile_by_node_feats[edge_key] = 1\n","\n","    def get_proportions(self):\n","        sum_value = sum(self.edges_profile_by_node_feats.values())\n","        for key, value in self.edges_profile_by_node_feats.items():\n","            self.edges_profile_by_node_feats_2_proportions[key] = value/sum_value\n","\n","\n","    def profile_the_upcoming_explanation(self, an_explanation, a_graph):\n","        profile = []\n","        if self.style == \"Edge\":\n","            graph_edges = [(source_index, target_index) for source_index, target_index in a_graph.edge_index.T.tolist()]\n","            for sal_score, (source_index, target_index) in zip(an_explanation, graph_edges):\n","                edge_key = tuple([tuple(a_graph.x[source_index].tolist()), tuple(a_graph.x[target_index].tolist())])\n","                if sal_score == 1:\n","                    profile.append(self.edges_profile_by_node_feats_2_proportions[edge_key])\n","                else:\n","                    profile.append(0)\n","            return profile\n","\n","        elif self.style == \"Node\":\n","            graph_edges = [(source_index, target_index) for source_index, target_index in a_graph.edge_index.T.tolist()]\n","            for (source_index, target_index) in graph_edges:\n","                edge_key = tuple([tuple(a_graph.x[source_index].tolist()), tuple(a_graph.x[target_index].tolist())])\n","                if (an_explanation[source_index] == 1) and (an_explanation[target_index] == 1):\n","                    profile.append(self.edges_profile_by_node_feats_2_proportions[edge_key])\n","                else:\n","                    profile.append(0)\n","            return profile\n","\n","    def __call__(self, an_explanation, a_graph, threshold):\n","\n","        profile = self.profile_the_upcoming_explanation(an_explanation, a_graph)\n","        profile_one_hot = [1 if value > threshold else 0 for value in profile]\n","        return profile_one_hot\n","\n","\n","edge_explanations = []\n","node_explanations = []\n","number_of_graphs = 10\n","for i in range(number_of_graphs):\n","    edge_explanations.extend(torch.randint(2, (1, mutag_test_dataset[i].edge_index[0].size()[0])).tolist())\n","    node_explanations.extend(torch.randint(2, (1, mutag_test_dataset[i].x.size()[0])).tolist())\n","\n","print(\"edge_explanations: \", edge_explanations)\n","print(\"node_explanations: \", node_explanations)\n","\n","common_edges_finder = profile_frequencies(list_of_saliencies=edge_explanations, test_dataset=mutag_test_dataset[:number_of_graphs], style=\"Edge\")\n","graph_index = 0\n","profile_one_hot = common_edges_finder(edge_explanations[graph_index], mutag_test_dataset[graph_index], 0.7)\n","print(\" input graph number of nodes: \", len(mutag_test_dataset[graph_index].x), \" input graph number of edges: \", len(mutag_test_dataset[graph_index].edge_index[0]))\n","for i, value in enumerate(profile_one_hot):\n","    print(i, \"   \", value)"],"metadata":{"id":"Dy2c02CO1oMX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715084108756,"user_tz":-120,"elapsed":403,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"2da7efcb-3e2f-4b43-e72f-45bcc5f2f739"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0     1\n","1     1\n","2     1\n","3     1\n","4     1\n","5     1\n","6     1\n","7     1\n","8     1\n","9     1\n","10     1\n","11     1\n","12     1\n","13     1\n","14     1\n","15     1\n","16     1\n","17     1\n","18     1\n","19     1\n","20     1\n","21     1\n","22     1\n","23     1\n","24     1\n","25     1\n","26     1\n","27     1\n","28     1\n","29     1\n","30     0\n","31     1\n","32     1\n","33     0\n","34     0\n","35     0\n","36     0\n","37     0\n"]}]},{"cell_type":"code","source":["sizes = []\n","for graph in mutag_dataset:\n","    sizes.append(len(graph.x))"],"metadata":{"id":"bmZKNMwY2zT5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(sizes.index(max(sizes)))\n","print(sizes.index(min(sizes)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lo3DYhP02-zo","executionInfo":{"status":"ok","timestamp":1713538726470,"user_tz":-120,"elapsed":322,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"9c4f4959-91dd-4305-b1f6-30d0708fb4cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5\n","75\n"]}]}]}