{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSwvvdzghlGyhfqxi5b4Gj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ua2_D2c4w_Mh"},"outputs":[],"source":["import torch\n","import statistics\n","from statistics import mean\n","import csv\n","import itertools\n","from sklearn import metrics\n","from copy import deepcopy"]},{"cell_type":"code","source":["class evalaution_of_xmethods_contrastivity(object):\n","    def __init__(self, a_trained_model, test_data):\n","        super(evalaution_of_xmethods_contrastivity, self).__init__()\n","        self.a_trained_model = a_trained_model\n","        self.test_data = test_data\n","\n","\n","    def is_salient(self, score, importance_threshold):\n","        if importance_threshold == score == 0:\n","            return True\n","        if importance_threshold == score == 1:\n","            return False\n","        if importance_threshold < score:\n","            return True\n","        else:\n","            return False\n","\n","    def standardize_for_contrastivity(self, sal_maps, contrast_coeff):\n","        final = []\n","        for graph in sal_maps:\n","            temp = []\n","            for node in graph:\n","                if node != 1.0:\n","                    temp.append(node*contrast_coeff - int(node*contrast_coeff))\n","                else:\n","                    temp.append(node)\n","            final.append(temp)\n","        return final\n","\n","    def normalize_saliency(self, input_graphs, sal_maps):\n","        Graphs_new_gradients = []\n","        for graph_grads in sal_maps:\n","            new_gradients = []\n","            for node_grads in graph_grads:\n","                val = (node_grads-min(graph_grads))/(max(graph_grads)-min(graph_grads)) if (max(graph_grads)-min(graph_grads)) != 0 else 0\n","                new_gradients.append(val)\n","            Graphs_new_gradients.append(new_gradients)\n","\n","        return Graphs_new_gradients\n","\n","    def binarize_scores(self, your_dataset, saliency_maps, importance_threshold, contrast_coeff):\n","        attribution_scores = self.standardize_for_contrastivity(saliency_maps, contrast_coeff)\n","        attribution_scores = self.normalize_saliency(your_dataset, attribution_scores)\n","\n","        binarized_attribution_scores_list = []\n","        for i in range(len(attribution_scores)):\n","            binary_score = ''\n","            sample_graph = deepcopy(your_dataset[i])\n","            for j in range(len(attribution_scores[i])):\n","                if self.is_salient(attribution_scores[i][j], importance_threshold):\n","                    binary_score += '1'\n","                else:\n","                    binary_score += '0'\n","            binarized_attribution_scores_list.append(binary_score)\n","        return binarized_attribution_scores_list\n","\n","    def hamming_distance(self, string1, string2):\n","\n","        distance = 0\n","        L = len(string1)\n","        for i in range(L):\n","            if string1[i] != string2[i]:\n","                distance += 1\n","        return distance\n","\n","    def my_contrastivity(self, your_dataset, saliencies_for_multiple_classes, importance_threshold, contrast_coeff):\n","        try:\n","            key_combinations = list(itertools.combinations(saliencies_for_multiple_classes.keys(), 2))\n","            contrastivity_combinations = []\n","            for (key1, key2) in key_combinations:\n","                binarized_salient_nodes_for_key1 = self.binarize_scores(your_dataset, saliencies_for_multiple_classes[key1], importance_threshold, contrast_coeff)\n","                binarized_salient_nodes_for_key2 = self.binarize_scores(your_dataset, saliencies_for_multiple_classes[key2], importance_threshold, contrast_coeff)\n","                result_list = []\n","                for class_0, class_1 in zip(binarized_salient_nodes_for_key1, binarized_salient_nodes_for_key2):\n","                    d = self.hamming_distance(class_0, class_1)/len(class_0)\n","                    result_list.append(d)\n","                contrastivity_combinations.append(mean(result_list))\n","            return mean(contrastivity_combinations)\n","        except:\n","            print(\"attributions are not in appropriate shape\")"],"metadata":{"id":"_wyjLuiFxEue"},"execution_count":null,"outputs":[]}]}