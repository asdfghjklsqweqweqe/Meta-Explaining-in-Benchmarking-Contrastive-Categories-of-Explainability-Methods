{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyMn7o55PcZmCE3e/uxPmnkP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVT1irXhrkKG","outputId":"6f1932d4-3efa-406e-f98c-cdfcf022e7ed","executionInfo":{"status":"ok","timestamp":1715948848399,"user_tz":-120,"elapsed":35967,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.1+cu121\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n","Collecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_cluster-1.6.3%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.25.2)\n","Installing collected packages: torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt22cu121\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"P0NjcUIbr5XI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715948863910,"user_tz":-120,"elapsed":14604,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"fffcb8c0-23b8-4970-af33-b7e8f311bde1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"bQ3lraKjKUh1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715949507055,"user_tz":-120,"elapsed":4,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"d93a6dde-42bb-427f-af43-1b88685f1f56"},"outputs":[{"output_type":"stream","name":"stdout","text":["ReLu is Selected.\n","Final Output:  tensor([[0.4570, 0.5430],\n","        [0.4682, 0.5318],\n","        [0.4686, 0.5314],\n","        [0.4543, 0.5457],\n","        [0.4720, 0.5280],\n","        [0.4916, 0.5084],\n","        [0.4586, 0.5414],\n","        [0.4708, 0.5292],\n","        [0.4683, 0.5317],\n","        [0.4570, 0.5430]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4570, 0.5430],\n","        [0.4573, 0.5427],\n","        [0.4739, 0.5261],\n","        [0.4693, 0.5307],\n","        [0.4543, 0.5457],\n","        [0.4740, 0.5260],\n","        [0.4671, 0.5329],\n","        [0.4731, 0.5269],\n","        [0.4685, 0.5315],\n","        [0.4601, 0.5399]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4839, 0.5161],\n","        [0.4719, 0.5281],\n","        [0.4505, 0.5495],\n","        [0.4478, 0.5522],\n","        [0.4730, 0.5270],\n","        [0.4940, 0.5060],\n","        [0.4505, 0.5495],\n","        [0.4583, 0.5417],\n","        [0.4893, 0.5107],\n","        [0.4505, 0.5495]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4735, 0.5265],\n","        [0.4961, 0.5039],\n","        [0.4553, 0.5447],\n","        [0.4657, 0.5343],\n","        [0.4622, 0.5378],\n","        [0.4627, 0.5373],\n","        [0.4570, 0.5430],\n","        [0.4605, 0.5395],\n","        [0.4728, 0.5272],\n","        [0.4658, 0.5342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4540, 0.5460],\n","        [0.4699, 0.5301],\n","        [0.4543, 0.5457],\n","        [0.4570, 0.5430],\n","        [0.4961, 0.5039],\n","        [0.4505, 0.5495],\n","        [0.4738, 0.5262],\n","        [0.4570, 0.5430],\n","        [0.4812, 0.5188],\n","        [0.4879, 0.5121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4658, 0.5342],\n","        [0.4659, 0.5341],\n","        [0.4809, 0.5191],\n","        [0.4802, 0.5198],\n","        [0.4627, 0.5373],\n","        [0.4600, 0.5400],\n","        [0.4916, 0.5084],\n","        [0.4678, 0.5322],\n","        [0.4505, 0.5495],\n","        [0.4956, 0.5044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4670, 0.5330],\n","        [0.4725, 0.5275],\n","        [0.4747, 0.5253],\n","        [0.4845, 0.5155],\n","        [0.4878, 0.5122],\n","        [0.4644, 0.5356],\n","        [0.4690, 0.5310],\n","        [0.4505, 0.5495],\n","        [0.4811, 0.5189],\n","        [0.4775, 0.5225]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4659, 0.5341],\n","        [0.4586, 0.5414],\n","        [0.4645, 0.5355],\n","        [0.4504, 0.5496],\n","        [0.4839, 0.5161],\n","        [0.4909, 0.5091],\n","        [0.4646, 0.5354],\n","        [0.4586, 0.5414],\n","        [0.4730, 0.5270],\n","        [0.4543, 0.5457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4961, 0.5039],\n","        [0.4870, 0.5130],\n","        [0.4595, 0.5405],\n","        [0.4737, 0.5263],\n","        [0.4505, 0.5495],\n","        [0.4505, 0.5495],\n","        [0.4722, 0.5278],\n","        [0.4801, 0.5199],\n","        [0.4689, 0.5311],\n","        [0.4505, 0.5495]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4678, 0.5322],\n","        [0.4543, 0.5457],\n","        [0.4505, 0.5495],\n","        [0.4543, 0.5457],\n","        [0.4956, 0.5044],\n","        [0.4872, 0.5128],\n","        [0.4697, 0.5303],\n","        [0.4695, 0.5305],\n","        [0.4605, 0.5395],\n","        [0.4644, 0.5356]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4505, 0.5495],\n","        [0.4943, 0.5057],\n","        [0.4543, 0.5457],\n","        [0.4505, 0.5495],\n","        [0.4609, 0.5391],\n","        [0.4683, 0.5317],\n","        [0.4870, 0.5130],\n","        [0.4543, 0.5457],\n","        [0.4627, 0.5373],\n","        [0.4961, 0.5039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4808, 0.5192],\n","        [0.4605, 0.5395],\n","        [0.4941, 0.5059],\n","        [0.4645, 0.5355],\n","        [0.4693, 0.5307],\n","        [0.4751, 0.5249],\n","        [0.4916, 0.5084],\n","        [0.4505, 0.5495],\n","        [0.4916, 0.5084],\n","        [0.4693, 0.5307]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4870, 0.5130],\n","        [0.4522, 0.5478],\n","        [0.4570, 0.5430],\n","        [0.4716, 0.5284],\n","        [0.4543, 0.5457],\n","        [0.4811, 0.5189],\n","        [0.4915, 0.5085],\n","        [0.4605, 0.5395],\n","        [0.4885, 0.5115],\n","        [0.4804, 0.5196]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4701, 0.5299],\n","        [0.4809, 0.5191],\n","        [0.4816, 0.5184],\n","        [0.4738, 0.5262],\n","        [0.4873, 0.5127],\n","        [0.4679, 0.5321],\n","        [0.4735, 0.5265],\n","        [0.4698, 0.5302],\n","        [0.4812, 0.5188],\n","        [0.4879, 0.5121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4889, 0.5111],\n","        [0.4825, 0.5175],\n","        [0.4802, 0.5198],\n","        [0.4899, 0.5101],\n","        [0.4644, 0.5356],\n","        [0.4644, 0.5356],\n","        [0.4716, 0.5284],\n","        [0.4605, 0.5395],\n","        [0.4812, 0.5188],\n","        [0.4708, 0.5292]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4695, 0.5305],\n","        [0.4738, 0.5262],\n","        [0.4605, 0.5395],\n","        [0.4658, 0.5342],\n","        [0.4899, 0.5101],\n","        [0.4722, 0.5278],\n","        [0.4683, 0.5317],\n","        [0.4649, 0.5351],\n","        [0.4683, 0.5317],\n","        [0.4941, 0.5059]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4658, 0.5342],\n","        [0.4961, 0.5039],\n","        [0.4738, 0.5262],\n","        [0.4740, 0.5260],\n","        [0.4543, 0.5457],\n","        [0.4690, 0.5310],\n","        [0.4740, 0.5260],\n","        [0.4804, 0.5196],\n","        [0.4975, 0.5025],\n","        [0.4604, 0.5396]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4961, 0.5039],\n","        [0.4693, 0.5307],\n","        [0.4915, 0.5085],\n","        [0.4739, 0.5261],\n","        [0.4754, 0.5246],\n","        [0.4693, 0.5307],\n","        [0.4810, 0.5190],\n","        [0.4689, 0.5311],\n","        [0.4831, 0.5169],\n","        [0.4627, 0.5373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","Final Output:  tensor([[0.4675, 0.5325],\n","        [0.4641, 0.5359],\n","        [0.4740, 0.5260],\n","        [0.4740, 0.5260],\n","        [0.4974, 0.5026],\n","        [0.4722, 0.5278],\n","        [0.4522, 0.5478],\n","        [0.4595, 0.5405]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"]}],"source":["from torch_geometric.utils import dropout\n","from torch_geometric.loader import DataLoader\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import math\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","from torch_geometric.utils.convert import to_scipy_sparse_matrix\n","#from torch_geometric.utils.train_test_split_edges import torch_geometric\n","import torch_geometric\n","import networkx as nx\n","import numpy as np\n","from torch_geometric.nn import GCNConv\n","import sys\n","from torch_geometric.datasets import TUDataset\n","from scipy.sparse import csr_matrix\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","import Batched_GraphSage_Layer as batched_graphsage_layer\n","import Batched_DIFFPOOL_Assignment as batched_diffpool_assignment\n","import Batched_DIFFPOOL_Embedding as batched_diffpool_embedding\n","import Batched_DIFFPOOL_Layer as batched_diffpool_layer\n","\n","\n","\n","class GlobalMeanPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return torch_geometric.nn.global_mean_pool(x, batch)\n","################################################################################\n","class IdenticalPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return x\n","\n","################################################################################\n","class DIFFPOOL_Model(nn.Module):\n","    '''\n","        DIFFPOOL Mode\n","    '''\n","    def __init__(self, embedding_input_dim, embedding_num_block_layers, embedding_hid_dim, new_feature_size, assignment_input_dim,\n","                 assignment_num_block_layers, assignment_hid_dim, max_number_of_nodes, concat_neighborhood, prediction_hid_layers,\n","                 num_classes, Weight_Initializer, Bias, dropout_rate, normalize_graphsage, aggregation, act_fun,\n","                 concat_diffpools_outputs, num_pooling, pooling):\n","\n","        super(DIFFPOOL_Model, self).__init__()\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.Bias = Bias\n","        self.dropout_rate = dropout_rate\n","        self.aggregation = aggregation\n","        self.act_fun = act_fun\n","        self.Weight_Initializer = Weight_Initializer\n","        self.concat_diffpools_outputs = concat_diffpools_outputs\n","        self.num_pooling = num_pooling\n","        self.concat = concat_neighborhood\n","        self.pooling = pooling\n","\n","\n","        self.embedding_input_dim = embedding_input_dim\n","        self.embedding_num_block_layers = embedding_num_block_layers\n","        self.embedding_hid_dim = embedding_hid_dim\n","        self.embedding_output_dim = new_feature_size\n","        self.normalize_graphsage = normalize_graphsage\n","\n","        self.assignment_input_dim = assignment_input_dim\n","        self.assignment_num_block_layers = assignment_num_block_layers\n","        self.assignment_hid_dim = assignment_hid_dim\n","        self.max_number_of_nodes = max_number_of_nodes\n","        self.assignment_output_dim = int(self.max_number_of_nodes * 0.25)\n","\n","\n","        prediction_input_dim_sum = 0\n","\n","        ###################################################.    DiffPool Layers\n","        diffpool_layers = []\n","        for i in range(self.num_pooling):\n","            a_new_layer = batched_diffpool_layer.Batched_DiffPool_Layer(embedding_input_dim=self.embedding_input_dim,\n","                                                                                 embedding_num_block_layers=self.embedding_num_block_layers,\n","                                                                                 embedding_hid_dim=self.embedding_hid_dim,\n","                                                                                 embedding_output_dim=self.embedding_output_dim,\n","                                                                                 assignment_input_dim=self.assignment_input_dim,\n","                                                                                 assignment_num_block_layers=self.assignment_num_block_layers,\n","                                                                                 assignment_hid_dim=self.assignment_hid_dim,\n","                                                                                 assignment_output_dim=self.assignment_output_dim,\n","                                                                                 concat=self.concat, Weight_Initializer=self.Weight_Initializer,\n","                                                                                 Bias=self.Bias, dropout_rate=self.dropout_rate,\n","                                                                                 normalize_graphsage=self.normalize_graphsage,\n","                                                                                 aggregation=self.aggregation, act_fun=self.act_fun).to(self.device)\n","            diffpool_layers.append(a_new_layer)\n","\n","            self.assignment_output_dim = int(self.assignment_output_dim * .25)\n","            self.embedding_input_dim = self.embedding_output_dim\n","            self.assignment_input_dim = self.embedding_output_dim\n","            prediction_input_dim_sum = prediction_input_dim_sum + self.embedding_output_dim\n","        self.diffpool_layers = nn.Sequential(*diffpool_layers).to(self.device)\n","\n","        ###################################################.    Last Extra Embedding\n","\n","        self.last_extra_embedding = batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer(input_dim=self.embedding_output_dim,\n","                                                                                                embedding_num_block_layers=self.embedding_num_block_layers,\n","                                                                                                hid_dim=self.embedding_hid_dim, concat=self.concat,\n","                                                                                                embedded_dim=self.embedding_output_dim, Bias=self.Bias,\n","                                                                                                normalize_graphsage=self.normalize_graphsage, dropout=self.dropout_rate,\n","                                                                                                aggregation=self.aggregation).to(self.device)\n","        prediction_input_dim_sum = prediction_input_dim_sum + self.embedding_output_dim\n","\n","        ###################################################.    Predictions\n","        self.prediction_input_dim = self.embedding_output_dim\n","        self.prediction_hid_layers = prediction_hid_layers\n","        self.num_classes = num_classes\n","\n","        prediction_layers = []\n","        if len(self.prediction_hid_layers) == 0:\n","            if self.concat_diffpools_outputs:\n","                a_new_layer = nn.Linear(prediction_input_dim_sum, self.num_classes).to(self.device)\n","                prediction_layers.append(a_new_layer)\n","                self.prediction_model = nn.Sequential(*prediction_layers).to(self.device)\n","            else:\n","                a_new_layer = nn.Linear(self.prediction_input_dim, self.num_classes).to(self.device)\n","                prediction_layers.append(a_new_layer)\n","                self.prediction_model = nn.Sequential(*prediction_layers).to(self.device)\n","        else:\n","            if self.concat_diffpools_outputs:\n","                predict_input_dim = prediction_input_dim_sum\n","                for i in range(len(self.prediction_hid_layers)):\n","                    a_new_layer = nn.Linear(predict_input_dim, prediction_hid_layers[i]).to(self.device)\n","                    prediction_layers.append(a_new_layer)\n","                    predict_input_dim = prediction_hid_layers[i]\n","                a_new_layer = nn.Linear(predict_input_dim, self.num_classes).to(self.device)\n","                prediction_layers.append(a_new_layer)\n","                self.prediction_model = nn.Sequential(*prediction_layers).to(self.device)\n","            else:\n","                predict_input_dim = self.prediction_input_dim\n","                for i in range(len(self.prediction_hid_layers)):\n","                    a_new_layer = nn.Linear(predict_input_dim, prediction_hid_layers[i]).to(self.device)\n","                    prediction_layers.append(a_new_layer)\n","                    predict_input_dim = prediction_hid_layers[i]\n","                a_new_layer = nn.Linear(predict_input_dim, self.num_classes).to(self.device)\n","                prediction_layers.append(a_new_layer)\n","                self.prediction_model = nn.Sequential(*prediction_layers).to(self.device)\n","\n","        if act_fun == 'ReLu':\n","            self.act_fun = F.relu\n","            print('ReLu is Selected.')\n","        elif act_fun == 'eLu':\n","            self.act_fun = nn.functional.elu\n","            print('eLu is Selected.')\n","        elif act_fun == 'tanh':\n","            self.act_fun = torch.tanh\n","            print('tanh is Selected.')\n","        self.act_fun_softmax = F.softmax\n","\n","        mean = 0\n","        std = 0.1\n","        self.initialize_weights(Weight_Initializer, Bias, mean, std)\n","\n","    def initialize_weights(model, Weight_Initializer, Bias, mean, std):\n","        # 1. Xavier Normal_.  2. Kaiming Normal_.  3. Uniform (0,0.1std)\n","\n","        if Weight_Initializer == 1:                                             #.      1. Xavier Normal_.\n","            for i, module in enumerate(model.children()):\n","                #print(i, module)\n","                if isinstance(module, torch.nn.Sequential):\n","                    for j, module_sub in enumerate(module):\n","                        #print(\"j: \",j,module_sub)\n","                        if isinstance(module_sub, batched_diffpool_layer.Batched_DiffPool_Layer):\n","                            #print(module_sub)\n","                            for party in module_sub.children():\n","                                if isinstance(party, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                                    for diff_embd_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_embd_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_embed_party_in_modulelist in diff_embd_party.children():\n","                                                if isinstance(diff_embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.xavier_normal_(diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    #torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_embed_party_in_modulelist.learnable_weights.weight: \",diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                elif isinstance(party, batched_diffpool_assignment.Batched_DiffPool_Assignment_Layer):\n","                                    for diff_assign_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_assign_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_assign_party_in_modulelist in diff_assign_party.children():\n","                                                if isinstance(diff_assign_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.xavier_normal_(diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_assign_party_in_modulelist.learnable_weights.weight: \",diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                        elif isinstance(diff_assign_party, torch.nn.Sequential):\n","                                            for diff_assign_party_in_sequential in diff_assign_party:\n","                                                if isinstance(diff_assign_party_in_sequential, torch.nn.Linear):\n","                                                    torch.nn.init.xavier_normal_(diff_assign_party_in_sequential.weight)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_sequential.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_sequential.bias)\n","                                                        #print(diff_assign_party_in_sequential.bias)\n","                        elif isinstance(module_sub, torch.nn.Linear):\n","                            #print(\"linear final prediction layers\")\n","                            torch.nn.init.xavier_normal_(module_sub.weight)\n","                            if Bias:\n","                                torch.nn.init.zeros_(module_sub.bias)\n","                                #print(module_sub.bias)\n","                elif isinstance(module, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                    for embd_party in module.children():\n","                        #print(\"embd_party: \")#, embd_party)\n","                        if isinstance(embd_party, torch.nn.ModuleList):\n","                            for embed_party_in_modulelist in embd_party.children():\n","                                if isinstance(embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                    torch.nn.init.xavier_normal_(embed_party_in_modulelist.learnable_weights.weight)\n","                                    #torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.weight)\n","                                    #print(\"embed_party_in_modulelist.learnable_weights.weight: \",embed_party_in_modulelist.learnable_weights.weight)\n","                                    if Bias:\n","                                        torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.bias)\n","                                        #print(embed_party_in_modulelist.learnable_weights.bias)\n","\n","        if Weight_Initializer == 2:                                             #.      1. Kaiming Normal_.\n","            for i, module in enumerate(model.children()):\n","                #print(i, module)\n","                if isinstance(module, torch.nn.Sequential):\n","                    for j, module_sub in enumerate(module):\n","                        #print(\"j: \",j,module_sub)\n","                        if isinstance(module_sub, batched_diffpool_layer.Batched_DiffPool_Layer):\n","                            #print(module_sub)\n","                            for party in module_sub.children():\n","                                if isinstance(party, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                                    for diff_embd_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_embd_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_embed_party_in_modulelist in diff_embd_party.children():\n","                                                if isinstance(diff_embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.kaiming_normal_(diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    #torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_embed_party_in_modulelist.learnable_weights.weight: \",diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                elif isinstance(party, batched_diffpool_assignment.Batched_DiffPool_Assignment_Layer):\n","                                    for diff_assign_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_assign_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_assign_party_in_modulelist in diff_assign_party.children():\n","                                                if isinstance(diff_assign_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.kaiming_normal_(diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_assign_party_in_modulelist.learnable_weights.weight: \",diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                        elif isinstance(diff_assign_party, torch.nn.Sequential):\n","                                            for diff_assign_party_in_sequential in diff_assign_party:\n","                                                if isinstance(diff_assign_party_in_sequential, torch.nn.Linear):\n","                                                    torch.nn.init.kaiming_normal_(diff_assign_party_in_sequential.weight)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_sequential.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_sequential.bias)\n","                                                        #print(diff_assign_party_in_sequential.bias)\n","                        elif isinstance(module_sub, torch.nn.Linear):\n","                            #print(\"linear final prediction layers\")\n","                            torch.nn.init.kaiming_normal_(module_sub.weight)\n","                            if Bias:\n","                                torch.nn.init.zeros_(module_sub.bias)\n","                                #print(module_sub.bias)\n","                elif isinstance(module, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                    for embd_party in module.children():\n","                        #print(\"embd_party: \")#, embd_party)\n","                        if isinstance(embd_party, torch.nn.ModuleList):\n","                            for embed_party_in_modulelist in embd_party.children():\n","                                if isinstance(embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                    torch.nn.init.kaiming_normal_(embed_party_in_modulelist.learnable_weights.weight)\n","                                    #torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.weight)\n","                                    #print(\"embed_party_in_modulelist.learnable_weights.weight: \",embed_party_in_modulelist.learnable_weights.weight)\n","                                    if Bias:\n","                                        torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.bias)\n","                                        #print(embed_party_in_modulelist.learnable_weights.bias)\n","\n","        if Weight_Initializer == 3:                                             #.      3. Uniform (0,0.1std)\n","            for i, module in enumerate(model.children()):\n","                #print(i, module)\n","                if isinstance(module, torch.nn.Sequential):\n","                    for j, module_sub in enumerate(module):\n","                        #print(\"j: \",j,module_sub)\n","                        if isinstance(module_sub, batched_diffpool_layer.Batched_DiffPool_Layer):\n","                            #print(module_sub)\n","                            for party in module_sub.children():\n","                                if isinstance(party, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                                    for diff_embd_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_embd_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_embed_party_in_modulelist in diff_embd_party.children():\n","                                                if isinstance(diff_embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.normal_(diff_embed_party_in_modulelist.learnable_weights.weight, mean=mean, std=std)\n","                                                    #torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_embed_party_in_modulelist.learnable_weights.weight: \",diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                elif isinstance(party, batched_diffpool_assignment.Batched_DiffPool_Assignment_Layer):\n","                                    for diff_assign_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_assign_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_assign_party_in_modulelist in diff_assign_party.children():\n","                                                if isinstance(diff_assign_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.normal_(diff_assign_party_in_modulelist.learnable_weights.weight, mean=mean, std=std)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_assign_party_in_modulelist.learnable_weights.weight: \",diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                        elif isinstance(diff_assign_party, torch.nn.Sequential):\n","                                            for diff_assign_party_in_sequential in diff_assign_party:\n","                                                if isinstance(diff_assign_party_in_sequential, torch.nn.Linear):\n","                                                    torch.nn.init.normal_(diff_assign_party_in_sequential.weight, mean=mean, std=std)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_sequential.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_sequential.bias)\n","                                                        #print(diff_assign_party_in_sequential.bias)\n","                        elif isinstance(module_sub, torch.nn.Linear):\n","                            #print(\"linear final prediction layers\")\n","                            torch.nn.init.normal_(module_sub.weight, mean=mean, std=std)\n","                            if Bias:\n","                                torch.nn.init.zeros_(module_sub.bias)\n","                                #print(module_sub.bias)\n","                elif isinstance(module, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                    for embd_party in module.children():\n","                        #print(\"embd_party: \")#, embd_party)\n","                        if isinstance(embd_party, torch.nn.ModuleList):\n","                            for embed_party_in_modulelist in embd_party.children():\n","                                if isinstance(embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                    torch.nn.init.normal_(embed_party_in_modulelist.learnable_weights.weight, mean=mean, std=std)\n","                                    #torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.weight)\n","                                    #print(\"embed_party_in_modulelist.learnable_weights.weight: \",embed_party_in_modulelist.learnable_weights.weight)\n","                                    if Bias:\n","                                        torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.bias)\n","                                        #print(embed_party_in_modulelist.learnable_weights.bias)\n","\n","\n","\n","\n","\n","\n","\n","    def computational_matricess(self, batched_graphs, edge_mask):\n","        if edge_mask == None:\n","            joint_tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())))\n","        else:\n","            joint_tilda_adjacency_matrix = torch.tensor(csr_matrix((np.array(edge_mask), (np.array(batched_graphs.edge_index[0]), np.array(batched_graphs.edge_index[1])))).todense())\n","\n","        joint_tilda_adjacency_matrix = joint_tilda_adjacency_matrix.type(torch.float32)\n","\n","\n","        if batched_graphs.batch is not None:\n","            graph_sizes = [len(batched_graphs[i].x) for i in range(len(batched_graphs))]\n","            batch_size = batched_graphs.num_graphs\n","        else:\n","            graph_sizes = [len(batched_graphs.x)]\n","            batch_size = 1\n","        max_number_of_nodes_in_batch_of_graphs = max(graph_sizes)\n","        #print(\"max_number_of_nodes_in_batch_of_graphs: \", max_number_of_nodes_in_batch_of_graphs)\n","\n","        new_number_of_nodes = int(joint_tilda_adjacency_matrix.size()[0] / batch_size)\n","\n","        adjacency_list = []\n","        feature_list = []\n","        start = 0\n","        for i in range(batch_size):\n","            end = start + graph_sizes[i]\n","            un_padded_adj = joint_tilda_adjacency_matrix[start:end, start:end]\n","            adj_off_set = max_number_of_nodes_in_batch_of_graphs - un_padded_adj.size()[0]\n","            if un_padded_adj.size()[0] <= max_number_of_nodes_in_batch_of_graphs:\n","                un_padded_adj = F.pad(un_padded_adj, (0, adj_off_set, 0, adj_off_set), mode='constant', value=0)\n","                un_padded_adj = un_padded_adj.type(torch.float32)\n","                num_nodes = max_number_of_nodes_in_batch_of_graphs\n","            un_padded_adj = un_padded_adj.type(torch.float32)\n","            adjacency_list.append(un_padded_adj)\n","            un_padded_feat = batched_graphs.x[start:end, :]\n","            node_feat_off_set = max_number_of_nodes_in_batch_of_graphs - graph_sizes[i]\n","            un_padded_feat = F.pad(un_padded_feat, (0, 0, 0, node_feat_off_set), mode='constant', value=0)\n","            un_padded_feat = un_padded_feat.type(torch.float32)\n","            un_padded_feat.require_grad = True\n","            feature_list.append(un_padded_feat)\n","            start = end\n","\n","        adjacency_list = list(map(lambda x: torch.unsqueeze(x, 0), adjacency_list))\n","        feature_list = list(map(lambda x: torch.unsqueeze(x, 0), feature_list))\n","\n","        new_adjacecny = torch.cat(adjacency_list, dim=0)\n","        new_features = torch.cat(feature_list, dim=0)\n","\n","        return new_adjacecny, new_features\n","\n","    def forward(self, batched_graphs, edge_mask):\n","        adjacecny, features = self.computational_matricess(batched_graphs, edge_mask)\n","        adjacecny = adjacecny.to(self.device)\n","        features = features.to(self.device)\n","        concatination_list_of_poolings = []\n","\n","        for i in range(self.num_pooling):\n","            embedding_output, assignment_output = self.diffpool_layers[i](features, adjacecny)\n","            #features = torch.matmul(torch.transpose(assignment_output, 1, 2), embedding_output)\n","            embedding_output = embedding_output.to(self.device)\n","            assignment_output = assignment_output.to(self.device)\n","            features = torch.bmm(torch.transpose(assignment_output, 1, 2), embedding_output)\n","            adjacecny = torch.transpose(assignment_output, 1, 2) @ adjacecny @ assignment_output\n","\n","\n","            if self.pooling == \"max\":\n","                embedding_output_pooled, _ = torch.max(embedding_output, dim=1)\n","            elif self.pooling == \"mean\":\n","                embedding_output_pooled = torch.mean(embedding_output, dim=1)\n","            elif self.pooling == \"sum\":\n","                embedding_output_pooled = torch.sum(embedding_output, dim=1)\n","            concatination_list_of_poolings.append(embedding_output_pooled)\n","\n","\n","        extra_embed = self.last_extra_embedding(features, adjacecny)\n","        if self.pooling == \"max\":\n","            extra_embed_pooled, _ = torch.max(extra_embed, dim=1)\n","        elif self.pooling == \"mean\":\n","            extra_embed_pooled = torch.mean(extra_embed, dim=1)\n","        elif self.pooling == \"sum\":\n","            extra_embed_pooled = torch.sum(extra_embed, dim=1)\n","        concatination_list_of_poolings.append(extra_embed_pooled)\n","\n","        if self.concat_diffpools_outputs:\n","            output = torch.cat(concatination_list_of_poolings, dim=1)\n","        else:\n","            output = extra_embed_pooled\n","\n","        prediction_output = output\n","        for i in range(len(self.prediction_hid_layers)):\n","\n","            prediction_output = self.act_fun(self.prediction_model[i](prediction_output))\n","        prediction_output = self.prediction_model[-1](prediction_output)\n","        prediction_output_soft = F.softmax(prediction_output, dim=-1)\n","\n","\n","\n","        return concatination_list_of_poolings, prediction_output, prediction_output_soft\n","\n","\n","\n","\n","\n","\n","\n","diffpool_model_example = DIFFPOOL_Model(embedding_input_dim=7, embedding_num_block_layers=1, embedding_hid_dim=64, new_feature_size=20,\n","                                        assignment_input_dim=7, assignment_num_block_layers=1, assignment_hid_dim=64, max_number_of_nodes=128,\n","                                        prediction_hid_layers=[7], concat_neighborhood=False, num_classes=2, Weight_Initializer=3,\n","                                        Bias=True, dropout_rate=0, normalize_graphsage=True, aggregation=\"mean\",\n","                                        act_fun=\"ReLu\", concat_diffpools_outputs=False, num_pooling=1, pooling=\"sum\")\n","\n","\n","dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n","batch_size = 10\n","batched_dataset = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","GlobalMeanPool_exp = GlobalMeanPool()\n","for batched_graph in batched_dataset:\n","    #x, edge_index, batch, y = batched_graph.x, batched_graph.edge_index, batched_graph.batch, batched_graph.y\n","    concatination_list_of_poolings, prediction_output, prediction_output_soft = diffpool_model_example(batched_graph, None)\n","    print(\"Final Output: \", prediction_output_soft)\n","\n"]},{"cell_type":"code","source":["print(np.zeros(1,dtype=np.float32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAUCyezHDUUU","executionInfo":{"status":"ok","timestamp":1689701500741,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"add24870-adfb-4eb4-cc92-4ad72d4d552f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.]\n"]}]}]}