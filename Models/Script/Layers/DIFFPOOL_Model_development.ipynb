{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM9HEudDr39miNiB24OfQ4J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install --upgrade scipy networkx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cvsh5p3Mfdh0","executionInfo":{"status":"ok","timestamp":1694871544515,"user_tz":-120,"elapsed":56064,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"41defb42-9b4c-4b0d-9b19-68f89954c83a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.1)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import math\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","from torch_geometric.utils.convert import to_scipy_sparse_matrix\n","from torch_geometric.utils.train_test_split_edges import torch_geometric\n","import networkx as nx\n","import numpy as np\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.loader import DataLoader\n","\n","from torch_geometric.datasets import TUDataset"],"metadata":{"id":"EYq5IcFQp8_L","executionInfo":{"status":"ok","timestamp":1694871546883,"user_tz":-120,"elapsed":2376,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["m = nn.Dropout(p=0)\n","input = torch.randn(4, 4)\n","output = m(input)\n","print(input)\n","#print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5K6XBqNTmZku","executionInfo":{"status":"ok","timestamp":1689371467863,"user_tz":-120,"elapsed":11,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"0b9e0aed-d5c8-426f-a95b-a6b5b5c596b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.5486,  0.8004,  0.3328, -1.8980],\n","        [ 0.8009,  0.8011,  0.4224, -0.5019],\n","        [-0.5427,  0.7062, -0.1693, -0.6536],\n","        [ 0.6186, -0.5346, -1.0154,  0.6742]])\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-jcetoUc-SUI","executionInfo":{"status":"ok","timestamp":1694871566303,"user_tz":-120,"elapsed":18879,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"c7accc77-3c37-4294-a82e-25e87658c372"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["dataset = TUDataset(root='data/TUDataset', name='MUTAG')"],"metadata":{"id":"ai5efxpkqEMr","executionInfo":{"status":"ok","timestamp":1694871567941,"user_tz":-120,"elapsed":1646,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2f0df75-53b7-42e4-e0f5-c60f7842973d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n","Extracting data/TUDataset/MUTAG/MUTAG.zip\n","Processing...\n","Done!\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_HfGP0awdzyD"},"outputs":[],"source":["\n","import sys\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","from torch_geometric.typing import Adj, OptPairTensor, Size, SparseTensor\n","import torch\n","import torch.nn as nn\n","import matrix_util as Mat_Util\n","class GNN_GraphSage_Layer(nn.Module):\n","    '''\n","        #    A single GraphSage Layer: Graph Sampling and Aggregate\n","    '''\n","    def __init__(self, input_dim, output_dim, Bias, normalize_embedding, dropout, aggregation):\n","        super(GNN_GraphSage_Layer, self).__init__()\n","\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.Bias = Bias\n","        self.dropout = dropout\n","        self.normalize_embedding = normalize_embedding\n","        self.aggregation = aggregation\n","        #self.add_self = add_self\n","\n","        if self.aggregation == 'mean':\n","            self.learnable_weights = nn.Linear(self.input_dim*2, self.output_dim, bias=self.Bias)\n","        else:\n","            self.learnable_weights = nn.Linear(self.input_dim, self.output_dim, bias=self.Bias)\n","\n","        self.normalize = F.normalize\n","\n","    def forward(self, input_tensor, tilda_adjacency_matrix):\n","\n","        if self.aggregation == 'mean':\n","            tilda_adjacency_matrix = tilda_adjacency_matrix / tilda_adjacency_matrix.sum(-1, keepdim=True)\n","        num_node_per_graph = tilda_adjacency_matrix.size(1)\n","        print(\"num_node_per_graph: \", num_node_per_graph)\n","\n","        tilda_adjacency_matrix_neghborhood = torch.mm(tilda_adjacency_matrix, input_tensor) # Y = A~ * X\n","\n","        neighborhood_aggregated = torch.cat((tilda_adjacency_matrix_neghborhood, input_tensor), 1)\n","\n","        node_linear = self.learnable_weights(neighborhood_aggregated) # Y * W\n","\n","        if self.normalize_embedding:\n","            node_linear = self.normalize(node_linear, p=2, dim=2)\n","\n","\n","\n","        return node_linear\n"]},{"cell_type":"code","source":["graphsage = GNN_GraphSage_Layer(input_dim=7, output_dim=7, Bias=True, normalize_embedding=True, dropout=0, aggregation='mean')\n","graph = dataset[0]\n","tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(graph.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(graph.edge_index).todense())))\n","#print(adjacency_matrix)\n","\n","graphsage_output = graphsage(graph.x, tilda_adjacency_matrix)\n","print(graphsage)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TqBPewh7PaG4","executionInfo":{"status":"ok","timestamp":1678030834209,"user_tz":-60,"elapsed":264,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"a29d2391-8a3a-41e3-eb92-3a469466086f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["num_node_per_graph:  17\n","GNN_GraphSage_Layer(\n","  (learnable_weights): Linear(in_features=14, out_features=7, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["graphsage = GNN_GraphSage_Layer(input_dim=7, output_dim=7, Bias=True, normalize_embedding=True, dropout=0, aggregation='mean')\n","graph = dataset[0]\n","tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(graph.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(graph.edge_index).todense())))\n","#print(adjacency_matrix)\n","\n","graphsage_output = graphsage(graph.x, tilda_adjacency_matrix)"],"metadata":{"id":"YNeMNGLvq-W2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678030804404,"user_tz":-60,"elapsed":248,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"28a0d56a-2d20-428d-aa9c-9d245f8ee207"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["num_node_per_graph:  17\n"]}]},{"cell_type":"code","source":["import sys\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","from torch_geometric.typing import Adj, OptPairTensor, Size, SparseTensor\n","import torch\n","import torch.nn as nn\n","import matrix_util as Mat_Util\n","class GNN_Batched_GraphSage_Layer(nn.Module):\n","    '''\n","        #    A single GraphSage Layer: Graph Sampling and Aggregate\n","    '''\n","    def __init__(self, input_dim, output_dim, Bias, normalize_graphsage, dropout, aggregation, concat):\n","        super(GNN_Batched_GraphSage_Layer, self).__init__()\n","\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.Bias = Bias\n","        self.dropout = dropout\n","        self.normalize_graphsage = normalize_graphsage\n","        self.aggregation = aggregation\n","        self.concat = concat\n","\n","        if self.concat:\n","            self.learnable_weights = nn.Linear(self.input_dim*2, self.output_dim, bias=self.Bias)\n","        else:\n","            self.learnable_weights = nn.Linear(self.input_dim, self.output_dim, bias=self.Bias)\n","\n","        self.normalize = F.normalize\n","\n","\n","    def forward(self, new_features, tilda_adjacency_matrix):\n","\n","        #new_features = new_features.to(torch.float32)\n","        new_features = new_features.type(torch.float32)\n","        tilda_adjacency_matrix = tilda_adjacency_matrix.type(torch.float32)\n","\n","\n","        if self.aggregation == 'mean':\n","            tilda_adjacency_matrix = tilda_adjacency_matrix / (tilda_adjacency_matrix.sum(-2, keepdim=False).unsqueeze(dim=-2))\n","        tilda_adjacency_matrix = torch.nan_to_num(tilda_adjacency_matrix, nan=0)\n","\n","        aggregated_neghborhood = torch.bmm(tilda_adjacency_matrix, new_features) # Y = A~ * X\n","\n","        if self.concat:\n","            aggregated_neghborhood = torch.cat((aggregated_neghborhood, new_features), 2)\n","\n","        node_linear = self.learnable_weights(aggregated_neghborhood) # Y * W\n","\n","        if self.normalize_graphsage:\n","            node_linear = self.normalize(node_linear, p=2, dim=2)\n","        node_linear = torch.nan_to_num(node_linear, nan=0)\n","        #print(\"node_linear: \",node_linear)\n","\n","        return node_linear"],"metadata":{"id":"YiXCuD2jK7cn","executionInfo":{"status":"ok","timestamp":1694871570170,"user_tz":-120,"elapsed":2234,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["mat = torch.arange(24).view(2,3,2, -1)\n","print(\"mat: \", mat.size())\n","print(mat)\n","print(\"===============================\")\n","sum = torch.sum(mat, dim=-2).unsqueeze(dim=-2)\n","print(\"sum: \", sum.size())\n","print(sum)\n","print(\"===============================\")\n","final = mat/sum\n","print(final)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"saqAAO8dZNVY","executionInfo":{"status":"ok","timestamp":1689786968578,"user_tz":-120,"elapsed":9,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"3937b93c-5a8e-40c7-bb91-a4e3770771f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mat:  torch.Size([2, 3, 2, 2])\n","tensor([[[[ 0,  1],\n","          [ 2,  3]],\n","\n","         [[ 4,  5],\n","          [ 6,  7]],\n","\n","         [[ 8,  9],\n","          [10, 11]]],\n","\n","\n","        [[[12, 13],\n","          [14, 15]],\n","\n","         [[16, 17],\n","          [18, 19]],\n","\n","         [[20, 21],\n","          [22, 23]]]])\n","===============================\n","sum:  torch.Size([2, 3, 1, 2])\n","tensor([[[[ 2,  4]],\n","\n","         [[10, 12]],\n","\n","         [[18, 20]]],\n","\n","\n","        [[[26, 28]],\n","\n","         [[34, 36]],\n","\n","         [[42, 44]]]])\n","===============================\n","tensor([[[[0.0000, 0.2500],\n","          [1.0000, 0.7500]],\n","\n","         [[0.4000, 0.4167],\n","          [0.6000, 0.5833]],\n","\n","         [[0.4444, 0.4500],\n","          [0.5556, 0.5500]]],\n","\n","\n","        [[[0.4615, 0.4643],\n","          [0.5385, 0.5357]],\n","\n","         [[0.4706, 0.4722],\n","          [0.5294, 0.5278]],\n","\n","         [[0.4762, 0.4773],\n","          [0.5238, 0.5227]]]])\n"]}]},{"cell_type":"code","source":["t = torch.tensor([[1.,2.,3.]])\n","print(\"tensor: \", t)\n","t1 = F.normalize(t, p=2.0, dim = 0)\n","t2 = F.normalize(t, p=2.0, dim = 1)\n","print(t1)\n","print(t2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tl4wpAzUh5ED","executionInfo":{"status":"ok","timestamp":1678033107330,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"5b46b806-eff8-4810-e084-ddada3997adc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor:  tensor([[1., 2., 3.]])\n","tensor([[1., 1., 1.]])\n","tensor([[0.2673, 0.5345, 0.8018]])\n"]}]},{"cell_type":"code","source":["batched_graphsage_example = GNN_Batched_GraphSage_Layer(input_dim=7, output_dim=7, Bias=True, normalize_graphsage=True, dropout=0,\n","                                                        aggregation='mean', concat=False)\n","print(batched_graphsage_example)"],"metadata":{"id":"Yd2Gllqx6Cl-","executionInfo":{"status":"ok","timestamp":1694871570170,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"19f8bbd1-1e88-4f7a-8296-68a6773a22c8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["GNN_Batched_GraphSage_Layer(\n","  (learnable_weights): Linear(in_features=7, out_features=7, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["batched_dataset = DataLoader(dataset, batch_size=1, shuffle=False)\n","\n","for batched_graph in batched_dataset:\n","    #print(len(batched_graph))\n","    x, edge_index, batch, y = batched_graph.x, batched_graph.edge_index, batched_graph.batch, batched_graph.y\n","    #print(batched_graph.num_graphs)\n","    tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graph.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graph.edge_index).todense())))\n","    #print(\"tilda_adjacency_matrix: \", tilda_adjacency_matrix.size())\n","    softmaxed_output = batched_graphsage_example(batched_graph, tilda_adjacency_matrix)\n","    print(\"softmaxed_output: \", softmaxed_output.size())\n","    break\n","print(softmaxed_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"ooZC3Suk6jIl","executionInfo":{"status":"error","timestamp":1694871571732,"user_tz":-120,"elapsed":1564,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"0c32fbea-75e7-4549-ab36-0f0825bee07d"},"execution_count":7,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-24cb24aa41cb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtilda_adjacency_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_scipy_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_scipy_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(\"tilda_adjacency_matrix: \", tilda_adjacency_matrix.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msoftmaxed_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_graphsage_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtilda_adjacency_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmaxed_output: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmaxed_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-5c89326d48a3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, new_features, tilda_adjacency_matrix)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#new_features = new_features.to(torch.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mtilda_adjacency_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtilda_adjacency_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \"root folder and try again.\")\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;34mf\"'{self.__class__.__name__}' object has no attribute '{key}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             ) from None\n","\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'type'"]}]},{"cell_type":"code","source":["print(graphsage_output.size())\n","print(graphsage_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wY5Z1xSor6UZ","executionInfo":{"status":"ok","timestamp":1677986639464,"user_tz":-60,"elapsed":264,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"4af0a0ff-ad42-43a5-efef-4c72add2ae55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([17, 7])\n","tensor([[ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.6193, -0.0558,  0.3279, -0.2110, -0.5358, -0.3831,  0.1656],\n","        [ 0.5391, -0.0586,  0.2297, -0.1688, -0.6186, -0.4392,  0.2216],\n","        [ 0.0833,  0.7969, -0.1444, -0.1451,  0.3239, -0.4434, -0.1207],\n","        [ 0.4752, -0.4233, -0.0693, -0.2001, -0.5904, -0.1068, -0.4362],\n","        [ 0.4752, -0.4233, -0.0693, -0.2001, -0.5904, -0.1068, -0.4362]],\n","       grad_fn=<DivBackward0>)\n"]}]},{"cell_type":"code","source":["sum=0\n","length_list = []\n","for i in range(len(dataset)):\n","    sum = sum + len(dataset[i].x)\n","    length_list.append(len(dataset[i].x))\n","    #print(len(dataset[i].x))\n","print(\"number of nodes in whole dataset: \", sum)\n","print(length_list)\n","print(\"max number of nodes in graphs: \", max(length_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1XO_SJu6cSQ","executionInfo":{"status":"ok","timestamp":1677978724294,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"45cddb9b-2e48-43fe-bbf9-bbba0370ab10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["number of nodes in whole dataset:  3371\n","[17, 13, 13, 19, 11, 28, 16, 20, 12, 17, 17, 20, 22, 13, 19, 22, 11, 17, 13, 18, 18, 17, 23, 27, 17, 13, 23, 17, 23, 23, 22, 24, 23, 13, 17, 14, 17, 15, 15, 13, 17, 13, 19, 17, 12, 23, 22, 17, 20, 16, 26, 26, 19, 19, 14, 17, 21, 25, 23, 19, 17, 11, 23, 20, 16, 16, 20, 23, 19, 14, 26, 16, 16, 23, 18, 10, 16, 16, 17, 19, 12, 25, 16, 11, 23, 23, 16, 12, 13, 23, 25, 19, 23, 19, 19, 25, 18, 13, 15, 16, 23, 26, 19, 23, 17, 20, 25, 19, 28, 24, 11, 15, 13, 16, 12, 10, 21, 23, 21, 13, 25, 21, 17, 11, 19, 20, 21, 15, 14, 11, 19, 11, 21, 22, 11, 20, 22, 13, 11, 16, 11, 20, 12, 11, 16, 16, 13, 15, 20, 12, 12, 22, 15, 12, 14, 12, 20, 20, 20, 14, 26, 24, 22, 22, 19, 23, 22, 11, 13, 17, 24, 12, 21, 22, 22, 12, 20, 13, 22, 28, 11, 14, 22, 22, 13, 12, 21, 16]\n","max number of nodes in graphs:  28\n"]}]},{"cell_type":"code","source":["\n","class DiffPool_Embedding_Layer(nn.Module):\n","    '''\n","   #     Z, new features size\n","    '''\n","    def __init__(self, input_dim_size, new_feat_dim_size, Bias, normalize_embedding, dropout, aggregation):\n","        super(DiffPool_Embedding_Layer, self).__init__()\n","        self.input_dim_size = input_dim_size\n","        self.new_feat_dim_size = new_feat_dim_size\n","        self.Bias = Bias\n","        self.normalize_embedding = normalize_embedding\n","        self.dropout = dropout\n","        self.aggregation = aggregation\n","        self.embedding_layer = GNN_GraphSage_Layer(input_dim=self.input_dim_size, output_dim=self.new_feat_dim_size, Bias=self.Bias, normalize_embedding=self.normalize_embedding, dropout=self.dropout, aggregation=self.aggregation)\n","        #self.embedding_layer = GNN_Batched_GraphSage_Layer(input_dim=self.input_dim_size, output_dim=self.new_feat_dim_size, Bias=self.Bias, normalize_embedding=self.normalize_embedding, dropout=self.dropout, aggregation=self.aggregation)\n","        self.act_fun = F.relu\n","\n","\n","    def forward(self, input_tensor, tilda_adjacency_matrix):\n","        #x, edge_index, batch, y = batched_graph.x, batched_graph.edge_index, batched_graph.batch, batched_graph.y\n","        z_l_init = self.embedding_layer(input_tensor, tilda_adjacency_matrix)\n","        z_l_init = self.act_fun(z_l_init)\n","\n","        return z_l_init\n"],"metadata":{"id":"vjPrH-wRncpZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","from torch_geometric.typing import Adj, OptPairTensor, Size, SparseTensor\n","import torch\n","import torch.nn as nn\n","import matrix_util as Mat_Util\n","import Batched_GraphSage_Layer as batched_graphsage_layer\n","class Batched_DiffPool_Embedding_Layer(nn.Module):\n","    '''\n","   #     Z, new features size\n","    '''\n","    def __init__(self, input_dim, embedding_num_block_layers, hid_dim, embedded_dim, Bias, normalize_graphsage, dropout,\n","                 aggregation, concat):\n","        super(Batched_DiffPool_Embedding_Layer, self).__init__()\n","        self.input_dim = input_dim\n","        self.embedding_num_block_layers = embedding_num_block_layers\n","        self.hid_dim = hid_dim\n","        self.embedded_dim = embedded_dim\n","        self.Bias = Bias\n","        self.normalize_graphsage = normalize_graphsage\n","        self.dropout = dropout\n","        self.aggregation = aggregation\n","        self.act_fun = F.relu\n","        self.concat = concat\n","\n","\n","        self.DiffPool_Embedding = nn.ModuleList()\n","\n","        if self.concat:\n","            self.hid_dim = 2*self.hid_dim\n","\n","        self.DiffPool_Embedding.append(GNN_Batched_GraphSage_Layer(input_dim=self.input_dim, output_dim=self.hid_dim,\n","                                                                                           Bias=self.Bias, normalize_graphsage=self.normalize_graphsage,\n","                                                                                           dropout=self.dropout, aggregation=self.aggregation, concat=self.concat))\n","\n","\n","        for i in range(embedding_num_block_layers):\n","            self.DiffPool_Embedding.append(GNN_Batched_GraphSage_Layer(input_dim=self.hid_dim, output_dim=self.hid_dim,\n","                                                                                               Bias=self.Bias, normalize_graphsage=self.normalize_graphsage,\n","                                                                                               dropout=self.dropout, aggregation=self.aggregation, concat=self.concat))\n","\n","        self.DiffPool_Embedding.append(GNN_Batched_GraphSage_Layer(input_dim=self.hid_dim, output_dim=self.embedded_dim,\n","                                                                                           Bias=self.Bias, normalize_graphsage=self.normalize_graphsage,\n","                                                                                           dropout=self.dropout, aggregation=self.aggregation, concat=self.concat))\n","\n","\n","\n","    def forward(self, input_tensor, tilda_adjacency_matrix):\n","\n","        for layer in self.DiffPool_Embedding:\n","            input_tensor = self.act_fun(layer(input_tensor, tilda_adjacency_matrix))\n","\n","        return input_tensor\n"],"metadata":{"id":"0cDYFIM8lqAJ","executionInfo":{"status":"ok","timestamp":1694871945535,"user_tz":-120,"elapsed":713,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["diffpool_embedding_example = Batched_DiffPool_Embedding_Layer(input_dim=7, embedding_num_block_layers=1, hid_dim=7, embedded_dim=7, Bias=True,\n","                                                              normalize_graphsage=True, dropout=0, aggregation=\"mean\", concat=True)"],"metadata":{"id":"oHW0COZ1TCPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import binascii\n","\n","class DiffPool_Assignment_Layer(nn.Module):\n","    '''\n","    #    S, new clusters, new number of nodes\n","    '''\n","    def __init__(self, input_dim_size, new_num_nodes, Bias, normalize_embedding, dropout, aggregation):\n","        super(DiffPool_Assignment_Layer, self).__init__()\n","        self.input_dim_size = input_dim_size\n","        self.new_num_nodes = new_num_nodes\n","        self.Bias = Bias\n","        self.normalize_embedding = normalize_embedding\n","        self.dropout = dropout\n","        self.aggregation = aggregation\n","        self.assinment_layer = GNN_GraphSage_Layer(input_dim=self.input_dim_size, output_dim=self.new_num_nodes, Bias=self.Bias, normalize_embedding=self.normalize_embedding, dropout=self.dropout, aggregation=self.aggregation)\n","        #self.assinment_layer = GNN_Batched_GraphSage_Layer(input_dim=self.input_dim_size, output_dim=self.new_num_nodes, Bias=self.Bias, normalize_embedding=self.normalize_embedding, dropout=self.dropout, aggregation=self.aggregation)\n","        self.act_fun = F.relu\n","\n","    def forward(self, input_tensor, tilda_adjacency_matrix):\n","        #x, edge_index, batch, y = batched_graph.x, batched_graph.edge_index, batched_graph.batch, batched_graph.y\n","        s_l_init = self.assinment_layer(input_tensor, tilda_adjacency_matrix)\n","        s_l_init = self.act_fun(s_l_init)\n","\n","        s_l = F.softmax(s_l_init, dim=-1)\n","\n","        return s_l\n"],"metadata":{"id":"lZa_8jjctleJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","from torch_geometric.typing import Adj, OptPairTensor, Size, SparseTensor\n","import torch\n","import torch.nn as nn\n","import matrix_util as Mat_Util\n","import Batched_GraphSage_Layer as batched_graphsage_layer\n","class Batched_DiffPool_Assignment_Layer(nn.Module):\n","    '''\n","    #    S, new clusters, new number of nodes\n","    '''\n","    def __init__(self, input_dim, assignment_num_block_layers, hid_dim, assigned_dim, Bias, normalize_graphsage, dropout,\n","                 aggregation, concat):\n","        super(Batched_DiffPool_Assignment_Layer, self).__init__()\n","        self.input_dim = input_dim\n","        self.assignment_num_block_layers = assignment_num_block_layers\n","        self.hid_dim = hid_dim\n","        self.assigned_dim = assigned_dim\n","        self.assignment_prediction_layer_input_dim = assigned_dim\n","        #########################################################.  General Parameters\n","        self.Bias = Bias\n","        self.normalize_graphsage = normalize_graphsage\n","        self.dropout = dropout\n","        self.aggregation = aggregation\n","        self.act_fun = F.relu\n","        self.concat=concat\n","\n","        self.diffPool_assignment = nn.ModuleList()\n","\n","        self.diffPool_assignment.append(GNN_Batched_GraphSage_Layer(input_dim=self.input_dim, output_dim=self.hid_dim,\n","                                                                                            Bias=self.Bias, normalize_graphsage=self.normalize_graphsage,\n","                                                                                            dropout=self.dropout, aggregation=self.aggregation, concat=self.concat))\n","\n","        for i in range(assignment_num_block_layers):\n","            self.diffPool_assignment.append(GNN_Batched_GraphSage_Layer(input_dim=self.hid_dim, output_dim=self.hid_dim,\n","                                                                                                Bias=self.Bias, normalize_graphsage=self.normalize_graphsage,\n","                                                                                                dropout=self.dropout, aggregation=self.aggregation, concat=self.concat))\n","\n","        self.diffPool_assignment.append(GNN_Batched_GraphSage_Layer(input_dim=self.hid_dim, output_dim=self.assigned_dim,\n","                                                                                            Bias=self.Bias, normalize_graphsage=self.normalize_graphsage,\n","                                                                                            dropout=self.dropout, aggregation=self.aggregation, concat=self.concat))\n","\n","\n","    def forward(self, input_tensor, tilda_adjacency_matrix):\n","\n","        for layer in self.diffPool_assignment:\n","            input_tensor = self.act_fun(layer(input_tensor, tilda_adjacency_matrix))\n","\n","        dense_prediction = F.softmax(input_tensor, dim=-1)\n","\n","        return dense_prediction\n"],"metadata":{"id":"9HLZ0QnKlwTF","executionInfo":{"status":"ok","timestamp":1694871950001,"user_tz":-120,"elapsed":220,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","class DiffPool_Layer(nn.Module):\n","    def __init__(self, input_dim_size, new_feat_dim_size, new_num_nodes, Bias, normalize_graphsage, dropout, aggregation):\n","        super(DiffPool_Layer, self).__init__()\n","        self.input_dim_size = input_dim_size\n","        self.new_feat_dim_size = new_feat_dim_size\n","        self.new_num_nodes = new_num_nodes\n","        self.Bias = Bias\n","        self.normalize_graphsage = normalize_graphsage\n","        self.dropout = dropout\n","        self.aggregation = aggregation\n","\n","        self.new_embed = DiffPool_Embedding_Layer(input_dim_size=input_dim_size, new_feat_dim_size=new_feat_dim_size, Bias=self.Bias, normalize_graphsage=self.normalize_graphsage, dropout=self.dropout, aggregation=self.aggregation)\n","        self.new_assign = DiffPool_Assignment_Layer(input_dim_size=self.input_dim_size, new_num_nodes=self.new_num_nodes, Bias=self.Bias , normalize_graphsage=self.normalize_graphsage , dropout=self.dropout, aggregation=self.aggregation)\n","\n","\n","    def forward(self, input_tensor, tilda_adjacency_matrix):\n","        #x, edge_index, batch, y = batched_graph.x, batched_graph.edge_index, batched_graph.batch, batched_graph.y\n","\n","        z_l = self.new_embed(input_tensor, tilda_adjacency_matrix)\n","        s_l = self.new_assign(input_tensor, tilda_adjacency_matrix)\n","\n","        new_X = torch.mm(s_l.transpose(-1, -2), z_l)\n","        new_adjacency = (s_l.transpose(-1, -2)).mm(tilda_adjacency_matrix).mm(s_l)\n","\n","        return new_X, new_adjacency\n"],"metadata":{"id":"qZ4_Zx1Bnm21"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","from torch_geometric.typing import Adj, OptPairTensor, Size, SparseTensor\n","import torch\n","import torch.nn as nn\n","import matrix_util as Mat_Util\n","import Batched_DIFFPOOL_Assignment as batched_diffpool_assignment\n","import Batched_DIFFPOOL_Embedding as batched_diffpool_embedding\n","class Batched_DiffPool_Layer(nn.Module):\n","    def __init__(self, embedding_input_dim, embedding_num_block_layers, embedding_hid_dim, embedding_output_dim, assignment_input_dim,\n","                 assignment_num_block_layers, assignment_hid_dim, assignment_output_dim, concat, Weight_Initializer, Bias,\n","                 dropout_rate, normalize_graphsage, aggregation, act_fun):\n","        super(Batched_DiffPool_Layer, self).__init__()\n","        ################################################.  General Parameters\n","        self.Bias = Bias\n","        self.dropout_rate = dropout_rate\n","        self.aggregation = aggregation\n","        self.Weight_Initializer = Weight_Initializer\n","        self.concat = concat\n","        self.normalize_graphsage = normalize_graphsage\n","\n","        ################################################.  Embedding and Assignment\n","\n","        self.embedding_input_dim = embedding_input_dim\n","        self.embedding_num_block_layers = embedding_num_block_layers\n","        self.embedding_hid_dim = embedding_hid_dim\n","        self.embedding_output_dim = embedding_output_dim\n","\n","        self.assignment_input_dim = assignment_input_dim\n","        self.assignment_num_block_layers = assignment_num_block_layers\n","        self.assignment_hid_dim = assignment_hid_dim\n","        self.assignment_output_dim = assignment_output_dim      # new number of nodes\n","\n","        ################################################.  Embedding\n","        self.diffpool_embedding = Batched_DiffPool_Embedding_Layer(input_dim=self.embedding_input_dim,\n","                                                                                              embedding_num_block_layers=self.embedding_num_block_layers,\n","                                                                                              hid_dim=self.embedding_hid_dim,\n","                                                                                              embedded_dim=self.embedding_output_dim,\n","                                                                                              concat=self.concat,Bias=self.Bias,\n","                                                                                              normalize_graphsage=self.normalize_graphsage,\n","                                                                                              dropout=self.dropout_rate,\n","                                                                                              aggregation=self.aggregation)\n","\n","        ################################################.  Assignment\n","        self.diffpool_assignment = Batched_DiffPool_Assignment_Layer(input_dim=self.assignment_input_dim,\n","                                                                                                 assignment_num_block_layers=self.assignment_num_block_layers,\n","                                                                                                 hid_dim=self.assignment_hid_dim,\n","                                                                                                 assigned_dim=self.assignment_output_dim,\n","                                                                                                 concat=self.concat, Bias=self.Bias,\n","                                                                                                 normalize_graphsage=self.normalize_graphsage,\n","                                                                                                 dropout=self.dropout_rate,\n","                                                                                                 aggregation=self.aggregation)\n","    def forward(self, features, adjacecny):\n","        features = features.to(torch.float32)\n","\n","        embedding_output = self.diffpool_embedding(features, adjacecny)\n","\n","        assignment_output = self.diffpool_assignment(features, adjacecny)\n","\n","        #features = torch.matmul(torch.transpose(assignment_output, 1, 2), embedding_output)\n","        #adjacecny = torch.transpose(assignment_output, 1, 2) @ adjacecny @ assignment_output\n","\n","\n","\n","        return embedding_output, assignment_output\n"],"metadata":{"id":"lBUfixvNl4fM","executionInfo":{"status":"ok","timestamp":1694871954767,"user_tz":-120,"elapsed":664,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["batched_diffpool_layer_example = Batched_DiffPool_Layer(embedding_input_dim=7, embedding_num_block_layers=1, embedding_hid_dim=7, embedding_output_dim=7,\n","                                                        assignment_input_dim=7, assignment_num_block_layers=1, assignment_hid_dim=7,\n","                                                        assignment_output_dim=7, Weight_Initializer=1, Bias=True, dropout_rate=0,\n","                                                        normalize_graphsage=True, concat=True, aggregation='mean', act_fun='ReLu')"],"metadata":{"id":"UCsN_tDb_MQE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch_geometric.loader import DataLoader\n","batched_dataset = DataLoader(dataset, batch_size=30, shuffle=False)\n","for batched_graph in batched_dataset:\n","    x, edge_index, batch, y = batched_graph.x, batched_graph.edge_index, batched_graph.batch, batched_graph.y\n","\n","    new_X, new_adjacency = batched_diffpool_layer_example(batched_graph, None)\n","    print(\"softmaxed_output: \", new_X.size())\n","    print(\"softmaxed_output: \", new_adjacency.size())\n","    break"],"metadata":{"id":"Mll4CF45_iBj","colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"status":"error","timestamp":1689686820433,"user_tz":-120,"elapsed":215,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"740287b8-f718-4edc-9543-68e3064c6792"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-d940c8b47979>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnew_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_adjacency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_diffpool_layer_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmaxed_output: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmaxed_output: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_adjacency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-3d39ac1bf7e7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, adjacecny)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                                                                                  aggregation=self.aggregation)\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjacecny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffpool_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjacecny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    294\u001b[0m         r\"\"\"Performs tensor device conversion, either for all attributes or\n\u001b[1;32m    295\u001b[0m         only the ones given in :obj:`*args`.\"\"\"\n\u001b[0;32m--> 296\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    297\u001b[0m             lambda x: x.to(device=device, non_blocking=non_blocking), *args)\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    277\u001b[0m         the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    184\u001b[0m         the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    295\u001b[0m         only the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    296\u001b[0m         return self.apply(\n\u001b[0;32m--> 297\u001b[0;31m             lambda x: x.to(device=device, non_blocking=non_blocking), *args)\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: to() received an invalid combination of arguments - got (non_blocking=bool, device=torch.dtype, ), but expected one of:\n * (torch.device device, torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (Tensor tensor, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n"]}]},{"cell_type":"code","source":["drive.mount('/content/drive/',force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3FtxgK9wDdXs","executionInfo":{"status":"ok","timestamp":1677975067892,"user_tz":-60,"elapsed":3167,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"9fc6e728-2100-4796-ac69-742e7a6284ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["from termcolor import colored"],"metadata":{"id":"T3nfDrVVfte8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch_geometric.utils import dropout\n","from torch_geometric.loader import DataLoader\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import math\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","from torch_geometric.utils.convert import to_scipy_sparse_matrix\n","from torch_geometric.utils.train_test_split_edges import torch_geometric\n","import networkx as nx\n","import numpy as np\n","from torch_geometric.nn import GCNConv\n","import sys\n","from torch_geometric.datasets import TUDataset\n","from scipy.sparse import csr_matrix\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","import Batched_GraphSage_Layer as batched_graphsage_layer\n","import Batched_DIFFPOOL_Assignment as batched_diffpool_assignment\n","import Batched_DIFFPOOL_Embedding as batched_diffpool_embedding\n","import Batched_DIFFPOOL_Layer as batched_diffpool_layer\n","\n","\n","\n","class GlobalMeanPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return gnn.global_mean_pool(x, batch)\n","################################################################################\n","class IdenticalPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return x\n","\n","################################################################################\n","class DIFFPOOL_Model(nn.Module):\n","    '''\n","        DIFFPOOL Mode\n","    '''\n","    def __init__(self, embedding_input_dim, embedding_num_block_layers, embedding_hid_dim, new_feature_size, assignment_input_dim,\n","                 assignment_num_block_layers, assignment_hid_dim, max_number_of_nodes, concat_neighborhood, prediction_hid_layers,\n","                 num_classes, Weight_Initializer, Bias, dropout_rate, normalize_graphsage, aggregation, act_fun,\n","                 concat_diffpools_outputs, num_pooling, pooling):\n","\n","        super(DIFFPOOL_Model, self).__init__()\n","        self.Bias = Bias\n","        self.dropout_rate = dropout_rate\n","        self.aggregation = aggregation\n","        self.act_fun = act_fun\n","        self.Weight_Initializer = Weight_Initializer\n","        self.concat_diffpools_outputs = concat_diffpools_outputs\n","        self.num_pooling = num_pooling\n","        self.concat = concat_neighborhood\n","        self.pooling = pooling\n","\n","\n","        self.embedding_input_dim = embedding_input_dim\n","        self.embedding_num_block_layers = embedding_num_block_layers\n","        self.embedding_hid_dim = embedding_hid_dim\n","        self.embedding_output_dim = new_feature_size\n","        self.normalize_graphsage = normalize_graphsage\n","\n","        self.assignment_input_dim = assignment_input_dim\n","        self.assignment_num_block_layers = assignment_num_block_layers\n","        self.assignment_hid_dim = assignment_hid_dim\n","        self.max_number_of_nodes = max_number_of_nodes\n","        self.assignment_output_dim = int(self.max_number_of_nodes * 0.25)\n","\n","\n","        prediction_input_dim_sum = 0\n","\n","        ###################################################.    DiffPool Layers\n","        diffpool_layers = []\n","        for i in range(self.num_pooling):\n","            diffpool_layers.append(Batched_DiffPool_Layer(embedding_input_dim=self.embedding_input_dim,\n","                                                                                 embedding_num_block_layers=self.embedding_num_block_layers,\n","                                                                                 embedding_hid_dim=self.embedding_hid_dim,\n","                                                                                 embedding_output_dim=self.embedding_output_dim,\n","                                                                                 assignment_input_dim=self.assignment_input_dim,\n","                                                                                 assignment_num_block_layers=self.assignment_num_block_layers,\n","                                                                                 assignment_hid_dim=self.assignment_hid_dim,\n","                                                                                 assignment_output_dim=self.assignment_output_dim,\n","                                                                                 concat=self.concat, Weight_Initializer=self.Weight_Initializer,\n","                                                                                 Bias=self.Bias, dropout_rate=self.dropout_rate,\n","                                                                                 normalize_graphsage=self.normalize_graphsage,\n","                                                                                 aggregation=self.aggregation, act_fun=self.act_fun))\n","\n","            self.assignment_output_dim = int(self.assignment_output_dim * .25)\n","            self.embedding_input_dim = self.embedding_output_dim\n","            self.assignment_input_dim = self.embedding_output_dim\n","            prediction_input_dim_sum = prediction_input_dim_sum + self.embedding_output_dim\n","        self.diffpool_layers = nn.Sequential(*diffpool_layers)\n","\n","        ###################################################.    Last Extra Embedding\n","\n","        self.last_extra_embedding = Batched_DiffPool_Embedding_Layer(input_dim=self.embedding_output_dim,\n","                                                                                                embedding_num_block_layers=self.embedding_num_block_layers,\n","                                                                                                hid_dim=self.embedding_hid_dim, concat=self.concat,\n","                                                                                                embedded_dim=self.embedding_output_dim, Bias=self.Bias,\n","                                                                                                normalize_graphsage=self.normalize_graphsage, dropout=self.dropout_rate,\n","                                                                                                aggregation=self.aggregation)\n","        prediction_input_dim_sum = prediction_input_dim_sum + self.embedding_output_dim\n","\n","        ###################################################.    Predictions\n","        self.prediction_input_dim = self.embedding_output_dim\n","        self.prediction_hid_layers = prediction_hid_layers\n","        self.num_classes = num_classes\n","\n","        prediction_layers = []\n","        if len(self.prediction_hid_layers) == 0:\n","            if self.concat_diffpools_outputs:\n","                prediction_layers.append(nn.Linear(prediction_input_dim_sum, self.num_classes))\n","                self.prediction_model = nn.Sequential(*prediction_layers)\n","            else:\n","                prediction_layers.append(nn.Linear(self.prediction_input_dim, self.num_classes))\n","                self.prediction_model = nn.Sequential(*prediction_layers)\n","        else:\n","            if self.concat_diffpools_outputs:\n","                predict_input_dim = prediction_input_dim_sum\n","                for i in range(len(self.prediction_hid_layers)):\n","                    prediction_layers.append(nn.Linear(predict_input_dim, prediction_hid_layers[i]))\n","                    predict_input_dim = prediction_hid_layers[i]\n","                prediction_layers.append(nn.Linear(predict_input_dim, self.num_classes))\n","                self.prediction_model = nn.Sequential(*prediction_layers)\n","            else:\n","                predict_input_dim = self.prediction_input_dim\n","                for i in range(len(self.prediction_hid_layers)):\n","                    prediction_layers.append(nn.Linear(predict_input_dim, prediction_hid_layers[i]))\n","                    predict_input_dim = prediction_hid_layers[i]\n","                prediction_layers.append(nn.Linear(predict_input_dim, self.num_classes))\n","                self.prediction_model = nn.Sequential(*prediction_layers)\n","\n","        if act_fun == 'ReLu':\n","            self.act_fun = F.relu\n","            print('ReLu is Selected.')\n","        elif act_fun == 'eLu':\n","            self.act_fun = nn.functional.elu\n","            print('eLu is Selected.')\n","        elif act_fun == 'tanh':\n","            self.act_fun = torch.tanh\n","            print('tanh is Selected.')\n","        self.act_fun_softmax = F.softmax\n","\n","        mean = 0\n","        std = 0.1\n","        self.initialize_weights(Weight_Initializer, Bias, mean, std)\n","\n","    def initialize_weights(model, Weight_Initializer, Bias, mean, std):\n","        # 1. Xavier Normal_.  2. Kaiming Normal_.  3. Uniform (0,0.1std)\n","\n","        if Weight_Initializer == 1:                                             #.      1. Xavier Normal_.\n","            for i, module in enumerate(model.children()):\n","                #print(i, module)\n","                if isinstance(module, torch.nn.Sequential):\n","                    for j, module_sub in enumerate(module):\n","                        #print(\"j: \",j,module_sub)\n","                        if isinstance(module_sub, batched_diffpool_layer.Batched_DiffPool_Layer):\n","                            #print(module_sub)\n","                            for party in module_sub.children():\n","                                if isinstance(party, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                                    for diff_embd_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_embd_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_embed_party_in_modulelist in diff_embd_party.children():\n","                                                if isinstance(diff_embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.xavier_normal_(diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    #torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_embed_party_in_modulelist.learnable_weights.weight: \",diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                elif isinstance(party, batched_diffpool_assignment.Batched_DiffPool_Assignment_Layer):\n","                                    for diff_assign_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_assign_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_assign_party_in_modulelist in diff_assign_party.children():\n","                                                if isinstance(diff_assign_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.xavier_normal_(diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_assign_party_in_modulelist.learnable_weights.weight: \",diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                        elif isinstance(diff_assign_party, torch.nn.Sequential):\n","                                            for diff_assign_party_in_sequential in diff_assign_party:\n","                                                if isinstance(diff_assign_party_in_sequential, torch.nn.Linear):\n","                                                    torch.nn.init.xavier_normal_(diff_assign_party_in_sequential.weight)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_sequential.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_sequential.bias)\n","                                                        #print(diff_assign_party_in_sequential.bias)\n","                        elif isinstance(module_sub, torch.nn.Linear):\n","                            #print(\"linear final prediction layers\")\n","                            torch.nn.init.xavier_normal_(module_sub.weight)\n","                            if Bias:\n","                                torch.nn.init.zeros_(module_sub.bias)\n","                                #print(module_sub.bias)\n","                elif isinstance(module, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                    for embd_party in module.children():\n","                        #print(\"embd_party: \")#, embd_party)\n","                        if isinstance(embd_party, torch.nn.ModuleList):\n","                            for embed_party_in_modulelist in embd_party.children():\n","                                if isinstance(embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                    torch.nn.init.xavier_normal_(embed_party_in_modulelist.learnable_weights.weight)\n","                                    #torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.weight)\n","                                    #print(\"embed_party_in_modulelist.learnable_weights.weight: \",embed_party_in_modulelist.learnable_weights.weight)\n","                                    if Bias:\n","                                        torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.bias)\n","                                        #print(embed_party_in_modulelist.learnable_weights.bias)\n","\n","        if Weight_Initializer == 2:                                             #.      1. Kaiming Normal_.\n","            for i, module in enumerate(model.children()):\n","                #print(i, module)\n","                if isinstance(module, torch.nn.Sequential):\n","                    for j, module_sub in enumerate(module):\n","                        #print(\"j: \",j,module_sub)\n","                        if isinstance(module_sub, batched_diffpool_layer.Batched_DiffPool_Layer):\n","                            #print(module_sub)\n","                            for party in module_sub.children():\n","                                if isinstance(party, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                                    for diff_embd_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_embd_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_embed_party_in_modulelist in diff_embd_party.children():\n","                                                if isinstance(diff_embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.kaiming_normal_(diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    #torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_embed_party_in_modulelist.learnable_weights.weight: \",diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                elif isinstance(party, batched_diffpool_assignment.Batched_DiffPool_Assignment_Layer):\n","                                    for diff_assign_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_assign_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_assign_party_in_modulelist in diff_assign_party.children():\n","                                                if isinstance(diff_assign_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.kaiming_normal_(diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_assign_party_in_modulelist.learnable_weights.weight: \",diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                        elif isinstance(diff_assign_party, torch.nn.Sequential):\n","                                            for diff_assign_party_in_sequential in diff_assign_party:\n","                                                if isinstance(diff_assign_party_in_sequential, torch.nn.Linear):\n","                                                    torch.nn.init.kaiming_normal_(diff_assign_party_in_sequential.weight)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_sequential.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_sequential.bias)\n","                                                        #print(diff_assign_party_in_sequential.bias)\n","                        elif isinstance(module_sub, torch.nn.Linear):\n","                            #print(\"linear final prediction layers\")\n","                            torch.nn.init.kaiming_normal_(module_sub.weight)\n","                            if Bias:\n","                                torch.nn.init.zeros_(module_sub.bias)\n","                                #print(module_sub.bias)\n","                elif isinstance(module, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                    for embd_party in module.children():\n","                        #print(\"embd_party: \")#, embd_party)\n","                        if isinstance(embd_party, torch.nn.ModuleList):\n","                            for embed_party_in_modulelist in embd_party.children():\n","                                if isinstance(embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                    torch.nn.init.kaiming_normal_(embed_party_in_modulelist.learnable_weights.weight)\n","                                    #torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.weight)\n","                                    #print(\"embed_party_in_modulelist.learnable_weights.weight: \",embed_party_in_modulelist.learnable_weights.weight)\n","                                    if Bias:\n","                                        torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.bias)\n","                                        #print(embed_party_in_modulelist.learnable_weights.bias)\n","\n","        if Weight_Initializer == 3:                                             #.      3. Uniform (0,0.1std)\n","            for i, module in enumerate(model.children()):\n","                #print(i, module)\n","                if isinstance(module, torch.nn.Sequential):\n","                    for j, module_sub in enumerate(module):\n","                        #print(\"j: \",j,module_sub)\n","                        if isinstance(module_sub, batched_diffpool_layer.Batched_DiffPool_Layer):\n","                            #print(module_sub)\n","                            for party in module_sub.children():\n","                                if isinstance(party, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                                    for diff_embd_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_embd_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_embed_party_in_modulelist in diff_embd_party.children():\n","                                                if isinstance(diff_embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.normal_(diff_embed_party_in_modulelist.learnable_weights.weight, mean=mean, std=std)\n","                                                    #torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_embed_party_in_modulelist.learnable_weights.weight: \",diff_embed_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_embed_party_in_modulelist.learnable_weights.bias)\n","                                elif isinstance(party, batched_diffpool_assignment.Batched_DiffPool_Assignment_Layer):\n","                                    for diff_assign_party in party.children():\n","                                        #print(\"diff_embd_party: \")#, diff_embd_party)\n","                                        if isinstance(diff_assign_party, torch.nn.ModuleList):\n","                                            #print(\"moduel list for diffpool embed\")\n","                                            for diff_assign_party_in_modulelist in diff_assign_party.children():\n","                                                if isinstance(diff_assign_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                                    torch.nn.init.normal_(diff_assign_party_in_modulelist.learnable_weights.weight, mean=mean, std=std)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    #print(\"diff_assign_party_in_modulelist.learnable_weights.weight: \",diff_assign_party_in_modulelist.learnable_weights.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                                        #print(diff_assign_party_in_modulelist.learnable_weights.bias)\n","                                        elif isinstance(diff_assign_party, torch.nn.Sequential):\n","                                            for diff_assign_party_in_sequential in diff_assign_party:\n","                                                if isinstance(diff_assign_party_in_sequential, torch.nn.Linear):\n","                                                    torch.nn.init.normal_(diff_assign_party_in_sequential.weight, mean=mean, std=std)\n","                                                    #torch.nn.init.zeros_(diff_assign_party_in_sequential.weight)\n","                                                    if Bias:\n","                                                        torch.nn.init.zeros_(diff_assign_party_in_sequential.bias)\n","                                                        #print(diff_assign_party_in_sequential.bias)\n","                        elif isinstance(module_sub, torch.nn.Linear):\n","                            #print(\"linear final prediction layers\")\n","                            torch.nn.init.normal_(module_sub.weight, mean=mean, std=std)\n","                            if Bias:\n","                                torch.nn.init.zeros_(module_sub.bias)\n","                                #print(module_sub.bias)\n","                elif isinstance(module, batched_diffpool_embedding.Batched_DiffPool_Embedding_Layer):\n","                    for embd_party in module.children():\n","                        #print(\"embd_party: \")#, embd_party)\n","                        if isinstance(embd_party, torch.nn.ModuleList):\n","                            for embed_party_in_modulelist in embd_party.children():\n","                                if isinstance(embed_party_in_modulelist, batched_graphsage_layer.GNN_Batched_GraphSage_Layer):\n","                                    torch.nn.init.normal_(embed_party_in_modulelist.learnable_weights.weight, mean=mean, std=std)\n","                                    #torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.weight)\n","                                    #print(\"embed_party_in_modulelist.learnable_weights.weight: \",embed_party_in_modulelist.learnable_weights.weight)\n","                                    if Bias:\n","                                        torch.nn.init.zeros_(embed_party_in_modulelist.learnable_weights.bias)\n","                                        #print(embed_party_in_modulelist.learnable_weights.bias)\n","\n","\n","\n","\n","\n","\n","\n","    def computational_matricess(self, batched_graphs, edge_mask):\n","        if edge_mask == None:\n","            joint_tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())))\n","        else:\n","            joint_tilda_adjacency_matrix = torch.tensor(csr_matrix((np.array(edge_mask), (np.array(batched_graphs.edge_index[0]), np.array(batched_graphs.edge_index[1])))).todense())\n","\n","        joint_tilda_adjacency_matrix = joint_tilda_adjacency_matrix.type(torch.float32)\n","        #batch_size = batched_graphs.num_graphs\n","\n","\n","        if batched_graphs.batch is not None:\n","            graph_sizes = [len(batched_graphs[i].x) for i in range(len(batched_graphs))]\n","            batch_size = batched_graphs.num_graphs\n","        else:\n","            graph_sizes = [len(batched_graphs.x)]\n","            batch_size = 1\n","        max_number_of_nodes_in_batch_of_graphs = max(graph_sizes)\n","        #print(\"max_number_of_nodes_in_batch_of_graphs: \", max_number_of_nodes_in_batch_of_graphs)\n","\n","\n","        new_number_of_nodes = int(joint_tilda_adjacency_matrix.size()[0] / batch_size)\n","\n","        adjacency_list = []\n","        feature_list = []\n","        for i in range(batch_size):\n","            start = i * graph_sizes[i]\n","            end = (i + 1) * graph_sizes[i]\n","            un_padded_adj = joint_tilda_adjacency_matrix[start:end, start:end]\n","            off_set = max_number_of_nodes_in_batch_of_graphs - un_padded_adj.size()[0]\n","            if un_padded_adj.size()[0] < max_number_of_nodes_in_batch_of_graphs:\n","                un_padded_adj = un_padded_adj.numpy()\n","                un_padded_adj = np.pad(un_padded_adj, [(0, off_set), (0, off_set)], mode='constant', constant_values=np.zeros(1,dtype=np.float32))\n","                un_padded_adj = torch.from_numpy(un_padded_adj)\n","            un_padded_adj = un_padded_adj.type(torch.float32)\n","            adjacency_list.append(un_padded_adj)\n","\n","            un_padded_feat = batched_graphs.x[start:end, :].numpy()\n","            un_padded_feat = torch.from_numpy(np.pad(un_padded_feat, [(0, off_set), (0, 0)], mode='constant', constant_values=np.zeros(1,dtype=np.float32)))\n","            feature_list.append(un_padded_feat)\n","\n","\n","        adjacency_list = list(map(lambda x: torch.unsqueeze(x, 0), adjacency_list))\n","        feature_list = list(map(lambda x: torch.unsqueeze(x, 0), feature_list))\n","\n","        new_adjacecny = torch.cat(adjacency_list, dim=0)\n","        new_features = torch.cat(feature_list, dim=0)\n","\n","\n","\n","        return new_adjacecny, new_features\n","\n","    def forward(self, batched_graphs, edge_mask):\n","        adjacecny, features = self.computational_matricess(batched_graphs, edge_mask)\n","        #print(adjacecny.size())\n","        concatination_list_of_poolings = []\n","\n","        for i in range(self.num_pooling):\n","            embedding_output, assignment_output = self.diffpool_layers[i](features, adjacecny)\n","            #features = torch.matmul(torch.transpose(assignment_output, 1, 2), embedding_output)\n","            features = torch.bmm(torch.transpose(assignment_output, 1, 2), embedding_output)\n","            adjacecny = torch.transpose(assignment_output, 1, 2) @ adjacecny @ assignment_output\n","\n","\n","            if self.pooling == \"max\":\n","                embedding_output_pooled, _ = torch.max(embedding_output, dim=1)\n","            elif self.pooling == \"mean\":\n","                embedding_output_pooled = torch.mean(embedding_output, dim=1)\n","            elif self.pooling == \"sum\":\n","                embedding_output_pooled = torch.sum(embedding_output, dim=1)\n","            concatination_list_of_poolings.append(embedding_output_pooled)\n","\n","\n","        extra_embed = self.last_extra_embedding(features, adjacecny)\n","        if self.pooling == \"max\":\n","            extra_embed_pooled, _ = torch.max(extra_embed, dim=1)\n","        elif self.pooling == \"mean\":\n","            extra_embed_pooled = torch.mean(extra_embed, dim=1)\n","        elif self.pooling == \"sum\":\n","            extra_embed_pooled = torch.sum(extra_embed, dim=1)\n","        concatination_list_of_poolings.append(extra_embed_pooled)\n","\n","        if self.concat_diffpools_outputs:\n","            output = torch.cat(concatination_list_of_poolings, dim=1)\n","        else:\n","            output = extra_embed_pooled\n","\n","        prediction_output = output\n","        for i in range(len(self.prediction_hid_layers)):\n","\n","            prediction_output = self.act_fun(self.prediction_model[i](prediction_output))\n","        prediction_output = F.softmax(self.prediction_model[-1](prediction_output), dim=-1)\n","\n","\n","\n","        return concatination_list_of_poolings, prediction_output\n","\n","\n","\n","\n","dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n","sum=0\n","length_list = []\n","for i in range(len(dataset)):\n","    sum = sum + len(dataset[i].x)\n","    length_list.append(len(dataset[i].x))\n","\n","#print(\"max number of nodes in graphs: \", max(length_list))\n","batch_size = 10\n","\n","\n","node_feat_size = len(dataset[0].x[0])\n","\n","hid_dim = 7\n","\n","diffpool_model_example = DIFFPOOL_Model(embedding_input_dim=7, embedding_num_block_layers=1, embedding_hid_dim=64, new_feature_size=64,\n","                                    assignment_input_dim=7, assignment_num_block_layers=1, assignment_hid_dim=64, max_number_of_nodes=256,\n","                                    prediction_hid_layers=[50], concat_neighborhood=False, num_classes=2, Weight_Initializer=3,\n","                                    Bias=True, dropout_rate=0, normalize_graphsage=False, aggregation=\"mean\",\n","                                    act_fun=\"ReLu\", concat_diffpools_outputs=True, num_pooling=1, pooling=\"max\")\n","#print(diffpool_model_example)\n","batched_dataset = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","\n","for batched_graph in batched_dataset:\n","    x, edge_index, batch, y = batched_graph.x, batched_graph.edge_index, batched_graph.batch, batched_graph.y\n","    concatination_list_of_poolings, prediction_output = diffpool_model_example(batched_graph, None)\n","    print(\"Final Output: \", prediction_output)\n","    #print(\"concatination_list_of_poolings: \", concatination_list_of_poolings)\n","    break\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OjaXBTSXO85P","executionInfo":{"status":"ok","timestamp":1694880559704,"user_tz":-120,"elapsed":376,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"bbc209f5-a239-4bf1-a091-f685c957a706"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["ReLu is Selected.\n","Final Output:  tensor([[0.5171, 0.4829],\n","        [0.5177, 0.4823],\n","        [0.5178, 0.4822],\n","        [0.5187, 0.4813],\n","        [0.5155, 0.4845],\n","        [0.5178, 0.4822],\n","        [0.5188, 0.4812],\n","        [0.5180, 0.4820],\n","        [0.5190, 0.4810],\n","        [0.5177, 0.4823]], grad_fn=<SoftmaxBackward0>)\n"]}]},{"cell_type":"code","source":["for batched_graph in batched_dataset:\n","    x, edge_index, batch, y = batched_graph.x, batched_graph.edge_index, batched_graph.batch, batched_graph.y\n","    tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graph.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graph.edge_index).todense())))\n","    #print(\"tilda_adjacency_matrix: \", tilda_adjacency_matrix.size())\n","    gnn_sage1_output = diffpool_model_example(batched_graph, None)\n","    #print(\"gnn_sage1_output: \", gnn_sage1_output.size())\n","    print(gnn_sage1_output)\n","    #break"],"metadata":{"id":"BxCgTV56GHY0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694880564017,"user_tz":-120,"elapsed":369,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"2e5e1594-0858-4a57-ab92-79261a593015"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["([tensor([[0.0816, 0.0000, 0.0591, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0518, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1304, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0149, 0.0250, 0.1109, 0.0662, 0.2061, 0.0000, 0.0399,\n","         0.1673, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0366, 0.0000, 0.1946, 0.0000, 0.0113, 0.0000, 0.0399, 0.0000,\n","         0.0000, 0.0000, 0.2024, 0.0000, 0.0000, 0.0852, 0.0000, 0.1726, 0.1025,\n","         0.1216],\n","        [0.0845, 0.0000, 0.0559, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0510, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1260, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0170, 0.0224, 0.1109, 0.0635, 0.1988, 0.0000, 0.0275,\n","         0.1677, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0385, 0.0000, 0.1963, 0.0000, 0.0113, 0.0000, 0.0402, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0888, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0869, 0.0000, 0.0557, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0538, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1301, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0124, 0.0264, 0.1109, 0.0629, 0.2066, 0.0000, 0.0275,\n","         0.1763, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0295, 0.0000, 0.2006, 0.0000, 0.0113, 0.0000, 0.0396, 0.0000,\n","         0.0000, 0.0045, 0.2054, 0.0000, 0.0000, 0.0905, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0880, 0.0000, 0.0610, 0.2339, 0.0000, 0.0422, 0.0000, 0.1273, 0.0921,\n","         0.0000, 0.0000, 0.0768, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1453, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0175, 0.0440, 0.1109, 0.0649, 0.2127, 0.0000, 0.0405,\n","         0.1808, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0347, 0.0000, 0.2168, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2054, 0.0000, 0.0000, 0.0961, 0.0000, 0.1721, 0.1025,\n","         0.1327],\n","        [0.0894, 0.0000, 0.0621, 0.1926, 0.0000, 0.0309, 0.0000, 0.1017, 0.0382,\n","         0.0000, 0.0000, 0.0646, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1399, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0200, 0.0309, 0.1109, 0.0668, 0.2141, 0.0000, 0.0208,\n","         0.1811, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0921,\n","         0.0564, 0.0391, 0.0000, 0.2041, 0.0000, 0.0113, 0.0000, 0.0429, 0.0000,\n","         0.0000, 0.0060, 0.1666, 0.0000, 0.0000, 0.0959, 0.0000, 0.1510, 0.1025,\n","         0.0934],\n","        [0.0907, 0.0000, 0.0607, 0.2378, 0.0000, 0.0327, 0.0000, 0.1251, 0.0880,\n","         0.0000, 0.0000, 0.0659, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1410, 0.0000, 0.0636, 0.0000, 0.0198, 0.0854, 0.0000,\n","         0.0000, 0.0714, 0.0169, 0.0327, 0.1109, 0.0657, 0.2182, 0.0000, 0.0423,\n","         0.1857, 0.0000, 0.1367, 0.0000, 0.1182, 0.0000, 0.0864, 0.0000, 0.1200,\n","         0.1350, 0.0355, 0.0000, 0.2078, 0.0000, 0.0113, 0.0000, 0.0433, 0.0000,\n","         0.0000, 0.0083, 0.2037, 0.0000, 0.0000, 0.0956, 0.0000, 0.1750, 0.1025,\n","         0.1234],\n","        [0.0905, 0.0000, 0.0610, 0.2338, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0672, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0173, 0.0342, 0.1109, 0.0653, 0.2213, 0.0000, 0.0540,\n","         0.1860, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0330, 0.0000, 0.2079, 0.0000, 0.0113, 0.0000, 0.0436, 0.0000,\n","         0.0000, 0.0089, 0.2054, 0.0000, 0.0000, 0.0964, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0907, 0.0000, 0.0612, 0.2378, 0.0000, 0.0327, 0.0000, 0.1251, 0.0880,\n","         0.0000, 0.0000, 0.0659, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1410, 0.0000, 0.0636, 0.0000, 0.0198, 0.0854, 0.0000,\n","         0.0000, 0.0701, 0.0192, 0.0327, 0.1109, 0.0667, 0.2182, 0.0000, 0.0423,\n","         0.1857, 0.0000, 0.1357, 0.0000, 0.1182, 0.0000, 0.0864, 0.0000, 0.1200,\n","         0.1350, 0.0388, 0.0000, 0.2078, 0.0000, 0.0113, 0.0000, 0.0433, 0.0000,\n","         0.0000, 0.0083, 0.2037, 0.0000, 0.0000, 0.0956, 0.0000, 0.1750, 0.1025,\n","         0.1234],\n","        [0.0911, 0.0000, 0.0610, 0.2329, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0690, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0194, 0.0342, 0.1109, 0.0658, 0.2213, 0.0000, 0.0540,\n","         0.1868, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0360, 0.0000, 0.2092, 0.0000, 0.0113, 0.0000, 0.0446, 0.0000,\n","         0.0000, 0.0092, 0.2054, 0.0000, 0.0000, 0.0979, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0901, 0.0000, 0.0606, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0642, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1407, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0149, 0.0329, 0.1109, 0.0651, 0.2174, 0.0000, 0.0399,\n","         0.1849, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0338, 0.0000, 0.2063, 0.0000, 0.0113, 0.0000, 0.0424, 0.0000,\n","         0.0000, 0.0081, 0.2024, 0.0000, 0.0000, 0.0942, 0.0000, 0.1726, 0.1025,\n","         0.1216]], grad_fn=<MaxBackward0>), tensor([[0.0371, 0.0000, 0.1106, 0.0000, 0.0590, 0.0890, 0.0000, 0.0000, 0.0615,\n","         0.0000, 0.0000, 0.1262, 0.0340, 0.0959, 0.0399, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0841, 0.1159, 0.0000, 0.0611, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0563, 0.1001, 0.0000, 0.0062, 0.0894, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0893, 0.0295, 0.0274, 0.0370, 0.0837, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0157, 0.0000, 0.0000, 0.0000, 0.1207, 0.0403, 0.0181,\n","         0.1249, 0.0000, 0.0658, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1103, 0.0000, 0.0586, 0.0892, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1261, 0.0343, 0.0956, 0.0391, 0.1315, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0841, 0.1154, 0.0000, 0.0612, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0565, 0.1001, 0.0000, 0.0058, 0.0899, 0.0000, 0.0281, 0.0000,\n","         0.0000, 0.0893, 0.0291, 0.0275, 0.0374, 0.0838, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1212, 0.0405, 0.0182,\n","         0.1250, 0.0000, 0.0660, 0.0000, 0.0000, 0.0462, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1103, 0.0000, 0.0586, 0.0892, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1262, 0.0344, 0.0956, 0.0392, 0.1315, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0841, 0.1154, 0.0000, 0.0612, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0565, 0.1001, 0.0000, 0.0058, 0.0899, 0.0000, 0.0281, 0.0000,\n","         0.0000, 0.0894, 0.0291, 0.0275, 0.0374, 0.0839, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1212, 0.0405, 0.0182,\n","         0.1250, 0.0000, 0.0660, 0.0000, 0.0000, 0.0462, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1110, 0.0000, 0.0591, 0.0889, 0.0000, 0.0000, 0.0615,\n","         0.0000, 0.0000, 0.1263, 0.0340, 0.0960, 0.0402, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0840, 0.1158, 0.0000, 0.0609, 0.0000, 0.0000, 0.1104,\n","         0.0000, 0.0562, 0.1000, 0.0000, 0.0063, 0.0892, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0893, 0.0298, 0.0272, 0.0370, 0.0837, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0157, 0.0000, 0.0000, 0.0000, 0.1206, 0.0401, 0.0182,\n","         0.1252, 0.0000, 0.0658, 0.0000, 0.0000, 0.0450, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0372, 0.0000, 0.1099, 0.0000, 0.0585, 0.0890, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1259, 0.0343, 0.0954, 0.0391, 0.1315, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0842, 0.1157, 0.0000, 0.0615, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0564, 0.1002, 0.0000, 0.0056, 0.0901, 0.0000, 0.0282, 0.0000,\n","         0.0000, 0.0892, 0.0290, 0.0278, 0.0373, 0.0838, 0.0000, 0.0513, 0.0000,\n","         0.0000, 0.0456, 0.0155, 0.0000, 0.0000, 0.0000, 0.1213, 0.0407, 0.0181,\n","         0.1248, 0.0000, 0.0660, 0.0000, 0.0000, 0.0466, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1119, 0.0000, 0.0597, 0.0894, 0.0000, 0.0000, 0.0621,\n","         0.0000, 0.0000, 0.1269, 0.0340, 0.0964, 0.0408, 0.1325, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0840, 0.1161, 0.0000, 0.0606, 0.0000, 0.0000, 0.1108,\n","         0.0000, 0.0562, 0.0998, 0.0000, 0.0070, 0.0887, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0897, 0.0302, 0.0269, 0.0367, 0.0843, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0457, 0.0159, 0.0000, 0.0000, 0.0000, 0.1201, 0.0398, 0.0182,\n","         0.1253, 0.0000, 0.0658, 0.0000, 0.0000, 0.0439, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1107, 0.0000, 0.0588, 0.0891, 0.0000, 0.0000, 0.0615,\n","         0.0000, 0.0000, 0.1264, 0.0342, 0.0959, 0.0398, 0.1317, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0841, 0.1154, 0.0000, 0.0609, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0563, 0.1000, 0.0000, 0.0063, 0.0894, 0.0000, 0.0281, 0.0000,\n","         0.0000, 0.0893, 0.0296, 0.0272, 0.0373, 0.0835, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1207, 0.0402, 0.0182,\n","         0.1255, 0.0000, 0.0659, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1113, 0.0000, 0.0593, 0.0893, 0.0000, 0.0000, 0.0617,\n","         0.0000, 0.0000, 0.1266, 0.0342, 0.0960, 0.0402, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0841, 0.1159, 0.0000, 0.0609, 0.0000, 0.0000, 0.1104,\n","         0.0000, 0.0563, 0.0999, 0.0000, 0.0064, 0.0892, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0897, 0.0297, 0.0272, 0.0370, 0.0843, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0157, 0.0000, 0.0000, 0.0000, 0.1207, 0.0401, 0.0182,\n","         0.1250, 0.0000, 0.0659, 0.0000, 0.0000, 0.0450, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0372, 0.0000, 0.1099, 0.0000, 0.0585, 0.0890, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1260, 0.0342, 0.0956, 0.0392, 0.1314, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0841, 0.1153, 0.0000, 0.0612, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0564, 0.1001, 0.0000, 0.0058, 0.0898, 0.0000, 0.0280, 0.0000,\n","         0.0000, 0.0891, 0.0292, 0.0275, 0.0374, 0.0831, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0154, 0.0000, 0.0000, 0.0000, 0.1210, 0.0405, 0.0182,\n","         0.1253, 0.0000, 0.0659, 0.0000, 0.0000, 0.0462, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1103, 0.0000, 0.0587, 0.0891, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1261, 0.0343, 0.0956, 0.0394, 0.1316, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0841, 0.1156, 0.0000, 0.0613, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0564, 0.1001, 0.0000, 0.0058, 0.0898, 0.0000, 0.0281, 0.0000,\n","         0.0000, 0.0893, 0.0292, 0.0275, 0.0373, 0.0838, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1211, 0.0405, 0.0182,\n","         0.1250, 0.0000, 0.0659, 0.0000, 0.0000, 0.0462, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5171, 0.4829],\n","        [0.5177, 0.4823],\n","        [0.5178, 0.4822],\n","        [0.5187, 0.4813],\n","        [0.5155, 0.4845],\n","        [0.5178, 0.4822],\n","        [0.5188, 0.4812],\n","        [0.5180, 0.4820],\n","        [0.5190, 0.4810],\n","        [0.5177, 0.4823]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0811, 0.0000, 0.0587, 0.2334, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0477, 0.0469, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1284, 0.0000, 0.0636, 0.0000, 0.0198, 0.0847, 0.0000,\n","         0.0000, 0.0712, 0.0145, 0.0229, 0.1109, 0.0659, 0.2047, 0.0000, 0.0403,\n","         0.1644, 0.0000, 0.1373, 0.0000, 0.1125, 0.0000, 0.0864, 0.0000, 0.1178,\n","         0.1333, 0.0361, 0.0000, 0.1916, 0.0000, 0.0113, 0.0000, 0.0383, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0823, 0.0000, 0.1707, 0.1025,\n","         0.1221],\n","        [0.0880, 0.0000, 0.0610, 0.2338, 0.0000, 0.0314, 0.0000, 0.1238, 0.0848,\n","         0.0000, 0.0000, 0.0623, 0.0456, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1384, 0.0000, 0.0636, 0.0000, 0.0198, 0.0841, 0.0000,\n","         0.0000, 0.0711, 0.0173, 0.0303, 0.1109, 0.0649, 0.2127, 0.0000, 0.0403,\n","         0.1808, 0.0000, 0.1368, 0.0000, 0.1115, 0.0000, 0.0864, 0.0000, 0.1165,\n","         0.1325, 0.0334, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2009, 0.0000, 0.0000, 0.0931, 0.0000, 0.1720, 0.1025,\n","         0.1219],\n","        [0.0813, 0.0000, 0.0580, 0.2343, 0.0000, 0.0314, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0474, 0.0464, 0.0043, 0.0891, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1297, 0.0000, 0.0461, 0.0000, 0.0000, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0111, 0.0237, 0.0982, 0.0641, 0.2062, 0.0000, 0.0403,\n","         0.1655, 0.0000, 0.1368, 0.0000, 0.1121, 0.0000, 0.0773, 0.0000, 0.1172,\n","         0.1335, 0.0303, 0.0000, 0.1925, 0.0000, 0.0000, 0.0000, 0.0378, 0.0000,\n","         0.0000, 0.0000, 0.2024, 0.0000, 0.0000, 0.0819, 0.0000, 0.1726, 0.0671,\n","         0.1219],\n","        [0.0876, 0.0000, 0.0623, 0.1871, 0.0000, 0.0309, 0.0000, 0.1032, 0.0341,\n","         0.0000, 0.0000, 0.0585, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0025, 0.0000, 0.1379, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0212, 0.0274, 0.1109, 0.0684, 0.2060, 0.0000, 0.0192,\n","         0.1752, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0863,\n","         0.0564, 0.0435, 0.0000, 0.1991, 0.0000, 0.0113, 0.0000, 0.0406, 0.0000,\n","         0.0000, 0.0016, 0.1658, 0.0000, 0.0000, 0.0923, 0.0000, 0.1447, 0.1025,\n","         0.0934],\n","        [0.0908, 0.0000, 0.0608, 0.2335, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0652, 0.0465, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1409, 0.0000, 0.0636, 0.0000, 0.0198, 0.0846, 0.0000,\n","         0.0000, 0.0712, 0.0169, 0.0323, 0.1109, 0.0658, 0.2176, 0.0000, 0.0403,\n","         0.1855, 0.0000, 0.1372, 0.0000, 0.1122, 0.0000, 0.0864, 0.0000, 0.1174,\n","         0.1331, 0.0352, 0.0000, 0.2077, 0.0000, 0.0113, 0.0000, 0.0430, 0.0000,\n","         0.0000, 0.0080, 0.2012, 0.0000, 0.0000, 0.0952, 0.0000, 0.1710, 0.1025,\n","         0.1221],\n","        [0.0857, 0.0000, 0.0608, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0634, 0.0709, 0.0043, 0.0921, 0.0000, 0.0000, 0.0000,\n","         0.0018, 0.0000, 0.1356, 0.0000, 0.0502, 0.0000, 0.0003, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0214, 0.0292, 0.0982, 0.0671, 0.2113, 0.0000, 0.0389,\n","         0.1764, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0790, 0.0000, 0.1267,\n","         0.1469, 0.0422, 0.0000, 0.2025, 0.0000, 0.0000, 0.0000, 0.0441, 0.0000,\n","         0.0000, 0.0043, 0.2054, 0.0000, 0.0000, 0.0942, 0.0000, 0.1641, 0.0671,\n","         0.1327],\n","        [0.0814, 0.0000, 0.0594, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0489, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1303, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0151, 0.0247, 0.1109, 0.0662, 0.1968, 0.0000, 0.0275,\n","         0.1658, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0370, 0.0000, 0.1925, 0.0000, 0.0113, 0.0000, 0.0381, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0830, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0822, 0.0000, 0.0594, 0.2329, 0.0000, 0.0535, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0539, 0.0867, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1315, 0.0000, 0.0747, 0.0000, 0.0198, 0.1154, 0.0140,\n","         0.0000, 0.0872, 0.0167, 0.0255, 0.1109, 0.0659, 0.2011, 0.0000, 0.0275,\n","         0.1685, 0.0000, 0.1555, 0.0000, 0.1225, 0.0000, 0.1055, 0.0000, 0.1267,\n","         0.1469, 0.0370, 0.0000, 0.1953, 0.0000, 0.0113, 0.0000, 0.0405, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0032, 0.0871, 0.0000, 0.1579, 0.1025,\n","         0.1342],\n","        [0.0832, 0.0000, 0.0599, 0.2382, 0.0000, 0.0422, 0.0000, 0.1247, 0.0921,\n","         0.0000, 0.0000, 0.0519, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1324, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0158, 0.0244, 0.1109, 0.0658, 0.2093, 0.0000, 0.0425,\n","         0.1679, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0352, 0.0000, 0.1945, 0.0000, 0.0113, 0.0000, 0.0390, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0863, 0.0000, 0.1761, 0.1025,\n","         0.1327],\n","        [0.0905, 0.0000, 0.0594, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0624, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1387, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0150, 0.0312, 0.1109, 0.0638, 0.2160, 0.0000, 0.0399,\n","         0.1840, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0298, 0.0000, 0.2064, 0.0000, 0.0113, 0.0000, 0.0419, 0.0000,\n","         0.0000, 0.0073, 0.2024, 0.0000, 0.0000, 0.0943, 0.0000, 0.1726, 0.1025,\n","         0.1216]], grad_fn=<MaxBackward0>), tensor([[0.0376, 0.0000, 0.1112, 0.0000, 0.0588, 0.0884, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1267, 0.0343, 0.0956, 0.0396, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1154, 0.0000, 0.0609, 0.0000, 0.0000, 0.1098,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0062, 0.0889, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0889, 0.0294, 0.0270, 0.0375, 0.0835, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0150, 0.0000, 0.0000, 0.0000, 0.1214, 0.0404, 0.0185,\n","         0.1247, 0.0000, 0.0660, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1118, 0.0000, 0.0591, 0.0885, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1270, 0.0343, 0.0958, 0.0400, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1155, 0.0000, 0.0607, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0065, 0.0887, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0891, 0.0296, 0.0269, 0.0374, 0.0840, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1213, 0.0403, 0.0185,\n","         0.1247, 0.0000, 0.0661, 0.0000, 0.0000, 0.0449, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1119, 0.0000, 0.0592, 0.0886, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1271, 0.0342, 0.0959, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0834, 0.1154, 0.0000, 0.0605, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0564, 0.0996, 0.0000, 0.0067, 0.0885, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0891, 0.0298, 0.0267, 0.0374, 0.0838, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1211, 0.0401, 0.0185,\n","         0.1249, 0.0000, 0.0661, 0.0000, 0.0000, 0.0445, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1108, 0.0000, 0.0586, 0.0884, 0.0000, 0.0000, 0.0606,\n","         0.0000, 0.0000, 0.1265, 0.0344, 0.0952, 0.0392, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1154, 0.0000, 0.0612, 0.0000, 0.0000, 0.1097,\n","         0.0000, 0.0566, 0.0999, 0.0000, 0.0059, 0.0894, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0889, 0.0291, 0.0273, 0.0377, 0.0838, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0457, 0.0151, 0.0000, 0.0000, 0.0000, 0.1218, 0.0406, 0.0186,\n","         0.1245, 0.0000, 0.0661, 0.0000, 0.0000, 0.0462, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1116, 0.0000, 0.0591, 0.0884, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1269, 0.0342, 0.0957, 0.0400, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1156, 0.0000, 0.0608, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0064, 0.0888, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0890, 0.0296, 0.0269, 0.0374, 0.0838, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1212, 0.0403, 0.0185,\n","         0.1247, 0.0000, 0.0660, 0.0000, 0.0000, 0.0451, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0381, 0.0000, 0.1122, 0.0000, 0.0592, 0.0887, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1273, 0.0344, 0.0959, 0.0400, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0834, 0.1152, 0.0000, 0.0605, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0565, 0.0995, 0.0000, 0.0067, 0.0885, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0892, 0.0298, 0.0267, 0.0376, 0.0841, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0459, 0.0150, 0.0000, 0.0000, 0.0000, 0.1212, 0.0401, 0.0186,\n","         0.1250, 0.0000, 0.0661, 0.0000, 0.0000, 0.0445, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0379, 0.0000, 0.1107, 0.0000, 0.0583, 0.0885, 0.0000, 0.0000, 0.0604,\n","         0.0000, 0.0000, 0.1265, 0.0347, 0.0952, 0.0386, 0.1313, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1148, 0.0000, 0.0611, 0.0000, 0.0000, 0.1095,\n","         0.0000, 0.0567, 0.0998, 0.0000, 0.0057, 0.0895, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0889, 0.0290, 0.0273, 0.0381, 0.0836, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0148, 0.0000, 0.0000, 0.0000, 0.1221, 0.0406, 0.0187,\n","         0.1247, 0.0000, 0.0662, 0.0000, 0.0000, 0.0465, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0379, 0.0000, 0.1114, 0.0000, 0.0588, 0.0885, 0.0000, 0.0000, 0.0608,\n","         0.0000, 0.0000, 0.1269, 0.0344, 0.0956, 0.0394, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1150, 0.0000, 0.0608, 0.0000, 0.0000, 0.1098,\n","         0.0000, 0.0565, 0.0996, 0.0000, 0.0062, 0.0890, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0889, 0.0294, 0.0269, 0.0377, 0.0836, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0150, 0.0000, 0.0000, 0.0000, 0.1215, 0.0404, 0.0187,\n","         0.1248, 0.0000, 0.0661, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1107, 0.0000, 0.0584, 0.0883, 0.0000, 0.0000, 0.0605,\n","         0.0000, 0.0000, 0.1266, 0.0345, 0.0954, 0.0389, 0.1314, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1148, 0.0000, 0.0609, 0.0000, 0.0000, 0.1096,\n","         0.0000, 0.0566, 0.0997, 0.0000, 0.0059, 0.0892, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0887, 0.0292, 0.0270, 0.0380, 0.0832, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0459, 0.0148, 0.0000, 0.0000, 0.0000, 0.1218, 0.0405, 0.0187,\n","         0.1249, 0.0000, 0.0661, 0.0000, 0.0000, 0.0460, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1105, 0.0000, 0.0583, 0.0885, 0.0000, 0.0000, 0.0604,\n","         0.0000, 0.0000, 0.1265, 0.0346, 0.0951, 0.0386, 0.1313, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1149, 0.0000, 0.0612, 0.0000, 0.0000, 0.1094,\n","         0.0000, 0.0567, 0.0999, 0.0000, 0.0057, 0.0896, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0888, 0.0289, 0.0274, 0.0380, 0.0836, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0148, 0.0000, 0.0000, 0.0000, 0.1221, 0.0406, 0.0186,\n","         0.1247, 0.0000, 0.0662, 0.0000, 0.0000, 0.0466, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5168, 0.4832],\n","        [0.5173, 0.4827],\n","        [0.5157, 0.4843],\n","        [0.5150, 0.4850],\n","        [0.5177, 0.4823],\n","        [0.5177, 0.4823],\n","        [0.5173, 0.4827],\n","        [0.5182, 0.4818],\n","        [0.5181, 0.4819],\n","        [0.5176, 0.4824]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0823, 0.0000, 0.0590, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0519, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1311, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0160, 0.0242, 0.1109, 0.0654, 0.2065, 0.0000, 0.0399,\n","         0.1680, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0356, 0.0000, 0.1953, 0.0000, 0.0113, 0.0000, 0.0398, 0.0000,\n","         0.0000, 0.0000, 0.2024, 0.0000, 0.0000, 0.0857, 0.0000, 0.1729, 0.1025,\n","         0.1216],\n","        [0.0811, 0.0000, 0.0589, 0.2343, 0.0000, 0.0312, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0503, 0.0588, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.0878, 0.0000,\n","         0.0000, 0.0934, 0.0147, 0.0342, 0.1109, 0.0660, 0.2213, 0.0000, 0.0540,\n","         0.1664, 0.0000, 0.1642, 0.0000, 0.1123, 0.0181, 0.0864, 0.0080, 0.1172,\n","         0.1446, 0.0363, 0.0000, 0.1931, 0.0000, 0.0113, 0.0000, 0.0390, 0.0000,\n","         0.0000, 0.0000, 0.2024, 0.0000, 0.0000, 0.0838, 0.0000, 0.1856, 0.1025,\n","         0.1216],\n","        [0.0813, 0.0000, 0.0580, 0.2335, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0491, 0.0465, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1297, 0.0000, 0.0636, 0.0000, 0.0198, 0.0846, 0.0000,\n","         0.0000, 0.0712, 0.0133, 0.0237, 0.1109, 0.0647, 0.2051, 0.0000, 0.0403,\n","         0.1662, 0.0000, 0.1372, 0.0000, 0.1122, 0.0000, 0.0864, 0.0000, 0.1174,\n","         0.1331, 0.0330, 0.0000, 0.1938, 0.0000, 0.0113, 0.0000, 0.0392, 0.0000,\n","         0.0000, 0.0000, 0.2012, 0.0000, 0.0000, 0.0839, 0.0000, 0.1710, 0.1025,\n","         0.1221],\n","        [0.0834, 0.0000, 0.0586, 0.2343, 0.0000, 0.0422, 0.0000, 0.1246, 0.0921,\n","         0.0000, 0.0000, 0.0468, 0.0709, 0.0057, 0.0921, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1300, 0.0000, 0.0461, 0.0000, 0.0003, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0142, 0.0266, 0.1030, 0.0769, 0.2084, 0.0000, 0.0434,\n","         0.1741, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0790, 0.0000, 0.1267,\n","         0.1469, 0.0355, 0.0000, 0.2181, 0.0000, 0.0000, 0.0000, 0.0380, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0837, 0.0000, 0.1726, 0.0672,\n","         0.1327],\n","        [0.0887, 0.0000, 0.0609, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0605, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1382, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0169, 0.0292, 0.1109, 0.0666, 0.2107, 0.0000, 0.0275,\n","         0.1798, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0374, 0.0000, 0.2034, 0.0000, 0.0113, 0.0000, 0.0419, 0.0000,\n","         0.0000, 0.0048, 0.2054, 0.0000, 0.0000, 0.0927, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0813, 0.0000, 0.0580, 0.1811, 0.0000, 0.0309, 0.0000, 0.0993, 0.0284,\n","         0.0000, 0.0000, 0.0474, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1297, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0111, 0.0237, 0.1109, 0.0646, 0.1954, 0.0000, 0.0185,\n","         0.1655, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0848,\n","         0.0556, 0.0319, 0.0000, 0.1925, 0.0000, 0.0113, 0.0000, 0.0378, 0.0000,\n","         0.0000, 0.0000, 0.1592, 0.0000, 0.0000, 0.0819, 0.0000, 0.1299, 0.1025,\n","         0.0934],\n","        [0.0866, 0.0000, 0.0586, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0817, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1481, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0196, 0.0464, 0.1109, 0.0657, 0.2155, 0.0000, 0.0399,\n","         0.1814, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0381, 0.0000, 0.2184, 0.0000, 0.0113, 0.0000, 0.0383, 0.0000,\n","         0.0000, 0.0066, 0.2024, 0.0000, 0.0000, 0.0983, 0.0000, 0.1726, 0.1025,\n","         0.1216],\n","        [0.0821, 0.0000, 0.0588, 0.1840, 0.0000, 0.0309, 0.0000, 0.0990, 0.0369,\n","         0.0000, 0.0000, 0.0531, 0.0305, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1306, 0.0000, 0.0636, 0.0000, 0.0198, 0.0710, 0.0000,\n","         0.0000, 0.0291, 0.0151, 0.0258, 0.1109, 0.0655, 0.2008, 0.0000, 0.0189,\n","         0.1676, 0.0000, 0.1232, 0.0000, 0.1062, 0.0000, 0.0864, 0.0000, 0.1067,\n","         0.0838, 0.0360, 0.0000, 0.1947, 0.0000, 0.0113, 0.0000, 0.0404, 0.0000,\n","         0.0000, 0.0000, 0.1716, 0.0000, 0.0000, 0.0859, 0.0000, 0.1352, 0.1025,\n","         0.0987],\n","        [0.0813, 0.0000, 0.0580, 0.2334, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0474, 0.0469, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1297, 0.0000, 0.0636, 0.0000, 0.0198, 0.0847, 0.0000,\n","         0.0000, 0.0712, 0.0132, 0.0237, 0.1109, 0.0644, 0.2047, 0.0000, 0.0403,\n","         0.1655, 0.0000, 0.1373, 0.0000, 0.1125, 0.0000, 0.0864, 0.0000, 0.1178,\n","         0.1333, 0.0339, 0.0000, 0.1925, 0.0000, 0.0113, 0.0000, 0.0378, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0819, 0.0000, 0.1707, 0.1025,\n","         0.1221],\n","        [0.0320, 0.0000, 0.0453, 0.0950, 0.0000, 0.0309, 0.0000, 0.0781, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.0812, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0000, 0.0000, 0.1109, 0.0527, 0.0741, 0.0000, 0.0024,\n","         0.0643, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0299,\n","         0.0536, 0.0000, 0.0000, 0.1006, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0015, 0.1025,\n","         0.0934]], grad_fn=<MaxBackward0>), tensor([[3.7292e-02, 0.0000e+00, 1.1087e-01, 0.0000e+00, 5.9001e-02, 8.8995e-02,\n","         0.0000e+00, 0.0000e+00, 6.1416e-02, 0.0000e+00, 0.0000e+00, 1.2646e-01,\n","         3.4134e-02, 9.5896e-02, 3.9858e-02, 1.3194e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3954e-02, 1.1568e-01, 0.0000e+00, 6.0889e-02,\n","         0.0000e+00, 0.0000e+00, 1.1027e-01, 0.0000e+00, 5.6353e-02, 9.9934e-02,\n","         0.0000e+00, 6.3529e-03, 8.9189e-02, 0.0000e+00, 2.8359e-02, 0.0000e+00,\n","         0.0000e+00, 8.9301e-02, 2.9621e-02, 2.7150e-02, 3.7184e-02, 8.3667e-02,\n","         0.0000e+00, 5.1602e-02, 0.0000e+00, 0.0000e+00, 4.5729e-02, 1.5529e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2080e-01, 4.0180e-02, 1.8237e-02,\n","         1.2513e-01, 0.0000e+00, 6.5891e-02, 0.0000e+00, 0.0000e+00, 4.5163e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7213e-02, 0.0000e+00, 1.1072e-01, 0.0000e+00, 5.8980e-02, 8.8923e-02,\n","         0.0000e+00, 0.0000e+00, 6.1385e-02, 0.0000e+00, 0.0000e+00, 1.2635e-01,\n","         3.4078e-02, 9.5843e-02, 3.9885e-02, 1.3199e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4015e-02, 1.1578e-01, 0.0000e+00, 6.0995e-02,\n","         0.0000e+00, 0.0000e+00, 1.1025e-01, 0.0000e+00, 5.6304e-02, 9.9995e-02,\n","         0.0000e+00, 6.2630e-03, 8.9285e-02, 0.0000e+00, 2.8420e-02, 0.0000e+00,\n","         0.0000e+00, 8.9246e-02, 2.9556e-02, 2.7248e-02, 3.7123e-02, 8.3619e-02,\n","         0.0000e+00, 5.1532e-02, 0.0000e+00, 0.0000e+00, 4.5671e-02, 1.5583e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2081e-01, 4.0245e-02, 1.8205e-02,\n","         1.2502e-01, 0.0000e+00, 6.5849e-02, 0.0000e+00, 0.0000e+00, 4.5340e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7096e-02, 0.0000e+00, 1.1130e-01, 0.0000e+00, 5.9488e-02, 8.8944e-02,\n","         0.0000e+00, 0.0000e+00, 6.1747e-02, 0.0000e+00, 0.0000e+00, 1.2659e-01,\n","         3.3836e-02, 9.6205e-02, 4.0631e-02, 1.3253e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4008e-02, 1.1632e-01, 0.0000e+00, 6.0832e-02,\n","         0.0000e+00, 0.0000e+00, 1.1062e-01, 0.0000e+00, 5.6202e-02, 9.9891e-02,\n","         0.0000e+00, 6.7434e-03, 8.8829e-02, 0.0000e+00, 2.8791e-02, 0.0000e+00,\n","         0.0000e+00, 8.9364e-02, 2.9939e-02, 2.7070e-02, 3.6719e-02, 8.3796e-02,\n","         0.0000e+00, 5.1516e-02, 0.0000e+00, 0.0000e+00, 4.5627e-02, 1.5821e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2030e-01, 4.0041e-02, 1.8146e-02,\n","         1.2487e-01, 0.0000e+00, 6.5777e-02, 0.0000e+00, 0.0000e+00, 4.4407e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7095e-02, 0.0000e+00, 1.1176e-01, 0.0000e+00, 5.9714e-02, 8.9019e-02,\n","         0.0000e+00, 0.0000e+00, 6.1996e-02, 0.0000e+00, 0.0000e+00, 1.2684e-01,\n","         3.3781e-02, 9.6465e-02, 4.1062e-02, 1.3269e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3926e-02, 1.1634e-01, 0.0000e+00, 6.0514e-02,\n","         0.0000e+00, 0.0000e+00, 1.1088e-01, 0.0000e+00, 5.6139e-02, 9.9757e-02,\n","         0.0000e+00, 7.1682e-03, 8.8407e-02, 0.0000e+00, 2.8820e-02, 0.0000e+00,\n","         0.0000e+00, 8.9383e-02, 3.0316e-02, 2.6795e-02, 3.6619e-02, 8.3668e-02,\n","         0.0000e+00, 5.1634e-02, 0.0000e+00, 0.0000e+00, 4.5655e-02, 1.5857e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1991e-01, 3.9772e-02, 1.8146e-02,\n","         1.2521e-01, 0.0000e+00, 6.5753e-02, 0.0000e+00, 0.0000e+00, 4.3604e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7267e-02, 0.0000e+00, 1.1069e-01, 0.0000e+00, 5.8989e-02, 8.8914e-02,\n","         0.0000e+00, 0.0000e+00, 6.1347e-02, 0.0000e+00, 0.0000e+00, 1.2631e-01,\n","         3.4112e-02, 9.5840e-02, 3.9838e-02, 1.3195e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4040e-02, 1.1581e-01, 0.0000e+00, 6.1073e-02,\n","         0.0000e+00, 0.0000e+00, 1.1024e-01, 0.0000e+00, 5.6329e-02, 9.9961e-02,\n","         0.0000e+00, 6.1729e-03, 8.9344e-02, 0.0000e+00, 2.8448e-02, 0.0000e+00,\n","         0.0000e+00, 8.9250e-02, 2.9473e-02, 2.7253e-02, 3.7160e-02, 8.3633e-02,\n","         0.0000e+00, 5.1483e-02, 0.0000e+00, 0.0000e+00, 4.5680e-02, 1.5607e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2083e-01, 4.0309e-02, 1.8263e-02,\n","         1.2494e-01, 0.0000e+00, 6.5857e-02, 0.0000e+00, 0.0000e+00, 4.5417e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7201e-02, 0.0000e+00, 1.1014e-01, 0.0000e+00, 5.8667e-02, 8.8840e-02,\n","         0.0000e+00, 0.0000e+00, 6.1147e-02, 0.0000e+00, 0.0000e+00, 1.2604e-01,\n","         3.4169e-02, 9.5507e-02, 3.9330e-02, 1.3172e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4082e-02, 1.1574e-01, 0.0000e+00, 6.1351e-02,\n","         0.0000e+00, 0.0000e+00, 1.0996e-01, 0.0000e+00, 5.6384e-02, 1.0011e-01,\n","         0.0000e+00, 5.7775e-03, 8.9786e-02, 0.0000e+00, 2.8364e-02, 0.0000e+00,\n","         0.0000e+00, 8.9143e-02, 2.9117e-02, 2.7585e-02, 3.7232e-02, 8.3610e-02,\n","         0.0000e+00, 5.1327e-02, 0.0000e+00, 0.0000e+00, 4.5647e-02, 1.5506e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2118e-01, 4.0570e-02, 1.8201e-02,\n","         1.2471e-01, 0.0000e+00, 6.5932e-02, 0.0000e+00, 0.0000e+00, 4.6233e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7149e-02, 0.0000e+00, 1.1139e-01, 0.0000e+00, 5.9506e-02, 8.8871e-02,\n","         0.0000e+00, 0.0000e+00, 6.1728e-02, 0.0000e+00, 0.0000e+00, 1.2655e-01,\n","         3.3812e-02, 9.6197e-02, 4.0706e-02, 1.3255e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3993e-02, 1.1631e-01, 0.0000e+00, 6.0855e-02,\n","         0.0000e+00, 0.0000e+00, 1.1060e-01, 0.0000e+00, 5.6167e-02, 9.9916e-02,\n","         0.0000e+00, 6.6987e-03, 8.8825e-02, 0.0000e+00, 2.8820e-02, 0.0000e+00,\n","         0.0000e+00, 8.9339e-02, 3.0012e-02, 2.7086e-02, 3.6672e-02, 8.3817e-02,\n","         0.0000e+00, 5.1528e-02, 0.0000e+00, 0.0000e+00, 4.5624e-02, 1.5820e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2031e-01, 4.0031e-02, 1.8140e-02,\n","         1.2488e-01, 0.0000e+00, 6.5760e-02, 0.0000e+00, 0.0000e+00, 4.4392e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7324e-02, 0.0000e+00, 1.1084e-01, 0.0000e+00, 5.9077e-02, 8.8990e-02,\n","         0.0000e+00, 0.0000e+00, 6.1396e-02, 0.0000e+00, 0.0000e+00, 1.2635e-01,\n","         3.4122e-02, 9.5805e-02, 3.9863e-02, 1.3210e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4072e-02, 1.1594e-01, 0.0000e+00, 6.1168e-02,\n","         0.0000e+00, 0.0000e+00, 1.1020e-01, 0.0000e+00, 5.6350e-02, 1.0002e-01,\n","         0.0000e+00, 6.1415e-03, 8.9426e-02, 0.0000e+00, 2.8536e-02, 0.0000e+00,\n","         0.0000e+00, 8.9421e-02, 2.9400e-02, 2.7364e-02, 3.7071e-02, 8.4081e-02,\n","         0.0000e+00, 5.1453e-02, 0.0000e+00, 0.0000e+00, 4.5661e-02, 1.5648e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2096e-01, 4.0375e-02, 1.8217e-02,\n","         1.2472e-01, 0.0000e+00, 6.5888e-02, 0.0000e+00, 0.0000e+00, 4.5535e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7216e-02, 0.0000e+00, 1.1068e-01, 0.0000e+00, 5.8984e-02, 8.8909e-02,\n","         0.0000e+00, 0.0000e+00, 6.1358e-02, 0.0000e+00, 0.0000e+00, 1.2631e-01,\n","         3.4083e-02, 9.5819e-02, 3.9827e-02, 1.3199e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4023e-02, 1.1584e-01, 0.0000e+00, 6.1063e-02,\n","         0.0000e+00, 0.0000e+00, 1.1022e-01, 0.0000e+00, 5.6331e-02, 9.9997e-02,\n","         0.0000e+00, 6.1988e-03, 8.9339e-02, 0.0000e+00, 2.8453e-02, 0.0000e+00,\n","         0.0000e+00, 8.9262e-02, 2.9482e-02, 2.7287e-02, 3.7117e-02, 8.3682e-02,\n","         0.0000e+00, 5.1489e-02, 0.0000e+00, 0.0000e+00, 4.5678e-02, 1.5589e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2086e-01, 4.0302e-02, 1.8216e-02,\n","         1.2489e-01, 0.0000e+00, 6.5869e-02, 0.0000e+00, 0.0000e+00, 4.5425e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 1.2434e-04, 2.1180e-02, 0.0000e+00, 2.9298e-02, 4.5940e-02,\n","         0.0000e+00, 0.0000e+00, 2.6953e-02, 0.0000e+00, 0.0000e+00, 8.6390e-02,\n","         8.3276e-03, 1.0871e-01, 0.0000e+00, 9.2434e-02, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 7.3556e-02, 1.2467e-01, 0.0000e+00, 6.6447e-02,\n","         0.0000e+00, 0.0000e+00, 1.1208e-01, 0.0000e+00, 9.2472e-02, 1.1002e-01,\n","         0.0000e+00, 0.0000e+00, 1.2243e-01, 0.0000e+00, 3.3294e-02, 0.0000e+00,\n","         0.0000e+00, 3.2541e-02, 3.3098e-02, 5.2043e-02, 5.1355e-02, 0.0000e+00,\n","         0.0000e+00, 1.0478e-01, 0.0000e+00, 0.0000e+00, 6.7165e-02, 3.7826e-03,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0235e-01, 4.9874e-02, 2.9341e-02,\n","         1.2487e-01, 0.0000e+00, 8.3353e-02, 0.0000e+00, 0.0000e+00, 7.3997e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n","       grad_fn=<MaxBackward0>)], tensor([[0.5171, 0.4829],\n","        [0.5183, 0.4817],\n","        [0.5167, 0.4833],\n","        [0.5167, 0.4833],\n","        [0.5183, 0.4817],\n","        [0.5134, 0.4866],\n","        [0.5179, 0.4821],\n","        [0.5145, 0.4855],\n","        [0.5168, 0.4832],\n","        [0.5107, 0.4893]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0804, 0.0000, 0.0580, 0.2325, 0.0000, 0.0316, 0.0000, 0.1237, 0.0845,\n","         0.0000, 0.0000, 0.0460, 0.0482, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1273, 0.0000, 0.0636, 0.0000, 0.0198, 0.0862, 0.0000,\n","         0.0000, 0.0713, 0.0129, 0.0228, 0.1109, 0.0655, 0.2027, 0.0000, 0.0403,\n","         0.1637, 0.0000, 0.1388, 0.0000, 0.1139, 0.0000, 0.0864, 0.0000, 0.1193,\n","         0.1345, 0.0347, 0.0000, 0.1907, 0.0000, 0.0113, 0.0000, 0.0380, 0.0000,\n","         0.0000, 0.0000, 0.2014, 0.0000, 0.0000, 0.0808, 0.0000, 0.1687, 0.1025,\n","         0.1232],\n","        [0.0798, 0.0000, 0.0555, 0.2346, 0.0000, 0.0314, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0408, 0.0478, 0.0043, 0.0891, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1245, 0.0000, 0.0461, 0.0000, 0.0000, 0.0855, 0.0000,\n","         0.0000, 0.0715, 0.0093, 0.0224, 0.0958, 0.0638, 0.2061, 0.0000, 0.0420,\n","         0.1617, 0.0000, 0.1385, 0.0000, 0.1156, 0.0000, 0.0773, 0.0000, 0.1228,\n","         0.1368, 0.0268, 0.0000, 0.1935, 0.0000, 0.0000, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2035, 0.0000, 0.0000, 0.0801, 0.0000, 0.1726, 0.0622,\n","         0.1250],\n","        [0.1121, 0.0000, 0.0586, 0.2509, 0.0000, 0.0312, 0.0000, 0.1700, 0.0860,\n","         0.0000, 0.0000, 0.1198, 0.0603, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1789, 0.0000, 0.0636, 0.0000, 0.0198, 0.0999, 0.0000,\n","         0.0000, 0.0714, 0.0165, 0.0868, 0.1109, 0.0657, 0.2654, 0.0000, 0.0399,\n","         0.2296, 0.0000, 0.1367, 0.0000, 0.1121, 0.0539, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0542, 0.0000, 0.2442, 0.0000, 0.0113, 0.0000, 0.0380, 0.0000,\n","         0.0000, 0.0034, 0.2024, 0.0000, 0.0000, 0.1239, 0.0000, 0.2306, 0.1025,\n","         0.1216],\n","        [0.0738, 0.0000, 0.0555, 0.2329, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0348, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0061, 0.0342, 0.1109, 0.0629, 0.2213, 0.0000, 0.0540,\n","         0.1521, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0268, 0.0000, 0.1814, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0713, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0880, 0.0000, 0.0610, 0.2343, 0.0000, 0.0312, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0623, 0.0588, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.0878, 0.0000,\n","         0.0000, 0.0934, 0.0173, 0.0342, 0.1109, 0.0656, 0.2213, 0.0000, 0.0540,\n","         0.1808, 0.0000, 0.1642, 0.0000, 0.1123, 0.0181, 0.0864, 0.0080, 0.1172,\n","         0.1446, 0.0362, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2024, 0.0000, 0.0000, 0.0931, 0.0000, 0.1856, 0.1025,\n","         0.1216],\n","        [0.0895, 0.0000, 0.0618, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0627, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1395, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0199, 0.0297, 0.1109, 0.0664, 0.2123, 0.0000, 0.0399,\n","         0.1809, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0387, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0423, 0.0000,\n","         0.0000, 0.0051, 0.2024, 0.0000, 0.0000, 0.0948, 0.0000, 0.1726, 0.1025,\n","         0.1216],\n","        [0.0841, 0.0000, 0.0576, 0.2375, 0.0000, 0.0309, 0.0000, 0.1253, 0.0880,\n","         0.0000, 0.0000, 0.0532, 0.0458, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1301, 0.0000, 0.0636, 0.0000, 0.0198, 0.0827, 0.0000,\n","         0.0000, 0.0701, 0.0142, 0.0259, 0.1109, 0.0631, 0.2072, 0.0000, 0.0422,\n","         0.1722, 0.0000, 0.1360, 0.0000, 0.1140, 0.0000, 0.0864, 0.0000, 0.1204,\n","         0.1354, 0.0319, 0.0000, 0.1979, 0.0000, 0.0113, 0.0000, 0.0400, 0.0000,\n","         0.0000, 0.0013, 0.2040, 0.0000, 0.0000, 0.0872, 0.0000, 0.1745, 0.1025,\n","         0.1235],\n","        [0.0911, 0.0000, 0.0610, 0.2378, 0.0000, 0.0309, 0.0000, 0.1251, 0.0880,\n","         0.0000, 0.0000, 0.0690, 0.0455, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1416, 0.0000, 0.0636, 0.0000, 0.0198, 0.0823, 0.0000,\n","         0.0000, 0.0701, 0.0194, 0.0335, 0.1109, 0.0658, 0.2208, 0.0000, 0.0423,\n","         0.1868, 0.0000, 0.1357, 0.0000, 0.1136, 0.0000, 0.0864, 0.0000, 0.1200,\n","         0.1350, 0.0360, 0.0000, 0.2092, 0.0000, 0.0113, 0.0000, 0.0446, 0.0000,\n","         0.0000, 0.0092, 0.2037, 0.0000, 0.0000, 0.0979, 0.0000, 0.1750, 0.1025,\n","         0.1234],\n","        [0.0912, 0.0000, 0.0608, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0859,\n","         0.0000, 0.0000, 0.0675, 0.0461, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1413, 0.0000, 0.0636, 0.0000, 0.0198, 0.0841, 0.0000,\n","         0.0000, 0.0714, 0.0189, 0.0325, 0.1109, 0.0662, 0.2191, 0.0000, 0.0398,\n","         0.1865, 0.0000, 0.1365, 0.0000, 0.1117, 0.0000, 0.0864, 0.0000, 0.1168,\n","         0.1332, 0.0370, 0.0000, 0.2092, 0.0000, 0.0113, 0.0000, 0.0441, 0.0000,\n","         0.0000, 0.0085, 0.2023, 0.0000, 0.0000, 0.0970, 0.0000, 0.1729, 0.1025,\n","         0.1216],\n","        [0.0858, 0.0000, 0.0606, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0859,\n","         0.0000, 0.0000, 0.0618, 0.0461, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1354, 0.0000, 0.0636, 0.0000, 0.0198, 0.0841, 0.0000,\n","         0.0000, 0.0714, 0.0210, 0.0282, 0.1109, 0.0668, 0.2096, 0.0000, 0.0398,\n","         0.1761, 0.0000, 0.1365, 0.0000, 0.1117, 0.0000, 0.0864, 0.0000, 0.1168,\n","         0.1332, 0.0411, 0.0000, 0.2025, 0.0000, 0.0113, 0.0000, 0.0435, 0.0000,\n","         0.0000, 0.0035, 0.2023, 0.0000, 0.0000, 0.0933, 0.0000, 0.1729, 0.1025,\n","         0.1216]], grad_fn=<MaxBackward0>), tensor([[0.0375, 0.0000, 0.1116, 0.0000, 0.0592, 0.0887, 0.0000, 0.0000, 0.0614,\n","         0.0000, 0.0000, 0.1269, 0.0341, 0.0960, 0.0403, 0.1323, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1157, 0.0000, 0.0606, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0563, 0.0997, 0.0000, 0.0067, 0.0886, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0891, 0.0299, 0.0269, 0.0372, 0.0837, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0154, 0.0000, 0.0000, 0.0000, 0.1208, 0.0401, 0.0184,\n","         0.1250, 0.0000, 0.0659, 0.0000, 0.0000, 0.0445, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1120, 0.0000, 0.0593, 0.0889, 0.0000, 0.0000, 0.0615,\n","         0.0000, 0.0000, 0.1272, 0.0342, 0.0962, 0.0404, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1154, 0.0000, 0.0603, 0.0000, 0.0000, 0.1104,\n","         0.0000, 0.0564, 0.0996, 0.0000, 0.0070, 0.0883, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0892, 0.0301, 0.0266, 0.0373, 0.0837, 0.0000, 0.0518, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1207, 0.0398, 0.0184,\n","         0.1254, 0.0000, 0.0660, 0.0000, 0.0000, 0.0440, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1120, 0.0000, 0.0594, 0.0885, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1269, 0.0339, 0.0960, 0.0405, 0.1325, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1158, 0.0000, 0.0606, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0562, 0.0998, 0.0000, 0.0067, 0.0885, 0.0000, 0.0289, 0.0000,\n","         0.0000, 0.0891, 0.0302, 0.0269, 0.0369, 0.0838, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0154, 0.0000, 0.0000, 0.0000, 0.1207, 0.0400, 0.0183,\n","         0.1249, 0.0000, 0.0660, 0.0000, 0.0000, 0.0443, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1103, 0.0000, 0.0583, 0.0885, 0.0000, 0.0000, 0.0607,\n","         0.0000, 0.0000, 0.1263, 0.0344, 0.0955, 0.0389, 0.1313, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1148, 0.0000, 0.0609, 0.0000, 0.0000, 0.1097,\n","         0.0000, 0.0565, 0.0998, 0.0000, 0.0059, 0.0893, 0.0000, 0.0282, 0.0000,\n","         0.0000, 0.0887, 0.0292, 0.0271, 0.0379, 0.0828, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0150, 0.0000, 0.0000, 0.0000, 0.1214, 0.0404, 0.0186,\n","         0.1252, 0.0000, 0.0660, 0.0000, 0.0000, 0.0459, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1110, 0.0000, 0.0589, 0.0886, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1266, 0.0342, 0.0957, 0.0398, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1155, 0.0000, 0.0609, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0564, 0.0998, 0.0000, 0.0063, 0.0890, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0890, 0.0295, 0.0271, 0.0374, 0.0836, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0153, 0.0000, 0.0000, 0.0000, 0.1211, 0.0403, 0.0184,\n","         0.1249, 0.0000, 0.0659, 0.0000, 0.0000, 0.0453, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1108, 0.0000, 0.0587, 0.0886, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1265, 0.0343, 0.0955, 0.0394, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1153, 0.0000, 0.0611, 0.0000, 0.0000, 0.1098,\n","         0.0000, 0.0565, 0.0999, 0.0000, 0.0059, 0.0893, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0890, 0.0292, 0.0272, 0.0376, 0.0837, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1215, 0.0405, 0.0185,\n","         0.1248, 0.0000, 0.0660, 0.0000, 0.0000, 0.0459, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1109, 0.0000, 0.0589, 0.0886, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1265, 0.0342, 0.0957, 0.0397, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1156, 0.0000, 0.0610, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0564, 0.0998, 0.0000, 0.0062, 0.0891, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0890, 0.0294, 0.0271, 0.0374, 0.0835, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0153, 0.0000, 0.0000, 0.0000, 0.1212, 0.0404, 0.0184,\n","         0.1248, 0.0000, 0.0660, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1108, 0.0000, 0.0588, 0.0886, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1265, 0.0343, 0.0956, 0.0395, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1154, 0.0000, 0.0610, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0564, 0.0999, 0.0000, 0.0060, 0.0893, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0890, 0.0293, 0.0272, 0.0375, 0.0836, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1214, 0.0404, 0.0184,\n","         0.1248, 0.0000, 0.0660, 0.0000, 0.0000, 0.0458, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1109, 0.0000, 0.0588, 0.0886, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1265, 0.0343, 0.0956, 0.0395, 0.1319, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1154, 0.0000, 0.0610, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0564, 0.0999, 0.0000, 0.0060, 0.0893, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0890, 0.0293, 0.0272, 0.0375, 0.0837, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1214, 0.0404, 0.0184,\n","         0.1248, 0.0000, 0.0660, 0.0000, 0.0000, 0.0457, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1106, 0.0000, 0.0586, 0.0886, 0.0000, 0.0000, 0.0608,\n","         0.0000, 0.0000, 0.1264, 0.0344, 0.0954, 0.0391, 0.1316, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1153, 0.0000, 0.0611, 0.0000, 0.0000, 0.1097,\n","         0.0000, 0.0565, 0.0999, 0.0000, 0.0058, 0.0894, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0889, 0.0292, 0.0273, 0.0376, 0.0835, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1216, 0.0405, 0.0185,\n","         0.1248, 0.0000, 0.0660, 0.0000, 0.0000, 0.0461, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5166, 0.4834],\n","        [0.5154, 0.4846],\n","        [0.5207, 0.4793],\n","        [0.5178, 0.4822],\n","        [0.5185, 0.4815],\n","        [0.5176, 0.4824],\n","        [0.5171, 0.4829],\n","        [0.5181, 0.4819],\n","        [0.5180, 0.4820],\n","        [0.5177, 0.4823]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[8.0560e-02, 0.0000e+00, 5.8634e-02, 2.3427e-01, 0.0000e+00, 3.1160e-02,\n","         0.0000e+00, 1.2464e-01, 8.5993e-02, 0.0000e+00, 0.0000e+00, 5.6688e-02,\n","         4.6386e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2891e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4205e-02, 0.0000e+00, 0.0000e+00, 7.1444e-02, 1.9962e-02,\n","         2.3987e-02, 1.1090e-01, 6.5688e-02, 2.0610e-01, 0.0000e+00, 3.9863e-02,\n","         1.8114e-01, 0.0000e+00, 1.3666e-01, 0.0000e+00, 1.1208e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1717e-01, 1.3348e-01, 3.5454e-02, 0.0000e+00,\n","         2.0974e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.8028e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0244e-01, 0.0000e+00, 0.0000e+00, 8.1620e-02,\n","         0.0000e+00, 1.7255e-01, 1.0255e-01, 1.2164e-01],\n","        [8.6530e-02, 0.0000e+00, 5.5118e-02, 2.1254e-01, 0.0000e+00, 3.0867e-02,\n","         0.0000e+00, 1.0990e-01, 4.5777e-02, 0.0000e+00, 0.0000e+00, 7.9071e-02,\n","         2.6636e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.4380e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 6.6979e-02, 0.0000e+00, 0.0000e+00, 2.9078e-02, 2.7958e-02,\n","         3.3667e-02, 1.1090e-01, 6.2475e-02, 2.1103e-01, 0.0000e+00, 3.2934e-02,\n","         2.0572e-01, 0.0000e+00, 1.2322e-01, 0.0000e+00, 1.0821e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1147e-01, 8.2665e-02, 2.5938e-02, 0.0000e+00,\n","         2.3204e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.5777e-02, 0.0000e+00,\n","         0.0000e+00, 1.0274e-05, 1.7063e-01, 0.0000e+00, 0.0000e+00, 9.2340e-02,\n","         0.0000e+00, 1.7873e-01, 1.0255e-01, 9.8160e-02],\n","        [8.5682e-02, 0.0000e+00, 6.0821e-02, 2.3427e-01, 0.0000e+00, 3.1160e-02,\n","         0.0000e+00, 1.2464e-01, 8.5993e-02, 0.0000e+00, 0.0000e+00, 6.3411e-02,\n","         4.6386e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         1.7693e-03, 0.0000e+00, 1.3556e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4205e-02, 0.0000e+00, 0.0000e+00, 7.1444e-02, 2.1426e-02,\n","         2.9202e-02, 1.1090e-01, 6.7076e-02, 2.1128e-01, 0.0000e+00, 3.9863e-02,\n","         1.7642e-01, 0.0000e+00, 1.3666e-01, 0.0000e+00, 1.1208e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1717e-01, 1.3348e-01, 4.2169e-02, 0.0000e+00,\n","         2.0251e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.4073e-02, 0.0000e+00,\n","         0.0000e+00, 4.2970e-03, 2.0244e-01, 0.0000e+00, 0.0000e+00, 9.4222e-02,\n","         0.0000e+00, 1.7255e-01, 1.0255e-01, 1.2164e-01],\n","        [9.0088e-02, 0.0000e+00, 6.2750e-02, 2.3427e-01, 0.0000e+00, 3.1160e-02,\n","         0.0000e+00, 1.2464e-01, 8.5993e-02, 0.0000e+00, 0.0000e+00, 6.3515e-02,\n","         4.6386e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.4050e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4205e-02, 0.0000e+00, 0.0000e+00, 7.1444e-02, 2.0453e-02,\n","         2.9548e-02, 1.1090e-01, 6.7461e-02, 2.1261e-01, 0.0000e+00, 3.9863e-02,\n","         1.8184e-01, 0.0000e+00, 1.3666e-01, 0.0000e+00, 1.1208e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1717e-01, 1.3348e-01, 3.8375e-02, 0.0000e+00,\n","         2.0466e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.2625e-02, 0.0000e+00,\n","         0.0000e+00, 4.8864e-03, 2.0244e-01, 0.0000e+00, 0.0000e+00, 9.5610e-02,\n","         0.0000e+00, 1.7255e-01, 1.0255e-01, 1.2164e-01],\n","        [8.8721e-02, 0.0000e+00, 6.1274e-02, 2.2252e-01, 0.0000e+00, 3.0867e-02,\n","         0.0000e+00, 1.2716e-01, 9.2928e-02, 0.0000e+00, 0.0000e+00, 6.2117e-02,\n","         5.8754e-02, 5.4064e-02, 1.0809e-01, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.4477e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.7813e-02, 0.0000e+00, 0.0000e+00, 9.3389e-02, 1.9691e-02,\n","         3.4154e-02, 1.1090e-01, 6.7047e-02, 2.2128e-01, 0.0000e+00, 5.4012e-02,\n","         1.8014e-01, 0.0000e+00, 1.6419e-01, 0.0000e+00, 1.1232e-01, 1.8134e-02,\n","         8.6433e-02, 7.9503e-03, 9.3218e-02, 1.4456e-01, 3.9659e-02, 0.0000e+00,\n","         2.0332e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.2286e-02, 0.0000e+00,\n","         0.0000e+00, 5.4262e-03, 1.9149e-01, 0.0000e+00, 0.0000e+00, 9.3759e-02,\n","         0.0000e+00, 1.8564e-01, 1.0255e-01, 1.1015e-01],\n","        [8.3786e-02, 0.0000e+00, 5.8923e-02, 2.3286e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2236e-01, 9.2130e-02, 0.0000e+00, 0.0000e+00, 5.1105e-02,\n","         7.0890e-02, 0.0000e+00, 9.2120e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.3095e-01, 0.0000e+00, 4.9221e-02, 0.0000e+00,\n","         3.2497e-04, 1.1241e-01, 0.0000e+00, 0.0000e+00, 8.7246e-02, 1.4125e-02,\n","         2.4986e-02, 9.8714e-02, 6.4986e-02, 1.9886e-01, 0.0000e+00, 2.7469e-02,\n","         1.6728e-01, 0.0000e+00, 1.5546e-01, 0.0000e+00, 1.1940e-01, 0.0000e+00,\n","         7.8992e-02, 0.0000e+00, 1.2671e-01, 1.4689e-01, 3.3560e-02, 0.0000e+00,\n","         1.9390e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9209e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0541e-01, 0.0000e+00, 0.0000e+00, 8.4733e-02,\n","         0.0000e+00, 1.5793e-01, 6.7302e-02, 1.3274e-01],\n","        [8.1398e-02, 0.0000e+00, 5.9411e-02, 2.3427e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2464e-01, 9.2130e-02, 0.0000e+00, 0.0000e+00, 4.8895e-02,\n","         7.0890e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.3033e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.1241e-01, 0.0000e+00, 0.0000e+00, 8.7246e-02, 1.5113e-02,\n","         2.4683e-02, 1.1090e-01, 6.6249e-02, 2.0610e-01, 0.0000e+00, 3.9863e-02,\n","         1.6577e-01, 0.0000e+00, 1.5546e-01, 0.0000e+00, 1.1940e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.2671e-01, 1.4689e-01, 3.6955e-02, 0.0000e+00,\n","         1.9247e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.8131e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0541e-01, 0.0000e+00, 0.0000e+00, 8.3015e-02,\n","         0.0000e+00, 1.7255e-01, 1.0255e-01, 1.3274e-01],\n","        [8.3693e-02, 0.0000e+00, 5.9350e-02, 2.3286e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2236e-01, 9.2130e-02, 0.0000e+00, 0.0000e+00, 5.7531e-02,\n","         7.0890e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.3348e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.1241e-01, 0.0000e+00, 0.0000e+00, 8.7246e-02, 1.6223e-02,\n","         2.8843e-02, 1.1090e-01, 6.5570e-02, 2.0767e-01, 0.0000e+00, 2.7469e-02,\n","         1.7367e-01, 0.0000e+00, 1.5546e-01, 0.0000e+00, 1.1940e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.2671e-01, 1.4689e-01, 3.6155e-02, 0.0000e+00,\n","         1.9849e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.1519e-02, 0.0000e+00,\n","         0.0000e+00, 3.3021e-03, 2.0541e-01, 0.0000e+00, 0.0000e+00, 8.8772e-02,\n","         0.0000e+00, 1.5793e-01, 1.0255e-01, 1.3274e-01],\n","        [7.6518e-02, 0.0000e+00, 5.3081e-02, 2.3353e-01, 0.0000e+00, 3.1419e-02,\n","         0.0000e+00, 1.2390e-01, 8.4965e-02, 0.0000e+00, 0.0000e+00, 3.4072e-02,\n","         4.6524e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.1954e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4553e-02, 0.0000e+00, 0.0000e+00, 7.1173e-02, 6.7591e-03,\n","         2.2492e-02, 1.1090e-01, 6.2919e-02, 2.0515e-01, 0.0000e+00, 4.0318e-02,\n","         1.5444e-01, 0.0000e+00, 1.3717e-01, 0.0000e+00, 1.1220e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1743e-01, 1.3312e-01, 2.3762e-02, 0.0000e+00,\n","         1.8739e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.0868e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0122e-01, 0.0000e+00, 0.0000e+00, 7.5630e-02,\n","         0.0000e+00, 1.7101e-01, 1.0255e-01, 1.2208e-01],\n","        [7.8876e-02, 0.0000e+00, 4.5298e-02, 2.4071e-01, 0.0000e+00, 3.1160e-02,\n","         0.0000e+00, 1.2653e-01, 9.0974e-02, 0.0000e+00, 0.0000e+00, 9.9801e-03,\n","         4.6386e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.1511e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4205e-02, 0.0000e+00, 0.0000e+00, 7.1444e-02, 0.0000e+00,\n","         2.2679e-02, 1.1090e-01, 5.7574e-02, 2.1244e-01, 0.0000e+00, 4.1506e-02,\n","         1.5156e-01, 0.0000e+00, 1.3666e-01, 0.0000e+00, 1.1235e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1842e-01, 1.3511e-01, 3.9056e-03, 0.0000e+00,\n","         1.9145e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 1.9340e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0552e-01, 0.0000e+00, 0.0000e+00, 6.8674e-02,\n","         0.0000e+00, 1.8060e-01, 1.0255e-01, 1.2210e-01]],\n","       grad_fn=<MaxBackward0>), tensor([[0.0377, 0.0000, 0.1112, 0.0000, 0.0588, 0.0885, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1267, 0.0342, 0.0956, 0.0397, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1155, 0.0000, 0.0609, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0565, 0.0998, 0.0000, 0.0062, 0.0890, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0890, 0.0294, 0.0271, 0.0375, 0.0837, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1214, 0.0404, 0.0185,\n","         0.1247, 0.0000, 0.0660, 0.0000, 0.0000, 0.0455, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0379, 0.0000, 0.1110, 0.0000, 0.0586, 0.0887, 0.0000, 0.0000, 0.0608,\n","         0.0000, 0.0000, 0.1266, 0.0345, 0.0952, 0.0392, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1153, 0.0000, 0.0612, 0.0000, 0.0000, 0.1097,\n","         0.0000, 0.0567, 0.0999, 0.0000, 0.0059, 0.0895, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0892, 0.0291, 0.0274, 0.0377, 0.0843, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1219, 0.0406, 0.0185,\n","         0.1245, 0.0000, 0.0662, 0.0000, 0.0000, 0.0463, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1113, 0.0000, 0.0591, 0.0885, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1267, 0.0342, 0.0958, 0.0400, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1156, 0.0000, 0.0608, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0564, 0.0998, 0.0000, 0.0064, 0.0888, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0890, 0.0296, 0.0270, 0.0373, 0.0837, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0153, 0.0000, 0.0000, 0.0000, 0.1211, 0.0403, 0.0185,\n","         0.1247, 0.0000, 0.0660, 0.0000, 0.0000, 0.0451, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1112, 0.0000, 0.0589, 0.0885, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1267, 0.0343, 0.0956, 0.0397, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1155, 0.0000, 0.0609, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0564, 0.0998, 0.0000, 0.0062, 0.0890, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0890, 0.0294, 0.0271, 0.0375, 0.0837, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1213, 0.0404, 0.0185,\n","         0.1247, 0.0000, 0.0660, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1105, 0.0000, 0.0585, 0.0885, 0.0000, 0.0000, 0.0607,\n","         0.0000, 0.0000, 0.1264, 0.0344, 0.0953, 0.0391, 0.1316, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1153, 0.0000, 0.0612, 0.0000, 0.0000, 0.1097,\n","         0.0000, 0.0565, 0.0999, 0.0000, 0.0058, 0.0895, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0889, 0.0291, 0.0274, 0.0377, 0.0835, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0457, 0.0151, 0.0000, 0.0000, 0.0000, 0.1217, 0.0406, 0.0185,\n","         0.1246, 0.0000, 0.0661, 0.0000, 0.0000, 0.0463, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1119, 0.0000, 0.0593, 0.0887, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1271, 0.0342, 0.0961, 0.0402, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1155, 0.0000, 0.0605, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0564, 0.0995, 0.0000, 0.0068, 0.0885, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0891, 0.0299, 0.0267, 0.0374, 0.0838, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1208, 0.0401, 0.0186,\n","         0.1250, 0.0000, 0.0660, 0.0000, 0.0000, 0.0443, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1118, 0.0000, 0.0592, 0.0887, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1270, 0.0342, 0.0960, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1154, 0.0000, 0.0606, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0564, 0.0996, 0.0000, 0.0067, 0.0885, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0891, 0.0298, 0.0268, 0.0374, 0.0838, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1210, 0.0401, 0.0185,\n","         0.1250, 0.0000, 0.0660, 0.0000, 0.0000, 0.0445, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1111, 0.0000, 0.0589, 0.0885, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1266, 0.0342, 0.0957, 0.0396, 0.1319, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1154, 0.0000, 0.0609, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0062, 0.0890, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0889, 0.0294, 0.0270, 0.0375, 0.0835, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1213, 0.0404, 0.0185,\n","         0.1248, 0.0000, 0.0660, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1111, 0.0000, 0.0587, 0.0885, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1267, 0.0344, 0.0956, 0.0394, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1151, 0.0000, 0.0608, 0.0000, 0.0000, 0.1098,\n","         0.0000, 0.0565, 0.0998, 0.0000, 0.0062, 0.0890, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0889, 0.0294, 0.0270, 0.0377, 0.0835, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0150, 0.0000, 0.0000, 0.0000, 0.1214, 0.0403, 0.0185,\n","         0.1249, 0.0000, 0.0661, 0.0000, 0.0000, 0.0455, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0381, 0.0000, 0.1116, 0.0000, 0.0588, 0.0889, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1270, 0.0346, 0.0956, 0.0393, 0.1317, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1149, 0.0000, 0.0608, 0.0000, 0.0000, 0.1098,\n","         0.0000, 0.0566, 0.0997, 0.0000, 0.0062, 0.0891, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0893, 0.0294, 0.0270, 0.0378, 0.0843, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0459, 0.0149, 0.0000, 0.0000, 0.0000, 0.1217, 0.0403, 0.0186,\n","         0.1250, 0.0000, 0.0662, 0.0000, 0.0000, 0.0455, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5171, 0.4829],\n","        [0.5156, 0.4844],\n","        [0.5177, 0.4823],\n","        [0.5176, 0.4824],\n","        [0.5190, 0.4810],\n","        [0.5164, 0.4836],\n","        [0.5177, 0.4823],\n","        [0.5181, 0.4819],\n","        [0.5161, 0.4839],\n","        [0.5156, 0.4844]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0810, 0.0000, 0.0580, 0.2335, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0489, 0.0468, 0.0043, 0.0891, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1293, 0.0000, 0.0460, 0.0000, 0.0000, 0.0847, 0.0000,\n","         0.0000, 0.0712, 0.0129, 0.0240, 0.0971, 0.0655, 0.2051, 0.0000, 0.0403,\n","         0.1664, 0.0000, 0.1373, 0.0000, 0.1124, 0.0000, 0.0773, 0.0000, 0.1177,\n","         0.1333, 0.0347, 0.0000, 0.1936, 0.0000, 0.0000, 0.0000, 0.0390, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0828, 0.0000, 0.1710, 0.0641,\n","         0.1221],\n","        [0.0809, 0.0000, 0.0580, 0.2334, 0.0000, 0.0314, 0.0000, 0.1240, 0.0850,\n","         0.0000, 0.0000, 0.0501, 0.0471, 0.0043, 0.0891, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1296, 0.0000, 0.0460, 0.0000, 0.0000, 0.0849, 0.0000,\n","         0.0000, 0.0712, 0.0130, 0.0247, 0.0971, 0.0655, 0.2047, 0.0000, 0.0403,\n","         0.1666, 0.0000, 0.1374, 0.0000, 0.1128, 0.0000, 0.0773, 0.0000, 0.1180,\n","         0.1335, 0.0347, 0.0000, 0.1937, 0.0000, 0.0000, 0.0000, 0.0394, 0.0000,\n","         0.0000, 0.0000, 0.2014, 0.0000, 0.0000, 0.0836, 0.0000, 0.1707, 0.0641,\n","         0.1222],\n","        [0.0857, 0.0000, 0.0608, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0634, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0018, 0.0000, 0.1356, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0214, 0.0292, 0.1109, 0.0671, 0.2113, 0.0000, 0.0275,\n","         0.1764, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0422, 0.0000, 0.2025, 0.0000, 0.0113, 0.0000, 0.0441, 0.0000,\n","         0.0000, 0.0043, 0.2054, 0.0000, 0.0000, 0.0942, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0905, 0.0000, 0.0594, 0.2449, 0.0000, 0.0312, 0.0000, 0.1276, 0.0941,\n","         0.0000, 0.0000, 0.0624, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1387, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0151, 0.0312, 0.1109, 0.0662, 0.2160, 0.0000, 0.0472,\n","         0.1840, 0.0000, 0.1367, 0.0000, 0.1167, 0.0000, 0.0864, 0.0000, 0.1282,\n","         0.1408, 0.0370, 0.0000, 0.2064, 0.0000, 0.0113, 0.0000, 0.0419, 0.0000,\n","         0.0000, 0.0073, 0.2095, 0.0000, 0.0000, 0.0943, 0.0000, 0.1812, 0.1025,\n","         0.1259],\n","        [0.0903, 0.0000, 0.0591, 0.2407, 0.0000, 0.0351, 0.0000, 0.1265, 0.0910,\n","         0.0000, 0.0000, 0.0618, 0.0438, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1380, 0.0000, 0.0636, 0.0000, 0.0198, 0.0815, 0.0000,\n","         0.0000, 0.0707, 0.0146, 0.0310, 0.1109, 0.0634, 0.2157, 0.0000, 0.0415,\n","         0.1836, 0.0000, 0.1346, 0.0000, 0.1143, 0.0000, 0.0864, 0.0000, 0.1184,\n","         0.1351, 0.0291, 0.0000, 0.2060, 0.0000, 0.0113, 0.0000, 0.0416, 0.0000,\n","         0.0000, 0.0071, 0.2055, 0.0000, 0.0000, 0.0941, 0.0000, 0.1806, 0.1025,\n","         0.1221],\n","        [0.0843, 0.0000, 0.0591, 0.2100, 0.0000, 0.0309, 0.0000, 0.1448, 0.0767,\n","         0.0000, 0.0000, 0.0526, 0.0793, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1309, 0.0000, 0.0636, 0.0000, 0.0198, 0.0843, 0.0000,\n","         0.0000, 0.0633, 0.0153, 0.0256, 0.1109, 0.0907, 0.2003, 0.0000, 0.0525,\n","         0.1773, 0.0000, 0.1762, 0.0000, 0.1057, 0.0457, 0.1201, 0.0000, 0.1394,\n","         0.0984, 0.0362, 0.0000, 0.2165, 0.0000, 0.0113, 0.0000, 0.0400, 0.0000,\n","         0.0000, 0.0019, 0.2005, 0.0000, 0.0000, 0.0862, 0.0000, 0.1578, 0.1025,\n","         0.0986],\n","        [0.0867, 0.0000, 0.0594, 0.2343, 0.0000, 0.0422, 0.0000, 0.1246, 0.0921,\n","         0.0000, 0.0000, 0.0507, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1326, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0151, 0.0262, 0.1109, 0.0662, 0.2065, 0.0000, 0.0404,\n","         0.1745, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0370, 0.0000, 0.2025, 0.0000, 0.0113, 0.0000, 0.0381, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0885, 0.0000, 0.1726, 0.1025,\n","         0.1327],\n","        [0.0822, 0.0000, 0.0594, 0.2334, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0539, 0.0469, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1315, 0.0000, 0.0636, 0.0000, 0.0198, 0.0847, 0.0000,\n","         0.0000, 0.0712, 0.0167, 0.0258, 0.1109, 0.0659, 0.2047, 0.0000, 0.0403,\n","         0.1685, 0.0000, 0.1373, 0.0000, 0.1125, 0.0000, 0.0864, 0.0000, 0.1178,\n","         0.1333, 0.0370, 0.0000, 0.1953, 0.0000, 0.0113, 0.0000, 0.0405, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0871, 0.0000, 0.1707, 0.1025,\n","         0.1221],\n","        [0.0864, 0.0000, 0.0549, 0.2370, 0.0000, 0.0314, 0.0000, 0.1265, 0.0897,\n","         0.0000, 0.0000, 0.0370, 0.0471, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1305, 0.0000, 0.0636, 0.0000, 0.0198, 0.0849, 0.0000,\n","         0.0000, 0.0720, 0.0046, 0.0222, 0.1109, 0.0630, 0.2164, 0.0000, 0.0403,\n","         0.1809, 0.0000, 0.1374, 0.0000, 0.1128, 0.0000, 0.0864, 0.0000, 0.1180,\n","         0.1335, 0.0221, 0.0000, 0.1980, 0.0000, 0.0113, 0.0000, 0.0340, 0.0000,\n","         0.0000, 0.0000, 0.2067, 0.0000, 0.0000, 0.0828, 0.0000, 0.1811, 0.1025,\n","         0.1222],\n","        [0.0832, 0.0000, 0.0588, 0.2334, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0543, 0.0469, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1328, 0.0000, 0.0636, 0.0000, 0.0198, 0.0847, 0.0000,\n","         0.0000, 0.0712, 0.0127, 0.0281, 0.1109, 0.0644, 0.2052, 0.0000, 0.0403,\n","         0.1724, 0.0000, 0.1373, 0.0000, 0.1125, 0.0000, 0.0864, 0.0000, 0.1178,\n","         0.1333, 0.0338, 0.0000, 0.1969, 0.0000, 0.0113, 0.0000, 0.0402, 0.0000,\n","         0.0000, 0.0024, 0.2013, 0.0000, 0.0000, 0.0863, 0.0000, 0.1707, 0.1025,\n","         0.1221]], grad_fn=<MaxBackward0>), tensor([[0.0372, 0.0000, 0.1118, 0.0000, 0.0596, 0.0889, 0.0000, 0.0000, 0.0619,\n","         0.0000, 0.0000, 0.1269, 0.0339, 0.0964, 0.0409, 0.1327, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1162, 0.0000, 0.0605, 0.0000, 0.0000, 0.1107,\n","         0.0000, 0.0562, 0.0997, 0.0000, 0.0071, 0.0884, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0894, 0.0302, 0.0268, 0.0367, 0.0838, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0157, 0.0000, 0.0000, 0.0000, 0.1202, 0.0399, 0.0182,\n","         0.1251, 0.0000, 0.0658, 0.0000, 0.0000, 0.0438, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0372, 0.0000, 0.1118, 0.0000, 0.0596, 0.0889, 0.0000, 0.0000, 0.0619,\n","         0.0000, 0.0000, 0.1269, 0.0339, 0.0964, 0.0409, 0.1327, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1162, 0.0000, 0.0605, 0.0000, 0.0000, 0.1107,\n","         0.0000, 0.0562, 0.0997, 0.0000, 0.0071, 0.0884, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0894, 0.0302, 0.0268, 0.0367, 0.0838, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0157, 0.0000, 0.0000, 0.0000, 0.1202, 0.0399, 0.0182,\n","         0.1251, 0.0000, 0.0658, 0.0000, 0.0000, 0.0438, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1110, 0.0000, 0.0590, 0.0889, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1265, 0.0342, 0.0960, 0.0399, 0.1319, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1156, 0.0000, 0.0608, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0563, 0.0998, 0.0000, 0.0064, 0.0890, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0892, 0.0297, 0.0270, 0.0373, 0.0834, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1208, 0.0402, 0.0184,\n","         0.1251, 0.0000, 0.0659, 0.0000, 0.0000, 0.0450, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1112, 0.0000, 0.0591, 0.0889, 0.0000, 0.0000, 0.0614,\n","         0.0000, 0.0000, 0.1266, 0.0342, 0.0959, 0.0401, 0.1321, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1157, 0.0000, 0.0608, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0564, 0.0999, 0.0000, 0.0064, 0.0890, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0893, 0.0297, 0.0271, 0.0372, 0.0839, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1208, 0.0402, 0.0183,\n","         0.1251, 0.0000, 0.0659, 0.0000, 0.0000, 0.0450, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1107, 0.0000, 0.0587, 0.0889, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1264, 0.0344, 0.0956, 0.0393, 0.1316, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1153, 0.0000, 0.0611, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0565, 0.1000, 0.0000, 0.0059, 0.0895, 0.0000, 0.0282, 0.0000,\n","         0.0000, 0.0892, 0.0293, 0.0273, 0.0375, 0.0838, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0153, 0.0000, 0.0000, 0.0000, 0.1213, 0.0404, 0.0183,\n","         0.1250, 0.0000, 0.0660, 0.0000, 0.0000, 0.0459, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1110, 0.0000, 0.0590, 0.0888, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1265, 0.0341, 0.0958, 0.0399, 0.1321, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1158, 0.0000, 0.0610, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0563, 0.1000, 0.0000, 0.0063, 0.0893, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0892, 0.0295, 0.0273, 0.0371, 0.0839, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1210, 0.0403, 0.0182,\n","         0.1249, 0.0000, 0.0659, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1114, 0.0000, 0.0592, 0.0890, 0.0000, 0.0000, 0.0615,\n","         0.0000, 0.0000, 0.1268, 0.0342, 0.0961, 0.0402, 0.1321, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1156, 0.0000, 0.0606, 0.0000, 0.0000, 0.1104,\n","         0.0000, 0.0563, 0.0997, 0.0000, 0.0067, 0.0888, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0893, 0.0299, 0.0269, 0.0372, 0.0837, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0458, 0.0155, 0.0000, 0.0000, 0.0000, 0.1207, 0.0400, 0.0184,\n","         0.1253, 0.0000, 0.0659, 0.0000, 0.0000, 0.0446, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0371, 0.0000, 0.1116, 0.0000, 0.0596, 0.0889, 0.0000, 0.0000, 0.0618,\n","         0.0000, 0.0000, 0.1268, 0.0338, 0.0963, 0.0408, 0.1327, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1164, 0.0000, 0.0607, 0.0000, 0.0000, 0.1107,\n","         0.0000, 0.0562, 0.0998, 0.0000, 0.0069, 0.0886, 0.0000, 0.0289, 0.0000,\n","         0.0000, 0.0893, 0.0301, 0.0270, 0.0367, 0.0838, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0456, 0.0158, 0.0000, 0.0000, 0.0000, 0.1202, 0.0400, 0.0182,\n","         0.1248, 0.0000, 0.0658, 0.0000, 0.0000, 0.0441, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1119, 0.0000, 0.0594, 0.0892, 0.0000, 0.0000, 0.0617,\n","         0.0000, 0.0000, 0.1270, 0.0342, 0.0962, 0.0404, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1156, 0.0000, 0.0605, 0.0000, 0.0000, 0.1105,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0069, 0.0886, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0895, 0.0300, 0.0268, 0.0372, 0.0841, 0.0000, 0.0518, 0.0000,\n","         0.0000, 0.0458, 0.0155, 0.0000, 0.0000, 0.0000, 0.1206, 0.0399, 0.0183,\n","         0.1254, 0.0000, 0.0659, 0.0000, 0.0000, 0.0442, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1110, 0.0000, 0.0591, 0.0888, 0.0000, 0.0000, 0.0614,\n","         0.0000, 0.0000, 0.1265, 0.0340, 0.0959, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1159, 0.0000, 0.0610, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0563, 0.0999, 0.0000, 0.0064, 0.0891, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0892, 0.0296, 0.0272, 0.0371, 0.0838, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0156, 0.0000, 0.0000, 0.0000, 0.1208, 0.0402, 0.0183,\n","         0.1248, 0.0000, 0.0659, 0.0000, 0.0000, 0.0451, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5157, 0.4843],\n","        [0.5158, 0.4842],\n","        [0.5187, 0.4813],\n","        [0.5179, 0.4821],\n","        [0.5176, 0.4824],\n","        [0.5185, 0.4815],\n","        [0.5178, 0.4822],\n","        [0.5170, 0.4830],\n","        [0.5167, 0.4833],\n","        [0.5169, 0.4831]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0899, 0.0000, 0.0640, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0468, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1335, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0142, 0.0262, 0.1109, 0.0747, 0.2061, 0.0000, 0.0436,\n","         0.1984, 0.0000, 0.1367, 0.0000, 0.1121, 0.0044, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0355, 0.0000, 0.2055, 0.0000, 0.0113, 0.0000, 0.0380, 0.0000,\n","         0.0000, 0.0057, 0.2024, 0.0000, 0.0000, 0.0816, 0.0000, 0.1726, 0.1025,\n","         0.1216],\n","        [0.0980, 0.0000, 0.0674, 0.2086, 0.0000, 0.0309, 0.0000, 0.1251, 0.0789,\n","         0.0000, 0.0000, 0.0509, 0.0322, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1417, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0151, 0.0327, 0.1109, 0.0773, 0.2102, 0.0000, 0.0462,\n","         0.2129, 0.0000, 0.1232, 0.0000, 0.1015, 0.0068, 0.0864, 0.0000, 0.1254,\n","         0.0800, 0.0370, 0.0000, 0.2161, 0.0000, 0.0113, 0.0000, 0.0391, 0.0000,\n","         0.0000, 0.0143, 0.2041, 0.0000, 0.0000, 0.0830, 0.0000, 0.1588, 0.1025,\n","         0.0949],\n","        [0.0839, 0.0000, 0.0573, 0.2343, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0438, 0.0709, 0.0095, 0.1081, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0492, 0.0000, 0.0003, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0123, 0.0342, 0.1035, 0.0766, 0.2213, 0.0000, 0.0540,\n","         0.1634, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0790, 0.0080, 0.1267,\n","         0.1469, 0.0331, 0.0000, 0.2079, 0.0000, 0.0000, 0.0000, 0.0363, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0804, 0.0000, 0.1856, 0.0635,\n","         0.1327],\n","        [0.0841, 0.0000, 0.0597, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0607, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0007, 0.0000, 0.1339, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0174, 0.0296, 0.1109, 0.0748, 0.2103, 0.0000, 0.0399,\n","         0.1749, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0374, 0.0000, 0.2046, 0.0000, 0.0113, 0.0000, 0.0430, 0.0000,\n","         0.0000, 0.0043, 0.2024, 0.0000, 0.0000, 0.0911, 0.0000, 0.1726, 0.1025,\n","         0.1216],\n","        [0.0841, 0.0000, 0.0597, 0.2357, 0.0000, 0.0309, 0.0000, 0.1255, 0.0877,\n","         0.0000, 0.0000, 0.0607, 0.0445, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0007, 0.0000, 0.1339, 0.0000, 0.0636, 0.0000, 0.0198, 0.0831, 0.0000,\n","         0.0000, 0.0716, 0.0174, 0.0296, 0.1109, 0.0655, 0.2103, 0.0000, 0.0390,\n","         0.1749, 0.0000, 0.1357, 0.0000, 0.1109, 0.0000, 0.0864, 0.0000, 0.1151,\n","         0.1326, 0.0374, 0.0000, 0.2000, 0.0000, 0.0113, 0.0000, 0.0430, 0.0000,\n","         0.0000, 0.0043, 0.2043, 0.0000, 0.0000, 0.0911, 0.0000, 0.1777, 0.1025,\n","         0.1200],\n","        [0.0737, 0.0000, 0.0550, 0.2449, 0.0000, 0.0422, 0.0000, 0.1276, 0.0941,\n","         0.0000, 0.0000, 0.0333, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1213, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0057, 0.0233, 0.1109, 0.0625, 0.2114, 0.0000, 0.0472,\n","         0.1556, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1282,\n","         0.1469, 0.0259, 0.0000, 0.1958, 0.0000, 0.0113, 0.0000, 0.0339, 0.0000,\n","         0.0000, 0.0000, 0.2095, 0.0000, 0.0000, 0.0702, 0.0000, 0.1812, 0.1025,\n","         0.1327],\n","        [0.0836, 0.0000, 0.0593, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0573, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1333, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0162, 0.0287, 0.1109, 0.0656, 0.2075, 0.0000, 0.0275,\n","         0.1737, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0362, 0.0000, 0.1985, 0.0000, 0.0113, 0.0000, 0.0416, 0.0000,\n","         0.0000, 0.0033, 0.2054, 0.0000, 0.0000, 0.0886, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0769, 0.0000, 0.0555, 0.2343, 0.0000, 0.0422, 0.0000, 0.1246, 0.0921,\n","         0.0000, 0.0000, 0.0348, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1218, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0061, 0.0219, 0.1109, 0.0699, 0.2061, 0.0000, 0.0419,\n","         0.1593, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0268, 0.0000, 0.2024, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0719, 0.0000, 0.1726, 0.1025,\n","         0.1327],\n","        [0.0905, 0.0000, 0.0594, 0.2343, 0.0000, 0.0422, 0.0000, 0.1246, 0.0921,\n","         0.0000, 0.0000, 0.0624, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1387, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0150, 0.0312, 0.1109, 0.0638, 0.2160, 0.0000, 0.0399,\n","         0.1840, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0298, 0.0000, 0.2064, 0.0000, 0.0113, 0.0000, 0.0419, 0.0000,\n","         0.0000, 0.0073, 0.2054, 0.0000, 0.0000, 0.0943, 0.0000, 0.1726, 0.1025,\n","         0.1327],\n","        [0.0975, 0.0000, 0.0621, 0.2069, 0.0000, 0.0309, 0.0000, 0.1006, 0.0531,\n","         0.0000, 0.0000, 0.0795, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1499, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0205, 0.0393, 0.1109, 0.0660, 0.2337, 0.0000, 0.0246,\n","         0.1984, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.1100,\n","         0.0562, 0.0362, 0.0000, 0.2179, 0.0000, 0.0113, 0.0000, 0.0460, 0.0000,\n","         0.0000, 0.0149, 0.1730, 0.0000, 0.0000, 0.1052, 0.0000, 0.1698, 0.1025,\n","         0.0934]], grad_fn=<MaxBackward0>), tensor([[0.0375, 0.0000, 0.1110, 0.0000, 0.0588, 0.0884, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1266, 0.0342, 0.0956, 0.0396, 0.1319, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1155, 0.0000, 0.0609, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0564, 0.0998, 0.0000, 0.0063, 0.0890, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0888, 0.0294, 0.0271, 0.0374, 0.0834, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1212, 0.0404, 0.0185,\n","         0.1248, 0.0000, 0.0660, 0.0000, 0.0000, 0.0453, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1102, 0.0000, 0.0584, 0.0884, 0.0000, 0.0000, 0.0606,\n","         0.0000, 0.0000, 0.1262, 0.0344, 0.0952, 0.0388, 0.1315, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1153, 0.0000, 0.0612, 0.0000, 0.0000, 0.1096,\n","         0.0000, 0.0565, 0.1000, 0.0000, 0.0057, 0.0896, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0887, 0.0290, 0.0275, 0.0377, 0.0833, 0.0000, 0.0513, 0.0000,\n","         0.0000, 0.0457, 0.0150, 0.0000, 0.0000, 0.0000, 0.1218, 0.0406, 0.0185,\n","         0.1246, 0.0000, 0.0661, 0.0000, 0.0000, 0.0465, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1120, 0.0000, 0.0592, 0.0887, 0.0000, 0.0000, 0.0614,\n","         0.0000, 0.0000, 0.1272, 0.0342, 0.0961, 0.0404, 0.1323, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1154, 0.0000, 0.0604, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0563, 0.0996, 0.0000, 0.0069, 0.0883, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0891, 0.0301, 0.0266, 0.0373, 0.0836, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1208, 0.0399, 0.0185,\n","         0.1253, 0.0000, 0.0660, 0.0000, 0.0000, 0.0441, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1114, 0.0000, 0.0591, 0.0885, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1268, 0.0341, 0.0958, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1157, 0.0000, 0.0608, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0563, 0.0998, 0.0000, 0.0065, 0.0887, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0889, 0.0297, 0.0270, 0.0372, 0.0835, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0153, 0.0000, 0.0000, 0.0000, 0.1210, 0.0402, 0.0184,\n","         0.1248, 0.0000, 0.0660, 0.0000, 0.0000, 0.0448, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1111, 0.0000, 0.0588, 0.0885, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1266, 0.0343, 0.0956, 0.0396, 0.1319, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1154, 0.0000, 0.0610, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0564, 0.0998, 0.0000, 0.0061, 0.0891, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0890, 0.0294, 0.0271, 0.0375, 0.0837, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1214, 0.0404, 0.0185,\n","         0.1247, 0.0000, 0.0660, 0.0000, 0.0000, 0.0456, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1111, 0.0000, 0.0586, 0.0886, 0.0000, 0.0000, 0.0608,\n","         0.0000, 0.0000, 0.1267, 0.0345, 0.0956, 0.0393, 0.1316, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1149, 0.0000, 0.0607, 0.0000, 0.0000, 0.1098,\n","         0.0000, 0.0565, 0.0997, 0.0000, 0.0062, 0.0890, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0889, 0.0295, 0.0269, 0.0378, 0.0833, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0459, 0.0149, 0.0000, 0.0000, 0.0000, 0.1214, 0.0403, 0.0186,\n","         0.1252, 0.0000, 0.0661, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1114, 0.0000, 0.0591, 0.0885, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1268, 0.0341, 0.0959, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1157, 0.0000, 0.0608, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0563, 0.0997, 0.0000, 0.0065, 0.0888, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0890, 0.0297, 0.0269, 0.0373, 0.0835, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0153, 0.0000, 0.0000, 0.0000, 0.1210, 0.0403, 0.0185,\n","         0.1248, 0.0000, 0.0659, 0.0000, 0.0000, 0.0449, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1112, 0.0000, 0.0588, 0.0886, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1268, 0.0343, 0.0957, 0.0395, 0.1317, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1151, 0.0000, 0.0607, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0565, 0.0997, 0.0000, 0.0064, 0.0888, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0889, 0.0296, 0.0269, 0.0376, 0.0833, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0459, 0.0150, 0.0000, 0.0000, 0.0000, 0.1213, 0.0402, 0.0185,\n","         0.1251, 0.0000, 0.0661, 0.0000, 0.0000, 0.0451, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1114, 0.0000, 0.0590, 0.0886, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1268, 0.0343, 0.0958, 0.0398, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1153, 0.0000, 0.0607, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0064, 0.0888, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0890, 0.0296, 0.0269, 0.0375, 0.0835, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1211, 0.0402, 0.0185,\n","         0.1250, 0.0000, 0.0660, 0.0000, 0.0000, 0.0450, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1108, 0.0000, 0.0588, 0.0885, 0.0000, 0.0000, 0.0608,\n","         0.0000, 0.0000, 0.1265, 0.0343, 0.0954, 0.0394, 0.1319, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1156, 0.0000, 0.0612, 0.0000, 0.0000, 0.1098,\n","         0.0000, 0.0565, 0.0999, 0.0000, 0.0059, 0.0894, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0890, 0.0292, 0.0273, 0.0375, 0.0838, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0457, 0.0152, 0.0000, 0.0000, 0.0000, 0.1216, 0.0405, 0.0185,\n","         0.1245, 0.0000, 0.0660, 0.0000, 0.0000, 0.0460, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5167, 0.4833],\n","        [0.5171, 0.4829],\n","        [0.5172, 0.4828],\n","        [0.5174, 0.4826],\n","        [0.5175, 0.4825],\n","        [0.5174, 0.4826],\n","        [0.5180, 0.4820],\n","        [0.5169, 0.4831],\n","        [0.5185, 0.4815],\n","        [0.5166, 0.4834]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0810, 0.0000, 0.0578, 0.2335, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0489, 0.0468, 0.0043, 0.0891, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1293, 0.0000, 0.0460, 0.0000, 0.0000, 0.0847, 0.0000,\n","         0.0000, 0.0712, 0.0126, 0.0240, 0.0971, 0.0643, 0.2048, 0.0000, 0.0403,\n","         0.1664, 0.0000, 0.1373, 0.0000, 0.1124, 0.0000, 0.0773, 0.0000, 0.1177,\n","         0.1333, 0.0322, 0.0000, 0.1936, 0.0000, 0.0000, 0.0000, 0.0390, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0828, 0.0000, 0.1707, 0.0641,\n","         0.1221],\n","        [0.0832, 0.0000, 0.0599, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0519, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1324, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0158, 0.0244, 0.1109, 0.0658, 0.1983, 0.0000, 0.0275,\n","         0.1679, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0352, 0.0000, 0.1945, 0.0000, 0.0113, 0.0000, 0.0390, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0863, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0905, 0.0000, 0.0594, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0624, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1387, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0150, 0.0312, 0.1109, 0.0638, 0.2160, 0.0000, 0.0399,\n","         0.1840, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0298, 0.0000, 0.2064, 0.0000, 0.0113, 0.0000, 0.0419, 0.0000,\n","         0.0000, 0.0073, 0.2024, 0.0000, 0.0000, 0.0943, 0.0000, 0.1726, 0.1025,\n","         0.1216],\n","        [0.0895, 0.0000, 0.0618, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0627, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1395, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0199, 0.0297, 0.1109, 0.0664, 0.2123, 0.0000, 0.0399,\n","         0.1809, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0387, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0425, 0.0000,\n","         0.0000, 0.0051, 0.2024, 0.0000, 0.0000, 0.0948, 0.0000, 0.1726, 0.1025,\n","         0.1216],\n","        [0.0841, 0.0000, 0.0597, 0.2356, 0.0000, 0.0309, 0.0000, 0.1256, 0.0878,\n","         0.0000, 0.0000, 0.0607, 0.0452, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0007, 0.0000, 0.1339, 0.0000, 0.0636, 0.0000, 0.0198, 0.0833, 0.0000,\n","         0.0000, 0.0717, 0.0174, 0.0296, 0.1109, 0.0655, 0.2103, 0.0000, 0.0390,\n","         0.1749, 0.0000, 0.1357, 0.0000, 0.1109, 0.0000, 0.0864, 0.0000, 0.1157,\n","         0.1332, 0.0374, 0.0000, 0.2000, 0.0000, 0.0113, 0.0000, 0.0430, 0.0000,\n","         0.0000, 0.0043, 0.2045, 0.0000, 0.0000, 0.0911, 0.0000, 0.1770, 0.1025,\n","         0.1202],\n","        [0.0919, 0.0000, 0.0555, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0348, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1218, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0061, 0.0199, 0.1109, 0.0629, 0.1956, 0.0000, 0.0275,\n","         0.1736, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0268, 0.0000, 0.1922, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0064, 0.2054, 0.0000, 0.0000, 0.0860, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0880, 0.0000, 0.0610, 0.2344, 0.0000, 0.0422, 0.0000, 0.1244, 0.0921,\n","         0.0000, 0.0000, 0.0623, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1384, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0173, 0.0303, 0.1109, 0.0735, 0.2127, 0.0000, 0.0434,\n","         0.1880, 0.0000, 0.1555, 0.0000, 0.1194, 0.0038, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0334, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2054, 0.0000, 0.0000, 0.0931, 0.0000, 0.1714, 0.1025,\n","         0.1327],\n","        [0.0883, 0.0000, 0.0610, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0623, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1384, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0173, 0.0303, 0.1109, 0.0649, 0.2127, 0.0000, 0.0399,\n","         0.1808, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0334, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2024, 0.0000, 0.0000, 0.0931, 0.0000, 0.1726, 0.1025,\n","         0.1216],\n","        [0.0820, 0.0000, 0.0580, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0474, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1297, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0123, 0.0237, 0.1109, 0.0729, 0.1971, 0.0000, 0.0300,\n","         0.1673, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0306, 0.0000, 0.2107, 0.0000, 0.0113, 0.0000, 0.0378, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0853, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0880, 0.0000, 0.0610, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0623, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1384, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0173, 0.0303, 0.1109, 0.0649, 0.2127, 0.0000, 0.0275,\n","         0.1808, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0334, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2054, 0.0000, 0.0000, 0.0931, 0.0000, 0.1579, 0.1025,\n","         0.1327]], grad_fn=<MaxBackward0>), tensor([[0.0372, 0.0000, 0.1118, 0.0000, 0.0596, 0.0889, 0.0000, 0.0000, 0.0619,\n","         0.0000, 0.0000, 0.1269, 0.0339, 0.0964, 0.0409, 0.1327, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1162, 0.0000, 0.0605, 0.0000, 0.0000, 0.1107,\n","         0.0000, 0.0562, 0.0997, 0.0000, 0.0071, 0.0884, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0894, 0.0302, 0.0268, 0.0367, 0.0838, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0157, 0.0000, 0.0000, 0.0000, 0.1202, 0.0399, 0.0182,\n","         0.1251, 0.0000, 0.0658, 0.0000, 0.0000, 0.0438, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1106, 0.0000, 0.0587, 0.0888, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1264, 0.0342, 0.0958, 0.0394, 0.1316, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1153, 0.0000, 0.0609, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0564, 0.0998, 0.0000, 0.0061, 0.0893, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0890, 0.0294, 0.0271, 0.0375, 0.0832, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0153, 0.0000, 0.0000, 0.0000, 0.1210, 0.0403, 0.0184,\n","         0.1251, 0.0000, 0.0659, 0.0000, 0.0000, 0.0455, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1107, 0.0000, 0.0589, 0.0888, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1264, 0.0342, 0.0957, 0.0397, 0.1319, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1157, 0.0000, 0.0611, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0564, 0.1000, 0.0000, 0.0061, 0.0893, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0892, 0.0294, 0.0273, 0.0373, 0.0837, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1211, 0.0404, 0.0183,\n","         0.1249, 0.0000, 0.0659, 0.0000, 0.0000, 0.0456, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0372, 0.0000, 0.1115, 0.0000, 0.0595, 0.0889, 0.0000, 0.0000, 0.0617,\n","         0.0000, 0.0000, 0.1267, 0.0339, 0.0961, 0.0406, 0.1326, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1162, 0.0000, 0.0608, 0.0000, 0.0000, 0.1106,\n","         0.0000, 0.0562, 0.0998, 0.0000, 0.0067, 0.0887, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0893, 0.0299, 0.0270, 0.0368, 0.0839, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0456, 0.0157, 0.0000, 0.0000, 0.0000, 0.1204, 0.0401, 0.0182,\n","         0.1248, 0.0000, 0.0658, 0.0000, 0.0000, 0.0444, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1110, 0.0000, 0.0591, 0.0888, 0.0000, 0.0000, 0.0614,\n","         0.0000, 0.0000, 0.1265, 0.0341, 0.0958, 0.0400, 0.1321, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1158, 0.0000, 0.0610, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0563, 0.0999, 0.0000, 0.0063, 0.0892, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0892, 0.0296, 0.0272, 0.0371, 0.0838, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1209, 0.0403, 0.0183,\n","         0.1249, 0.0000, 0.0659, 0.0000, 0.0000, 0.0452, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1103, 0.0000, 0.0583, 0.0890, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1263, 0.0346, 0.0953, 0.0387, 0.1313, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1150, 0.0000, 0.0613, 0.0000, 0.0000, 0.1096,\n","         0.0000, 0.0566, 0.1000, 0.0000, 0.0056, 0.0900, 0.0000, 0.0280, 0.0000,\n","         0.0000, 0.0892, 0.0289, 0.0275, 0.0378, 0.0839, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1217, 0.0407, 0.0184,\n","         0.1250, 0.0000, 0.0661, 0.0000, 0.0000, 0.0467, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1105, 0.0000, 0.0587, 0.0887, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1263, 0.0342, 0.0957, 0.0394, 0.1316, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1153, 0.0000, 0.0609, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0563, 0.0999, 0.0000, 0.0062, 0.0893, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0890, 0.0294, 0.0271, 0.0374, 0.0831, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0153, 0.0000, 0.0000, 0.0000, 0.1210, 0.0403, 0.0183,\n","         0.1252, 0.0000, 0.0659, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1110, 0.0000, 0.0589, 0.0890, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1265, 0.0343, 0.0957, 0.0396, 0.1319, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1155, 0.0000, 0.0610, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0564, 0.0999, 0.0000, 0.0061, 0.0894, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0894, 0.0294, 0.0272, 0.0374, 0.0841, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0154, 0.0000, 0.0000, 0.0000, 0.1212, 0.0404, 0.0183,\n","         0.1249, 0.0000, 0.0660, 0.0000, 0.0000, 0.0456, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0371, 0.0000, 0.1104, 0.0000, 0.0588, 0.0886, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1262, 0.0340, 0.0958, 0.0396, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1157, 0.0000, 0.0610, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0563, 0.0999, 0.0000, 0.0062, 0.0892, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0890, 0.0295, 0.0272, 0.0372, 0.0831, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0154, 0.0000, 0.0000, 0.0000, 0.1209, 0.0403, 0.0183,\n","         0.1249, 0.0000, 0.0659, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1091, 0.0000, 0.0578, 0.0887, 0.0000, 0.0000, 0.0605,\n","         0.0000, 0.0000, 0.1257, 0.0346, 0.0949, 0.0379, 0.1306, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1148, 0.0000, 0.0615, 0.0000, 0.0000, 0.1094,\n","         0.0000, 0.0567, 0.1001, 0.0000, 0.0052, 0.0904, 0.0000, 0.0279, 0.0000,\n","         0.0000, 0.0887, 0.0286, 0.0278, 0.0380, 0.0828, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0458, 0.0150, 0.0000, 0.0000, 0.0000, 0.1219, 0.0408, 0.0184,\n","         0.1249, 0.0000, 0.0662, 0.0000, 0.0000, 0.0474, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5157, 0.4843],\n","        [0.5174, 0.4826],\n","        [0.5176, 0.4824],\n","        [0.5175, 0.4825],\n","        [0.5175, 0.4825],\n","        [0.5165, 0.4835],\n","        [0.5184, 0.4816],\n","        [0.5175, 0.4825],\n","        [0.5169, 0.4831],\n","        [0.5186, 0.4814]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0723, 0.0000, 0.0516, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0213, 0.0464, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1153, 0.0000, 0.0636, 0.0000, 0.0198, 0.0842, 0.0000,\n","         0.0000, 0.0714, 0.0000, 0.0219, 0.1109, 0.0603, 0.2061, 0.0000, 0.0399,\n","         0.1525, 0.0000, 0.1367, 0.0000, 0.1121, 0.0000, 0.0864, 0.0000, 0.1172,\n","         0.1335, 0.0142, 0.0000, 0.1840, 0.0000, 0.0113, 0.0000, 0.0289, 0.0000,\n","         0.0000, 0.0000, 0.2024, 0.0000, 0.0000, 0.0637, 0.0000, 0.1726, 0.1025,\n","         0.1216],\n","        [0.0779, 0.0000, 0.0546, 0.2353, 0.0000, 0.0422, 0.0000, 0.1248, 0.0921,\n","         0.0000, 0.0000, 0.0338, 0.0709, 0.0041, 0.0921, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1206, 0.0000, 0.0462, 0.0000, 0.0003, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0061, 0.0218, 0.0958, 0.0617, 0.2073, 0.0000, 0.0420,\n","         0.1573, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0790, 0.0000, 0.1267,\n","         0.1469, 0.0254, 0.0000, 0.1863, 0.0000, 0.0000, 0.0000, 0.0333, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0757, 0.0000, 0.1748, 0.0645,\n","         0.1327],\n","        [0.0808, 0.0000, 0.0553, 0.2329, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0408, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0078, 0.0342, 0.1109, 0.0625, 0.2213, 0.0000, 0.0540,\n","         0.1630, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0259, 0.0000, 0.1902, 0.0000, 0.0113, 0.0000, 0.0352, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0786, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0808, 0.0000, 0.0553, 0.2329, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0408, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0078, 0.0342, 0.1109, 0.0616, 0.2213, 0.0000, 0.0540,\n","         0.1630, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0252, 0.0000, 0.1902, 0.0000, 0.0113, 0.0000, 0.0352, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0786, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0833, 0.0000, 0.0594, 0.2334, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0553, 0.0469, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1331, 0.0000, 0.0636, 0.0000, 0.0198, 0.0847, 0.0000,\n","         0.0000, 0.0712, 0.0151, 0.0287, 0.1109, 0.0662, 0.2061, 0.0000, 0.0403,\n","         0.1726, 0.0000, 0.1373, 0.0000, 0.1125, 0.0000, 0.0864, 0.0000, 0.1178,\n","         0.1333, 0.0370, 0.0000, 0.1969, 0.0000, 0.0113, 0.0000, 0.0404, 0.0000,\n","         0.0000, 0.0028, 0.2013, 0.0000, 0.0000, 0.0870, 0.0000, 0.1707, 0.1025,\n","         0.1221],\n","        [0.0891, 0.0000, 0.0576, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0859,\n","         0.0000, 0.0000, 0.0500, 0.0461, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1354, 0.0000, 0.0636, 0.0000, 0.0198, 0.0841, 0.0000,\n","         0.0000, 0.0714, 0.0205, 0.0287, 0.1109, 0.0796, 0.2156, 0.0000, 0.0440,\n","         0.1826, 0.0000, 0.1365, 0.0000, 0.1117, 0.0000, 0.0864, 0.0000, 0.1168,\n","         0.1332, 0.0312, 0.0000, 0.2238, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2023, 0.0000, 0.0000, 0.0915, 0.0000, 0.1729, 0.1025,\n","         0.1216],\n","        [0.0901, 0.0000, 0.0591, 0.2335, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0595, 0.0466, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1381, 0.0000, 0.0636, 0.0000, 0.0198, 0.0846, 0.0000,\n","         0.0000, 0.0712, 0.0126, 0.0306, 0.1109, 0.0644, 0.2137, 0.0000, 0.0403,\n","         0.1829, 0.0000, 0.1372, 0.0000, 0.1122, 0.0000, 0.0864, 0.0000, 0.1175,\n","         0.1331, 0.0314, 0.0000, 0.2049, 0.0000, 0.0113, 0.0000, 0.0406, 0.0000,\n","         0.0000, 0.0064, 0.2013, 0.0000, 0.0000, 0.0921, 0.0000, 0.1709, 0.1025,\n","         0.1221],\n","        [0.0813, 0.0000, 0.0580, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0474, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1297, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0111, 0.0237, 0.1109, 0.0646, 0.1954, 0.0000, 0.0275,\n","         0.1655, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0319, 0.0000, 0.1925, 0.0000, 0.0113, 0.0000, 0.0378, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0819, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0911, 0.0000, 0.0610, 0.2407, 0.0000, 0.0309, 0.0000, 0.1265, 0.0910,\n","         0.0000, 0.0000, 0.0690, 0.0438, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1416, 0.0000, 0.0636, 0.0000, 0.0198, 0.0802, 0.0000,\n","         0.0000, 0.0707, 0.0194, 0.0335, 0.1109, 0.0658, 0.2208, 0.0000, 0.0415,\n","         0.1868, 0.0000, 0.1346, 0.0000, 0.1124, 0.0000, 0.0864, 0.0000, 0.1184,\n","         0.1351, 0.0360, 0.0000, 0.2092, 0.0000, 0.0113, 0.0000, 0.0446, 0.0000,\n","         0.0000, 0.0092, 0.2055, 0.0000, 0.0000, 0.0979, 0.0000, 0.1806, 0.1025,\n","         0.1221],\n","        [0.0320, 0.0000, 0.0453, 0.0950, 0.0000, 0.0309, 0.0000, 0.0781, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.0812, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0000, 0.0000, 0.1109, 0.0527, 0.0741, 0.0000, 0.0024,\n","         0.0643, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0299,\n","         0.0536, 0.0000, 0.0000, 0.1006, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0015, 0.1025,\n","         0.0934]], grad_fn=<MaxBackward0>), tensor([[3.7569e-02, 0.0000e+00, 1.1038e-01, 0.0000e+00, 5.8380e-02, 8.8733e-02,\n","         0.0000e+00, 0.0000e+00, 6.0845e-02, 0.0000e+00, 0.0000e+00, 1.2632e-01,\n","         3.4444e-02, 9.5399e-02, 3.8896e-02, 1.3135e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3751e-02, 1.1498e-01, 0.0000e+00, 6.1050e-02,\n","         0.0000e+00, 0.0000e+00, 1.0969e-01, 0.0000e+00, 5.6525e-02, 9.9931e-02,\n","         0.0000e+00, 5.7953e-03, 8.9571e-02, 0.0000e+00, 2.8097e-02, 0.0000e+00,\n","         0.0000e+00, 8.8972e-02, 2.9130e-02, 2.7307e-02, 3.7735e-02, 8.3393e-02,\n","         0.0000e+00, 5.1535e-02, 0.0000e+00, 0.0000e+00, 4.5821e-02, 1.5042e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2156e-01, 4.0511e-02, 1.8421e-02,\n","         1.2506e-01, 0.0000e+00, 6.6084e-02, 0.0000e+00, 0.0000e+00, 4.6208e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7618e-02, 0.0000e+00, 1.1202e-01, 0.0000e+00, 5.9439e-02, 8.9036e-02,\n","         0.0000e+00, 0.0000e+00, 6.1650e-02, 0.0000e+00, 0.0000e+00, 1.2712e-01,\n","         3.4140e-02, 9.6276e-02, 4.0468e-02, 1.3233e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3667e-02, 1.1562e-01, 0.0000e+00, 6.0405e-02,\n","         0.0000e+00, 0.0000e+00, 1.1052e-01, 0.0000e+00, 5.6347e-02, 9.9596e-02,\n","         0.0000e+00, 7.0414e-03, 8.8417e-02, 0.0000e+00, 2.8627e-02, 0.0000e+00,\n","         0.0000e+00, 8.9393e-02, 3.0141e-02, 2.6674e-02, 3.7140e-02, 8.3913e-02,\n","         0.0000e+00, 5.1760e-02, 0.0000e+00, 0.0000e+00, 4.5794e-02, 1.5432e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2051e-01, 3.9868e-02, 1.8381e-02,\n","         1.2528e-01, 0.0000e+00, 6.5953e-02, 0.0000e+00, 0.0000e+00, 4.3932e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7504e-02, 0.0000e+00, 1.1087e-01, 0.0000e+00, 5.8777e-02, 8.8783e-02,\n","         0.0000e+00, 0.0000e+00, 6.1068e-02, 0.0000e+00, 0.0000e+00, 1.2654e-01,\n","         3.4258e-02, 9.5740e-02, 3.9511e-02, 1.3175e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3793e-02, 1.1527e-01, 0.0000e+00, 6.0876e-02,\n","         0.0000e+00, 0.0000e+00, 1.1000e-01, 0.0000e+00, 5.6408e-02, 9.9845e-02,\n","         0.0000e+00, 6.2243e-03, 8.9178e-02, 0.0000e+00, 2.8361e-02, 0.0000e+00,\n","         0.0000e+00, 8.9098e-02, 2.9486e-02, 2.7109e-02, 3.7475e-02, 8.3507e-02,\n","         0.0000e+00, 5.1615e-02, 0.0000e+00, 0.0000e+00, 4.5753e-02, 1.5249e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2117e-01, 4.0293e-02, 1.8398e-02,\n","         1.2508e-01, 0.0000e+00, 6.5970e-02, 0.0000e+00, 0.0000e+00, 4.5454e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7607e-02, 0.0000e+00, 1.1026e-01, 0.0000e+00, 5.8300e-02, 8.8758e-02,\n","         0.0000e+00, 0.0000e+00, 6.0761e-02, 0.0000e+00, 0.0000e+00, 1.2627e-01,\n","         3.4477e-02, 9.5352e-02, 3.8717e-02, 1.3125e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3788e-02, 1.1490e-01, 0.0000e+00, 6.1139e-02,\n","         0.0000e+00, 0.0000e+00, 1.0963e-01, 0.0000e+00, 5.6553e-02, 9.9937e-02,\n","         0.0000e+00, 5.6908e-03, 8.9709e-02, 0.0000e+00, 2.8092e-02, 0.0000e+00,\n","         0.0000e+00, 8.8971e-02, 2.9029e-02, 2.7386e-02, 3.7786e-02, 8.3406e-02,\n","         0.0000e+00, 5.1513e-02, 0.0000e+00, 0.0000e+00, 4.5803e-02, 1.5030e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2165e-01, 4.0597e-02, 1.8442e-02,\n","         1.2499e-01, 0.0000e+00, 6.6112e-02, 0.0000e+00, 0.0000e+00, 4.6437e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7313e-02, 0.0000e+00, 1.1158e-01, 0.0000e+00, 5.9458e-02, 8.8753e-02,\n","         0.0000e+00, 0.0000e+00, 6.1587e-02, 0.0000e+00, 0.0000e+00, 1.2677e-01,\n","         3.3930e-02, 9.6108e-02, 4.0600e-02, 1.3255e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3821e-02, 1.1615e-01, 0.0000e+00, 6.0763e-02,\n","         0.0000e+00, 0.0000e+00, 1.1048e-01, 0.0000e+00, 5.6244e-02, 9.9789e-02,\n","         0.0000e+00, 6.7328e-03, 8.8669e-02, 0.0000e+00, 2.8875e-02, 0.0000e+00,\n","         0.0000e+00, 8.9230e-02, 2.9920e-02, 2.6966e-02, 3.6884e-02, 8.3827e-02,\n","         0.0000e+00, 5.1504e-02, 0.0000e+00, 0.0000e+00, 4.5662e-02, 1.5627e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2051e-01, 4.0076e-02, 1.8285e-02,\n","         1.2481e-01, 0.0000e+00, 6.5838e-02, 0.0000e+00, 0.0000e+00, 4.4390e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7247e-02, 0.0000e+00, 1.1153e-01, 0.0000e+00, 5.9297e-02, 8.8743e-02,\n","         0.0000e+00, 0.0000e+00, 6.1550e-02, 0.0000e+00, 0.0000e+00, 1.2682e-01,\n","         3.3964e-02, 9.6080e-02, 4.0474e-02, 1.3236e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3700e-02, 1.1590e-01, 0.0000e+00, 6.0558e-02,\n","         0.0000e+00, 0.0000e+00, 1.1045e-01, 0.0000e+00, 5.6275e-02, 9.9787e-02,\n","         0.0000e+00, 6.8353e-03, 8.8535e-02, 0.0000e+00, 2.8650e-02, 0.0000e+00,\n","         0.0000e+00, 8.9124e-02, 3.0042e-02, 2.6853e-02, 3.6998e-02, 8.3514e-02,\n","         0.0000e+00, 5.1655e-02, 0.0000e+00, 0.0000e+00, 4.5744e-02, 1.5469e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2051e-01, 3.9934e-02, 1.8259e-02,\n","         1.2517e-01, 0.0000e+00, 6.5894e-02, 0.0000e+00, 0.0000e+00, 4.4230e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7478e-02, 0.0000e+00, 1.1089e-01, 0.0000e+00, 5.8887e-02, 8.8725e-02,\n","         0.0000e+00, 0.0000e+00, 6.1137e-02, 0.0000e+00, 0.0000e+00, 1.2647e-01,\n","         3.4218e-02, 9.5669e-02, 3.9687e-02, 1.3195e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3843e-02, 1.1559e-01, 0.0000e+00, 6.1032e-02,\n","         0.0000e+00, 0.0000e+00, 1.1001e-01, 0.0000e+00, 5.6401e-02, 9.9914e-02,\n","         0.0000e+00, 6.1108e-03, 8.9257e-02, 0.0000e+00, 2.8488e-02, 0.0000e+00,\n","         0.0000e+00, 8.9145e-02, 2.9389e-02, 2.7215e-02, 3.7350e-02, 8.3762e-02,\n","         0.0000e+00, 5.1487e-02, 0.0000e+00, 0.0000e+00, 4.5727e-02, 1.5361e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2119e-01, 4.0379e-02, 1.8368e-02,\n","         1.2482e-01, 0.0000e+00, 6.5943e-02, 0.0000e+00, 0.0000e+00, 4.5578e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7451e-02, 0.0000e+00, 1.1021e-01, 0.0000e+00, 5.8428e-02, 8.8619e-02,\n","         0.0000e+00, 0.0000e+00, 6.0800e-02, 0.0000e+00, 0.0000e+00, 1.2619e-01,\n","         3.4357e-02, 9.5406e-02, 3.8955e-02, 1.3142e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3826e-02, 1.1519e-01, 0.0000e+00, 6.1190e-02,\n","         0.0000e+00, 0.0000e+00, 1.0974e-01, 0.0000e+00, 5.6481e-02, 9.9942e-02,\n","         0.0000e+00, 5.7134e-03, 8.9634e-02, 0.0000e+00, 2.8254e-02, 0.0000e+00,\n","         0.0000e+00, 8.8896e-02, 2.9059e-02, 2.7372e-02, 3.7645e-02, 8.3261e-02,\n","         0.0000e+00, 5.1419e-02, 0.0000e+00, 0.0000e+00, 4.5757e-02, 1.5150e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2148e-01, 4.0585e-02, 1.8432e-02,\n","         1.2485e-01, 0.0000e+00, 6.6033e-02, 0.0000e+00, 0.0000e+00, 4.6286e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7535e-02, 0.0000e+00, 1.1054e-01, 0.0000e+00, 5.8597e-02, 8.8720e-02,\n","         0.0000e+00, 0.0000e+00, 6.0965e-02, 0.0000e+00, 0.0000e+00, 1.2634e-01,\n","         3.4345e-02, 9.5453e-02, 3.9244e-02, 1.3165e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3836e-02, 1.1534e-01, 0.0000e+00, 6.1153e-02,\n","         0.0000e+00, 0.0000e+00, 1.0980e-01, 0.0000e+00, 5.6474e-02, 9.9969e-02,\n","         0.0000e+00, 5.8325e-03, 8.9544e-02, 0.0000e+00, 2.8308e-02, 0.0000e+00,\n","         0.0000e+00, 8.9066e-02, 2.9159e-02, 2.7362e-02, 3.7541e-02, 8.3676e-02,\n","         0.0000e+00, 5.1455e-02, 0.0000e+00, 0.0000e+00, 4.5753e-02, 1.5223e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2146e-01, 4.0528e-02, 1.8384e-02,\n","         1.2483e-01, 0.0000e+00, 6.6020e-02, 0.0000e+00, 0.0000e+00, 4.6118e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 1.2434e-04, 2.1180e-02, 0.0000e+00, 2.9298e-02, 4.5940e-02,\n","         0.0000e+00, 0.0000e+00, 2.6953e-02, 0.0000e+00, 0.0000e+00, 8.6390e-02,\n","         8.3276e-03, 1.0871e-01, 0.0000e+00, 9.2434e-02, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 7.3556e-02, 1.2467e-01, 0.0000e+00, 6.6447e-02,\n","         0.0000e+00, 0.0000e+00, 1.1208e-01, 0.0000e+00, 9.2472e-02, 1.1002e-01,\n","         0.0000e+00, 0.0000e+00, 1.2243e-01, 0.0000e+00, 3.3294e-02, 0.0000e+00,\n","         0.0000e+00, 3.2541e-02, 3.3098e-02, 5.2043e-02, 5.1355e-02, 0.0000e+00,\n","         0.0000e+00, 1.0478e-01, 0.0000e+00, 0.0000e+00, 6.7165e-02, 3.7826e-03,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0235e-01, 4.9874e-02, 2.9341e-02,\n","         1.2487e-01, 0.0000e+00, 8.3353e-02, 0.0000e+00, 0.0000e+00, 7.3997e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n","       grad_fn=<MaxBackward0>)], tensor([[0.5157, 0.4843],\n","        [0.5161, 0.4839],\n","        [0.5180, 0.4820],\n","        [0.5180, 0.4820],\n","        [0.5170, 0.4830],\n","        [0.5172, 0.4828],\n","        [0.5173, 0.4827],\n","        [0.5170, 0.4830],\n","        [0.5181, 0.4819],\n","        [0.5107, 0.4893]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[8.1018e-02, 0.0000e+00, 5.7986e-02, 2.3353e-01, 0.0000e+00, 3.1419e-02,\n","         0.0000e+00, 1.2390e-01, 8.4965e-02, 0.0000e+00, 0.0000e+00, 4.9342e-02,\n","         4.6524e-02, 1.0159e-02, 8.9109e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.2948e-01, 0.0000e+00, 4.6110e-02, 0.0000e+00,\n","         0.0000e+00, 8.4553e-02, 0.0000e+00, 0.0000e+00, 7.1173e-02, 1.2757e-02,\n","         2.4257e-02, 1.0367e-01, 7.9290e-02, 2.0515e-01, 0.0000e+00, 4.7070e-02,\n","         1.7200e-01, 0.0000e+00, 1.3716e-01, 0.0000e+00, 1.1220e-01, 0.0000e+00,\n","         7.7296e-02, 0.0000e+00, 1.1743e-01, 1.3312e-01, 3.3537e-02, 0.0000e+00,\n","         2.1497e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9112e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0122e-01, 0.0000e+00, 0.0000e+00, 8.3090e-02,\n","         0.0000e+00, 1.7101e-01, 6.7362e-02, 1.2208e-01],\n","        [8.1874e-02, 0.0000e+00, 5.9506e-02, 2.2584e-01, 0.0000e+00, 3.0867e-02,\n","         0.0000e+00, 1.1942e-01, 6.6097e-02, 0.0000e+00, 0.0000e+00, 5.4645e-02,\n","         2.6636e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         7.6514e-05, 0.0000e+00, 1.3337e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 6.6979e-02, 0.0000e+00, 0.0000e+00, 4.4265e-02, 1.6533e-02,\n","         2.6804e-02, 1.1090e-01, 8.3507e-02, 2.1691e-01, 0.0000e+00, 5.0574e-02,\n","         1.8043e-01, 0.0000e+00, 1.2322e-01, 0.0000e+00, 1.0506e-01, 2.2645e-03,\n","         8.6433e-02, 0.0000e+00, 8.6155e-02, 8.9208e-02, 3.7649e-02, 0.0000e+00,\n","         2.2543e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.0778e-02, 0.0000e+00,\n","         0.0000e+00, 3.7507e-04, 1.8314e-01, 0.0000e+00, 0.0000e+00, 8.9562e-02,\n","         0.0000e+00, 1.8501e-01, 1.0255e-01, 9.3367e-02],\n","        [8.7405e-02, 0.0000e+00, 6.1839e-02, 2.3353e-01, 0.0000e+00, 3.1419e-02,\n","         0.0000e+00, 1.2390e-01, 8.4965e-02, 0.0000e+00, 0.0000e+00, 5.7118e-02,\n","         4.6524e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.3736e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4553e-02, 0.0000e+00, 0.0000e+00, 7.1173e-02, 1.8506e-02,\n","         2.6583e-02, 1.1090e-01, 6.6955e-02, 2.0515e-01, 0.0000e+00, 4.0318e-02,\n","         1.7488e-01, 0.0000e+00, 1.3716e-01, 0.0000e+00, 1.1220e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1743e-01, 1.3312e-01, 3.5899e-02, 0.0000e+00,\n","         1.9917e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.0431e-02, 0.0000e+00,\n","         0.0000e+00, 1.1446e-03, 2.0122e-01, 0.0000e+00, 0.0000e+00, 9.1241e-02,\n","         0.0000e+00, 1.7101e-01, 1.0255e-01, 1.2208e-01],\n","        [8.1347e-02, 0.0000e+00, 5.8027e-02, 2.3433e-01, 0.0000e+00, 3.1160e-02,\n","         0.0000e+00, 1.2460e-01, 8.5948e-02, 0.0000e+00, 0.0000e+00, 4.7357e-02,\n","         4.6064e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2970e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4083e-02, 0.0000e+00, 0.0000e+00, 7.1396e-02, 1.1059e-02,\n","         2.3676e-02, 1.1090e-01, 6.4575e-02, 2.0646e-01, 0.0000e+00, 3.9829e-02,\n","         1.6553e-01, 0.0000e+00, 1.3651e-01, 0.0000e+00, 1.1172e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1685e-01, 1.3322e-01, 3.1898e-02, 0.0000e+00,\n","         1.9247e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.7847e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0232e-01, 0.0000e+00, 0.0000e+00, 8.1874e-02,\n","         0.0000e+00, 1.7289e-01, 1.0255e-01, 1.2156e-01],\n","        [9.0492e-02, 0.0000e+00, 6.2210e-02, 2.3427e-01, 0.0000e+00, 3.1160e-02,\n","         0.0000e+00, 1.2464e-01, 8.5993e-02, 0.0000e+00, 0.0000e+00, 6.4059e-02,\n","         4.6386e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         2.8219e-03, 0.0000e+00, 1.3983e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4205e-02, 0.0000e+00, 0.0000e+00, 7.1444e-02, 2.4366e-02,\n","         3.1229e-02, 1.1090e-01, 6.8431e-02, 2.1604e-01, 0.0000e+00, 3.9863e-02,\n","         1.8397e-01, 0.0000e+00, 1.3666e-01, 0.0000e+00, 1.1208e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1717e-01, 1.3348e-01, 4.4768e-02, 0.0000e+00,\n","         2.0643e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.2601e-02, 0.0000e+00,\n","         0.0000e+00, 7.2950e-03, 2.0244e-01, 0.0000e+00, 0.0000e+00, 9.5701e-02,\n","         0.0000e+00, 1.7255e-01, 1.0255e-01, 1.2164e-01],\n","        [8.2753e-02, 0.0000e+00, 5.8634e-02, 2.3427e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2716e-01, 9.2928e-02, 0.0000e+00, 0.0000e+00, 4.6839e-02,\n","         7.0890e-02, 4.2724e-03, 1.0809e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.4477e-01, 0.0000e+00, 4.6066e-02, 0.0000e+00,\n","         3.2497e-04, 1.1241e-01, 0.0000e+00, 0.0000e+00, 9.3389e-02, 1.4230e-02,\n","         3.4154e-02, 9.9556e-02, 7.3988e-02, 2.2128e-01, 0.0000e+00, 5.4012e-02,\n","         1.6947e-01, 0.0000e+00, 1.6419e-01, 0.0000e+00, 1.1940e-01, 1.8134e-02,\n","         7.8992e-02, 7.9503e-03, 1.2671e-01, 1.4689e-01, 3.5454e-02, 0.0000e+00,\n","         2.1155e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8028e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0541e-01, 0.0000e+00, 0.0000e+00, 8.6464e-02,\n","         0.0000e+00, 1.8564e-01, 6.7151e-02, 1.3274e-01],\n","        [8.0622e-02, 0.0000e+00, 5.6984e-02, 2.3353e-01, 0.0000e+00, 3.5342e-02,\n","         0.0000e+00, 1.2390e-01, 8.4965e-02, 0.0000e+00, 0.0000e+00, 4.7522e-02,\n","         4.6524e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2785e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4553e-02, 0.0000e+00, 0.0000e+00, 7.1173e-02, 1.1244e-02,\n","         2.3878e-02, 1.1090e-01, 6.4438e-02, 2.0515e-01, 0.0000e+00, 4.0318e-02,\n","         1.6527e-01, 0.0000e+00, 1.3716e-01, 0.0000e+00, 1.1445e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1743e-01, 1.3312e-01, 3.0418e-02, 0.0000e+00,\n","         1.9233e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.8267e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0122e-01, 0.0000e+00, 0.0000e+00, 8.2466e-02,\n","         0.0000e+00, 1.7101e-01, 1.0255e-01, 1.2208e-01],\n","        [7.9686e-02, 0.0000e+00, 4.7947e-02, 2.3777e-01, 0.0000e+00, 5.3199e-02,\n","         0.0000e+00, 1.2561e-01, 8.8040e-02, 0.0000e+00, 0.0000e+00, 2.6306e-02,\n","         6.7670e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2326e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.0302e-01, 0.0000e+00, 0.0000e+00, 7.1681e-02, 7.8863e-04,\n","         2.2675e-02, 1.1090e-01, 5.9187e-02, 2.0895e-01, 0.0000e+00, 4.2328e-02,\n","         1.6810e-01, 0.0000e+00, 1.3568e-01, 0.0000e+00, 1.2587e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.2002e-01, 1.3503e-01, 1.0495e-02, 0.0000e+00,\n","         1.8994e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 2.1943e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0452e-01, 0.0000e+00, 0.0000e+00, 7.4331e-02,\n","         0.0000e+00, 1.7699e-01, 1.0255e-01, 1.3590e-01],\n","        [7.9902e-02, 0.0000e+00, 5.5480e-02, 2.3286e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2236e-01, 9.2130e-02, 0.0000e+00, 0.0000e+00, 4.0125e-02,\n","         7.0890e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2621e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.1241e-01, 0.0000e+00, 0.0000e+00, 8.7246e-02, 9.5167e-03,\n","         2.2763e-02, 1.1090e-01, 7.5818e-02, 1.9294e-01, 0.0000e+00, 3.7729e-02,\n","         1.6282e-01, 0.0000e+00, 1.5546e-01, 0.0000e+00, 1.1940e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.2671e-01, 1.4689e-01, 2.6841e-02, 0.0000e+00,\n","         2.0694e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.4146e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0541e-01, 0.0000e+00, 0.0000e+00, 8.0250e-02,\n","         0.0000e+00, 1.5793e-01, 1.0255e-01, 1.3274e-01],\n","        [7.9454e-02, 0.0000e+00, 5.5480e-02, 2.3286e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2236e-01, 9.2130e-02, 0.0000e+00, 0.0000e+00, 3.4816e-02,\n","         7.0890e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2178e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.1241e-01, 0.0000e+00, 0.0000e+00, 8.7246e-02, 6.0814e-03,\n","         1.8455e-02, 1.1090e-01, 6.2901e-02, 1.9294e-01, 0.0000e+00, 2.7469e-02,\n","         1.5934e-01, 0.0000e+00, 1.5546e-01, 0.0000e+00, 1.1940e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.2671e-01, 1.4689e-01, 2.6841e-02, 0.0000e+00,\n","         1.8634e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.4146e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0541e-01, 0.0000e+00, 0.0000e+00, 7.6419e-02,\n","         0.0000e+00, 1.5793e-01, 1.0255e-01, 1.3274e-01]],\n","       grad_fn=<MaxBackward0>), tensor([[0.0371, 0.0000, 0.1117, 0.0000, 0.0595, 0.0887, 0.0000, 0.0000, 0.0617,\n","         0.0000, 0.0000, 0.1268, 0.0338, 0.0962, 0.0409, 0.1327, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1163, 0.0000, 0.0606, 0.0000, 0.0000, 0.1106,\n","         0.0000, 0.0562, 0.0998, 0.0000, 0.0070, 0.0884, 0.0000, 0.0289, 0.0000,\n","         0.0000, 0.0891, 0.0301, 0.0269, 0.0367, 0.0836, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0156, 0.0000, 0.0000, 0.0000, 0.1203, 0.0399, 0.0182,\n","         0.1249, 0.0000, 0.0658, 0.0000, 0.0000, 0.0440, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0371, 0.0000, 0.1109, 0.0000, 0.0591, 0.0886, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1264, 0.0339, 0.0958, 0.0401, 0.1323, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1161, 0.0000, 0.0610, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0563, 0.0999, 0.0000, 0.0064, 0.0890, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0890, 0.0296, 0.0272, 0.0370, 0.0834, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1208, 0.0402, 0.0182,\n","         0.1247, 0.0000, 0.0659, 0.0000, 0.0000, 0.0451, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1116, 0.0000, 0.0595, 0.0888, 0.0000, 0.0000, 0.0616,\n","         0.0000, 0.0000, 0.1268, 0.0339, 0.0961, 0.0406, 0.1326, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1161, 0.0000, 0.0608, 0.0000, 0.0000, 0.1105,\n","         0.0000, 0.0563, 0.0998, 0.0000, 0.0067, 0.0887, 0.0000, 0.0289, 0.0000,\n","         0.0000, 0.0892, 0.0299, 0.0270, 0.0369, 0.0839, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0156, 0.0000, 0.0000, 0.0000, 0.1205, 0.0401, 0.0183,\n","         0.1248, 0.0000, 0.0659, 0.0000, 0.0000, 0.0444, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1111, 0.0000, 0.0591, 0.0887, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1266, 0.0341, 0.0959, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1158, 0.0000, 0.0609, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0563, 0.0999, 0.0000, 0.0064, 0.0890, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0892, 0.0296, 0.0271, 0.0371, 0.0837, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1209, 0.0402, 0.0183,\n","         0.1248, 0.0000, 0.0659, 0.0000, 0.0000, 0.0451, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1112, 0.0000, 0.0592, 0.0888, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1266, 0.0341, 0.0959, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1158, 0.0000, 0.0609, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0563, 0.0999, 0.0000, 0.0064, 0.0890, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0892, 0.0296, 0.0271, 0.0372, 0.0839, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1209, 0.0402, 0.0183,\n","         0.1248, 0.0000, 0.0659, 0.0000, 0.0000, 0.0451, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1118, 0.0000, 0.0595, 0.0888, 0.0000, 0.0000, 0.0617,\n","         0.0000, 0.0000, 0.1270, 0.0339, 0.0963, 0.0408, 0.1325, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1159, 0.0000, 0.0604, 0.0000, 0.0000, 0.1106,\n","         0.0000, 0.0562, 0.0997, 0.0000, 0.0071, 0.0883, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0891, 0.0303, 0.0267, 0.0369, 0.0834, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0457, 0.0156, 0.0000, 0.0000, 0.0000, 0.1202, 0.0398, 0.0183,\n","         0.1253, 0.0000, 0.0658, 0.0000, 0.0000, 0.0438, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1111, 0.0000, 0.0590, 0.0888, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1266, 0.0342, 0.0958, 0.0398, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1156, 0.0000, 0.0609, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0564, 0.0998, 0.0000, 0.0063, 0.0891, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0892, 0.0295, 0.0271, 0.0373, 0.0838, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0153, 0.0000, 0.0000, 0.0000, 0.1211, 0.0403, 0.0184,\n","         0.1249, 0.0000, 0.0660, 0.0000, 0.0000, 0.0452, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1106, 0.0000, 0.0585, 0.0888, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1265, 0.0345, 0.0955, 0.0389, 0.1313, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1149, 0.0000, 0.0610, 0.0000, 0.0000, 0.1098,\n","         0.0000, 0.0566, 0.0999, 0.0000, 0.0059, 0.0895, 0.0000, 0.0281, 0.0000,\n","         0.0000, 0.0891, 0.0292, 0.0272, 0.0378, 0.0835, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0459, 0.0150, 0.0000, 0.0000, 0.0000, 0.1215, 0.0404, 0.0185,\n","         0.1252, 0.0000, 0.0661, 0.0000, 0.0000, 0.0460, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1103, 0.0000, 0.0584, 0.0885, 0.0000, 0.0000, 0.0607,\n","         0.0000, 0.0000, 0.1263, 0.0343, 0.0957, 0.0390, 0.1312, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1149, 0.0000, 0.0608, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0565, 0.0997, 0.0000, 0.0060, 0.0892, 0.0000, 0.0281, 0.0000,\n","         0.0000, 0.0887, 0.0294, 0.0270, 0.0378, 0.0824, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0459, 0.0150, 0.0000, 0.0000, 0.0000, 0.1211, 0.0403, 0.0185,\n","         0.1254, 0.0000, 0.0660, 0.0000, 0.0000, 0.0455, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1109, 0.0000, 0.0588, 0.0889, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1266, 0.0344, 0.0957, 0.0393, 0.1317, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1152, 0.0000, 0.0609, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0565, 0.0998, 0.0000, 0.0061, 0.0893, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0892, 0.0293, 0.0271, 0.0376, 0.0838, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1214, 0.0404, 0.0185,\n","         0.1249, 0.0000, 0.0661, 0.0000, 0.0000, 0.0456, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5157, 0.4843],\n","        [0.5164, 0.4836],\n","        [0.5170, 0.4830],\n","        [0.5167, 0.4833],\n","        [0.5180, 0.4820],\n","        [0.5174, 0.4826],\n","        [0.5167, 0.4833],\n","        [0.5161, 0.4839],\n","        [0.5165, 0.4835],\n","        [0.5163, 0.4837]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0809, 0.0000, 0.0581, 0.2335, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0501, 0.0465, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1296, 0.0000, 0.0636, 0.0000, 0.0198, 0.0846, 0.0000,\n","         0.0000, 0.0712, 0.0130, 0.0247, 0.1109, 0.0656, 0.2051, 0.0000, 0.0403,\n","         0.1666, 0.0000, 0.1372, 0.0000, 0.1122, 0.0000, 0.0864, 0.0000, 0.1174,\n","         0.1331, 0.0350, 0.0000, 0.1937, 0.0000, 0.0113, 0.0000, 0.0394, 0.0000,\n","         0.0000, 0.0000, 0.2012, 0.0000, 0.0000, 0.0836, 0.0000, 0.1710, 0.1025,\n","         0.1221],\n","        [0.0880, 0.0000, 0.0610, 0.2364, 0.0000, 0.0422, 0.0000, 0.1247, 0.0921,\n","         0.0000, 0.0000, 0.0623, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1384, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0173, 0.0303, 0.1109, 0.0763, 0.2127, 0.0000, 0.0428,\n","         0.1808, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0334, 0.0000, 0.2122, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2054, 0.0000, 0.0000, 0.0931, 0.0000, 0.1724, 0.1025,\n","         0.1327],\n","        [0.0813, 0.0000, 0.0580, 0.2329, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0474, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0111, 0.0342, 0.1109, 0.0646, 0.2213, 0.0000, 0.0540,\n","         0.1655, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0319, 0.0000, 0.1925, 0.0000, 0.0113, 0.0000, 0.0378, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0819, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0880, 0.0000, 0.0609, 0.2335, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0602, 0.0468, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1380, 0.0000, 0.0636, 0.0000, 0.0198, 0.0847, 0.0000,\n","         0.0000, 0.0712, 0.0180, 0.0298, 0.1109, 0.0668, 0.2108, 0.0000, 0.0403,\n","         0.1793, 0.0000, 0.1373, 0.0000, 0.1124, 0.0000, 0.0864, 0.0000, 0.1177,\n","         0.1333, 0.0380, 0.0000, 0.2026, 0.0000, 0.0113, 0.0000, 0.0417, 0.0000,\n","         0.0000, 0.0051, 0.2013, 0.0000, 0.0000, 0.0920, 0.0000, 0.1707, 0.1025,\n","         0.1221],\n","        [0.0882, 0.0000, 0.0607, 0.1902, 0.0000, 0.0309, 0.0000, 0.1006, 0.0375,\n","         0.0000, 0.0000, 0.0590, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1380, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0163, 0.0295, 0.1109, 0.0659, 0.2098, 0.0000, 0.0214,\n","         0.1789, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0947,\n","         0.0561, 0.0362, 0.0000, 0.2020, 0.0000, 0.0113, 0.0000, 0.0410, 0.0000,\n","         0.0000, 0.0046, 0.1647, 0.0000, 0.0000, 0.0913, 0.0000, 0.1452, 0.1025,\n","         0.0934],\n","        [0.0853, 0.0000, 0.0604, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0603, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1351, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0189, 0.0285, 0.1109, 0.0663, 0.2087, 0.0000, 0.0275,\n","         0.1752, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0385, 0.0000, 0.2010, 0.0000, 0.0113, 0.0000, 0.0426, 0.0000,\n","         0.0000, 0.0033, 0.2054, 0.0000, 0.0000, 0.0919, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0880, 0.0000, 0.0610, 0.2335, 0.0000, 0.0422, 0.0000, 0.1239, 0.0921,\n","         0.0000, 0.0000, 0.0623, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1384, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0173, 0.0303, 0.1109, 0.0656, 0.2127, 0.0000, 0.0403,\n","         0.1808, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0350, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2054, 0.0000, 0.0000, 0.0931, 0.0000, 0.1710, 0.1025,\n","         0.1327],\n","        [0.0812, 0.0000, 0.0568, 0.2326, 0.0000, 0.0351, 0.0000, 0.1237, 0.0845,\n","         0.0000, 0.0000, 0.0474, 0.0480, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1277, 0.0000, 0.0636, 0.0000, 0.0198, 0.0861, 0.0000,\n","         0.0000, 0.0712, 0.0129, 0.0226, 0.1109, 0.0635, 0.2031, 0.0000, 0.0403,\n","         0.1659, 0.0000, 0.1387, 0.0000, 0.1143, 0.0000, 0.0864, 0.0000, 0.1190,\n","         0.1343, 0.0320, 0.0000, 0.1937, 0.0000, 0.0113, 0.0000, 0.0387, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0826, 0.0000, 0.1691, 0.1025,\n","         0.1232],\n","        [0.0320, 0.0000, 0.0453, 0.0950, 0.0000, 0.0309, 0.0000, 0.0781, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.0812, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0000, 0.0000, 0.1109, 0.0527, 0.0741, 0.0000, 0.0024,\n","         0.0643, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0299,\n","         0.0536, 0.0000, 0.0000, 0.1006, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0015, 0.1025,\n","         0.0934],\n","        [0.0492, 0.0000, 0.0453, 0.2329, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0000, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0000, 0.0342, 0.1109, 0.0562, 0.2213, 0.0000, 0.0540,\n","         0.1436, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0000, 0.0000, 0.1535, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0040, 0.0000, 0.1856, 0.1025,\n","         0.1327]], grad_fn=<MaxBackward0>), tensor([[3.7012e-02, 0.0000e+00, 1.1120e-01, 0.0000e+00, 5.9517e-02, 8.9051e-02,\n","         0.0000e+00, 0.0000e+00, 6.1833e-02, 0.0000e+00, 0.0000e+00, 1.2650e-01,\n","         3.3799e-02, 9.6253e-02, 4.0665e-02, 1.3253e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4104e-02, 1.1640e-01, 0.0000e+00, 6.0871e-02,\n","         0.0000e+00, 0.0000e+00, 1.1070e-01, 0.0000e+00, 5.6178e-02, 9.9943e-02,\n","         0.0000e+00, 6.7478e-03, 8.8908e-02, 0.0000e+00, 2.8749e-02, 0.0000e+00,\n","         0.0000e+00, 8.9441e-02, 2.9951e-02, 2.7119e-02, 3.6637e-02, 8.3811e-02,\n","         0.0000e+00, 5.1527e-02, 0.0000e+00, 0.0000e+00, 4.5610e-02, 1.5925e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2019e-01, 4.0024e-02, 1.8082e-02,\n","         1.2491e-01, 0.0000e+00, 6.5743e-02, 0.0000e+00, 0.0000e+00, 4.4413e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7278e-02, 0.0000e+00, 1.1179e-01, 0.0000e+00, 5.9551e-02, 8.9289e-02,\n","         0.0000e+00, 0.0000e+00, 6.2031e-02, 0.0000e+00, 0.0000e+00, 1.2693e-01,\n","         3.3991e-02, 9.6467e-02, 4.0829e-02, 1.3237e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3906e-02, 1.1589e-01, 0.0000e+00, 6.0336e-02,\n","         0.0000e+00, 0.0000e+00, 1.1084e-01, 0.0000e+00, 5.6213e-02, 9.9731e-02,\n","         0.0000e+00, 7.1892e-03, 8.8449e-02, 0.0000e+00, 2.8432e-02, 0.0000e+00,\n","         0.0000e+00, 8.9519e-02, 3.0360e-02, 2.6677e-02, 3.6881e-02, 8.3706e-02,\n","         0.0000e+00, 5.1833e-02, 0.0000e+00, 0.0000e+00, 4.5754e-02, 1.5748e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1998e-01, 3.9655e-02, 1.8173e-02,\n","         1.2574e-01, 0.0000e+00, 6.5800e-02, 0.0000e+00, 0.0000e+00, 4.3614e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7258e-02, 0.0000e+00, 1.1080e-01, 0.0000e+00, 5.8946e-02, 8.9091e-02,\n","         0.0000e+00, 0.0000e+00, 6.1477e-02, 0.0000e+00, 0.0000e+00, 1.2647e-01,\n","         3.4150e-02, 9.6136e-02, 3.9895e-02, 1.3170e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3988e-02, 1.1534e-01, 0.0000e+00, 6.0638e-02,\n","         0.0000e+00, 0.0000e+00, 1.1046e-01, 0.0000e+00, 5.6269e-02, 9.9798e-02,\n","         0.0000e+00, 6.5553e-03, 8.9029e-02, 0.0000e+00, 2.8161e-02, 0.0000e+00,\n","         0.0000e+00, 8.9197e-02, 2.9851e-02, 2.6895e-02, 3.7313e-02, 8.3032e-02,\n","         0.0000e+00, 5.1749e-02, 0.0000e+00, 0.0000e+00, 4.5742e-02, 1.5543e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2043e-01, 3.9974e-02, 1.8305e-02,\n","         1.2575e-01, 0.0000e+00, 6.5815e-02, 0.0000e+00, 0.0000e+00, 4.4742e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7078e-02, 0.0000e+00, 1.1129e-01, 0.0000e+00, 5.9553e-02, 8.9084e-02,\n","         0.0000e+00, 0.0000e+00, 6.1870e-02, 0.0000e+00, 0.0000e+00, 1.2654e-01,\n","         3.3821e-02, 9.6242e-02, 4.0739e-02, 1.3256e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4110e-02, 1.1643e-01, 0.0000e+00, 6.0878e-02,\n","         0.0000e+00, 0.0000e+00, 1.1071e-01, 0.0000e+00, 5.6185e-02, 9.9949e-02,\n","         0.0000e+00, 6.7318e-03, 8.8904e-02, 0.0000e+00, 2.8743e-02, 0.0000e+00,\n","         0.0000e+00, 8.9485e-02, 2.9959e-02, 2.7111e-02, 3.6641e-02, 8.3944e-02,\n","         0.0000e+00, 5.1531e-02, 0.0000e+00, 0.0000e+00, 4.5608e-02, 1.5954e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2020e-01, 4.0022e-02, 1.8091e-02,\n","         1.2494e-01, 0.0000e+00, 6.5737e-02, 0.0000e+00, 0.0000e+00, 4.4413e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7089e-02, 0.0000e+00, 1.1055e-01, 0.0000e+00, 5.9097e-02, 8.8971e-02,\n","         0.0000e+00, 0.0000e+00, 6.1492e-02, 0.0000e+00, 0.0000e+00, 1.2616e-01,\n","         3.3966e-02, 9.5846e-02, 4.0003e-02, 1.3213e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4188e-02, 1.1617e-01, 0.0000e+00, 6.1241e-02,\n","         0.0000e+00, 0.0000e+00, 1.1033e-01, 0.0000e+00, 5.6268e-02, 1.0010e-01,\n","         0.0000e+00, 6.1310e-03, 8.9489e-02, 0.0000e+00, 2.8551e-02, 0.0000e+00,\n","         0.0000e+00, 8.9345e-02, 2.9442e-02, 2.7443e-02, 3.6893e-02, 8.3817e-02,\n","         0.0000e+00, 5.1395e-02, 0.0000e+00, 0.0000e+00, 4.5606e-02, 1.5805e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2071e-01, 4.0368e-02, 1.8118e-02,\n","         1.2475e-01, 0.0000e+00, 6.5799e-02, 0.0000e+00, 0.0000e+00, 4.5527e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7361e-02, 0.0000e+00, 1.1111e-01, 0.0000e+00, 5.9225e-02, 8.9245e-02,\n","         0.0000e+00, 0.0000e+00, 6.1618e-02, 0.0000e+00, 0.0000e+00, 1.2654e-01,\n","         3.4141e-02, 9.6068e-02, 4.0031e-02, 1.3208e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4074e-02, 1.1587e-01, 0.0000e+00, 6.0942e-02,\n","         0.0000e+00, 0.0000e+00, 1.1044e-01, 0.0000e+00, 5.6341e-02, 9.9906e-02,\n","         0.0000e+00, 6.4301e-03, 8.9230e-02, 0.0000e+00, 2.8449e-02, 0.0000e+00,\n","         0.0000e+00, 8.9578e-02, 2.9654e-02, 2.7157e-02, 3.7049e-02, 8.4074e-02,\n","         0.0000e+00, 5.1599e-02, 0.0000e+00, 0.0000e+00, 4.5704e-02, 1.5718e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2067e-01, 4.0157e-02, 1.8219e-02,\n","         1.2504e-01, 0.0000e+00, 6.5903e-02, 0.0000e+00, 0.0000e+00, 4.4972e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7129e-02, 0.0000e+00, 1.1152e-01, 0.0000e+00, 5.9625e-02, 8.9155e-02,\n","         0.0000e+00, 0.0000e+00, 6.1964e-02, 0.0000e+00, 0.0000e+00, 1.2670e-01,\n","         3.3849e-02, 9.6406e-02, 4.0849e-02, 1.3255e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4053e-02, 1.1628e-01, 0.0000e+00, 6.0663e-02,\n","         0.0000e+00, 0.0000e+00, 1.1082e-01, 0.0000e+00, 5.6169e-02, 9.9824e-02,\n","         0.0000e+00, 6.9701e-03, 8.8686e-02, 0.0000e+00, 2.8704e-02, 0.0000e+00,\n","         0.0000e+00, 8.9495e-02, 3.0148e-02, 2.6917e-02, 3.6682e-02, 8.3796e-02,\n","         0.0000e+00, 5.1616e-02, 0.0000e+00, 0.0000e+00, 4.5646e-02, 1.5918e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2001e-01, 3.9869e-02, 1.8135e-02,\n","         1.2519e-01, 0.0000e+00, 6.5739e-02, 0.0000e+00, 0.0000e+00, 4.3980e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7295e-02, 0.0000e+00, 1.1094e-01, 0.0000e+00, 5.9058e-02, 8.9193e-02,\n","         0.0000e+00, 0.0000e+00, 6.1550e-02, 0.0000e+00, 0.0000e+00, 1.2650e-01,\n","         3.4164e-02, 9.5995e-02, 3.9900e-02, 1.3192e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3991e-02, 1.1567e-01, 0.0000e+00, 6.0824e-02,\n","         0.0000e+00, 0.0000e+00, 1.1037e-01, 0.0000e+00, 5.6370e-02, 9.9920e-02,\n","         0.0000e+00, 6.4516e-03, 8.9170e-02, 0.0000e+00, 2.8271e-02, 0.0000e+00,\n","         0.0000e+00, 8.9441e-02, 2.9706e-02, 2.7110e-02, 3.7162e-02, 8.3769e-02,\n","         0.0000e+00, 5.1679e-02, 0.0000e+00, 0.0000e+00, 4.5742e-02, 1.5601e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2068e-01, 4.0099e-02, 1.8206e-02,\n","         1.2527e-01, 0.0000e+00, 6.5897e-02, 0.0000e+00, 0.0000e+00, 4.4995e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 1.2434e-04, 2.1180e-02, 0.0000e+00, 2.9298e-02, 4.5940e-02,\n","         0.0000e+00, 0.0000e+00, 2.6953e-02, 0.0000e+00, 0.0000e+00, 8.6390e-02,\n","         8.3276e-03, 1.0871e-01, 0.0000e+00, 9.2434e-02, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 7.3556e-02, 1.2467e-01, 0.0000e+00, 6.6447e-02,\n","         0.0000e+00, 0.0000e+00, 1.1208e-01, 0.0000e+00, 9.2472e-02, 1.1002e-01,\n","         0.0000e+00, 0.0000e+00, 1.2243e-01, 0.0000e+00, 3.3294e-02, 0.0000e+00,\n","         0.0000e+00, 3.2541e-02, 3.3098e-02, 5.2043e-02, 5.1355e-02, 0.0000e+00,\n","         0.0000e+00, 1.0478e-01, 0.0000e+00, 0.0000e+00, 6.7165e-02, 3.7826e-03,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0235e-01, 4.9874e-02, 2.9341e-02,\n","         1.2487e-01, 0.0000e+00, 8.3353e-02, 0.0000e+00, 0.0000e+00, 7.3997e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.6772e-02, 0.0000e+00, 1.0863e-01, 0.0000e+00, 5.7686e-02, 8.8573e-02,\n","         0.0000e+00, 0.0000e+00, 6.0572e-02, 0.0000e+00, 0.0000e+00, 1.2548e-01,\n","         3.4243e-02, 9.5305e-02, 3.7919e-02, 1.3039e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3910e-02, 1.1465e-01, 0.0000e+00, 6.1183e-02,\n","         0.0000e+00, 0.0000e+00, 1.0968e-01, 0.0000e+00, 5.6471e-02, 1.0008e-01,\n","         0.0000e+00, 5.3574e-03, 9.0139e-02, 0.0000e+00, 2.7626e-02, 0.0000e+00,\n","         0.0000e+00, 8.8337e-02, 2.8946e-02, 2.7551e-02, 3.7823e-02, 8.1474e-02,\n","         0.0000e+00, 5.1507e-02, 0.0000e+00, 0.0000e+00, 4.5778e-02, 1.5003e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2117e-01, 4.0607e-02, 1.8294e-02,\n","         1.2555e-01, 0.0000e+00, 6.6055e-02, 0.0000e+00, 0.0000e+00, 4.6817e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n","       grad_fn=<MaxBackward0>)], tensor([[0.5168, 0.4832],\n","        [0.5182, 0.4818],\n","        [0.5183, 0.4817],\n","        [0.5174, 0.4826],\n","        [0.5149, 0.4851],\n","        [0.5183, 0.4817],\n","        [0.5184, 0.4816],\n","        [0.5168, 0.4832],\n","        [0.5107, 0.4893],\n","        [0.5159, 0.4841]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0823, 0.0000, 0.0551, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0859,\n","         0.0000, 0.0000, 0.0500, 0.0461, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1337, 0.0000, 0.0636, 0.0000, 0.0198, 0.0841, 0.0000,\n","         0.0000, 0.0714, 0.0169, 0.0244, 0.1109, 0.0751, 0.2065, 0.0000, 0.0398,\n","         0.1738, 0.0000, 0.1365, 0.0000, 0.1117, 0.0000, 0.0864, 0.0000, 0.1168,\n","         0.1332, 0.0286, 0.0000, 0.2074, 0.0000, 0.0113, 0.0000, 0.0319, 0.0000,\n","         0.0000, 0.0000, 0.2023, 0.0000, 0.0000, 0.0884, 0.0000, 0.1729, 0.1025,\n","         0.1216],\n","        [0.0907, 0.0000, 0.0607, 0.2349, 0.0000, 0.0309, 0.0000, 0.1250, 0.0868,\n","         0.0000, 0.0000, 0.0659, 0.0453, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1410, 0.0000, 0.0636, 0.0000, 0.0198, 0.0836, 0.0000,\n","         0.0000, 0.0715, 0.0169, 0.0327, 0.1109, 0.0658, 0.2182, 0.0000, 0.0395,\n","         0.1857, 0.0000, 0.1360, 0.0000, 0.1111, 0.0000, 0.0864, 0.0000, 0.1160,\n","         0.1330, 0.0352, 0.0000, 0.2078, 0.0000, 0.0113, 0.0000, 0.0433, 0.0000,\n","         0.0000, 0.0083, 0.2033, 0.0000, 0.0000, 0.0956, 0.0000, 0.1753, 0.1025,\n","         0.1208],\n","        [0.0794, 0.0000, 0.0453, 0.2343, 0.0000, 0.0314, 0.0000, 0.1246, 0.0860,\n","         0.0000, 0.0000, 0.0115, 0.0481, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1151, 0.0000, 0.0636, 0.0000, 0.0198, 0.0862, 0.0000,\n","         0.0000, 0.0714, 0.0000, 0.0219, 0.1109, 0.0572, 0.2061, 0.0000, 0.0399,\n","         0.1522, 0.0000, 0.1386, 0.0000, 0.1140, 0.0000, 0.0864, 0.0000, 0.1186,\n","         0.1348, 0.0039, 0.0000, 0.1840, 0.0000, 0.0113, 0.0000, 0.0193, 0.0000,\n","         0.0000, 0.0000, 0.2024, 0.0000, 0.0000, 0.0673, 0.0000, 0.1726, 0.1025,\n","         0.1234],\n","        [0.0780, 0.0000, 0.0550, 0.2382, 0.0000, 0.0535, 0.0000, 0.1247, 0.0881,\n","         0.0000, 0.0000, 0.0333, 0.0867, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1213, 0.0000, 0.0747, 0.0000, 0.0198, 0.1154, 0.0140,\n","         0.0000, 0.0714, 0.0057, 0.0239, 0.1109, 0.0625, 0.2093, 0.0000, 0.0425,\n","         0.1556, 0.0000, 0.1365, 0.0000, 0.1225, 0.0000, 0.1055, 0.0000, 0.1197,\n","         0.1344, 0.0259, 0.0000, 0.1896, 0.0000, 0.0113, 0.0000, 0.0339, 0.0000,\n","         0.0000, 0.0000, 0.2031, 0.0000, 0.0032, 0.0736, 0.0000, 0.1761, 0.1025,\n","         0.1342],\n","        [0.0814, 0.0000, 0.0594, 0.2382, 0.0000, 0.0535, 0.0000, 0.1247, 0.0881,\n","         0.0000, 0.0000, 0.0489, 0.0867, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1303, 0.0000, 0.0747, 0.0000, 0.0198, 0.1154, 0.0140,\n","         0.0000, 0.0700, 0.0151, 0.0247, 0.1109, 0.0662, 0.2093, 0.0000, 0.0425,\n","         0.1658, 0.0000, 0.1350, 0.0000, 0.1225, 0.0000, 0.1055, 0.0000, 0.1197,\n","         0.1344, 0.0370, 0.0000, 0.1925, 0.0000, 0.0113, 0.0000, 0.0381, 0.0000,\n","         0.0000, 0.0000, 0.2031, 0.0000, 0.0032, 0.0830, 0.0000, 0.1761, 0.1025,\n","         0.1342],\n","        [0.0814, 0.0000, 0.0594, 0.2329, 0.0000, 0.0535, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0489, 0.0867, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1303, 0.0000, 0.0747, 0.0000, 0.0198, 0.1154, 0.0140,\n","         0.0000, 0.0872, 0.0151, 0.0247, 0.1109, 0.0662, 0.1968, 0.0000, 0.0275,\n","         0.1658, 0.0000, 0.1555, 0.0000, 0.1225, 0.0000, 0.1055, 0.0000, 0.1267,\n","         0.1469, 0.0370, 0.0000, 0.1925, 0.0000, 0.0113, 0.0000, 0.0381, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0032, 0.0830, 0.0000, 0.1579, 0.1025,\n","         0.1342],\n","        [0.0785, 0.0000, 0.0555, 0.2343, 0.0000, 0.0422, 0.0000, 0.1246, 0.0921,\n","         0.0000, 0.0000, 0.0348, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1218, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0061, 0.0219, 0.1109, 0.0629, 0.2061, 0.0000, 0.0399,\n","         0.1583, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0268, 0.0000, 0.1850, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0747, 0.0000, 0.1726, 0.1025,\n","         0.1327],\n","        [0.0320, 0.0000, 0.0453, 0.0950, 0.0000, 0.0309, 0.0000, 0.0781, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.0812, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0000, 0.0000, 0.1109, 0.0527, 0.0741, 0.0000, 0.0024,\n","         0.0643, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0299,\n","         0.0536, 0.0000, 0.0000, 0.1006, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0015, 0.1025,\n","         0.0934],\n","        [0.0320, 0.0000, 0.0453, 0.0950, 0.0000, 0.0309, 0.0000, 0.0781, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.0812, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0000, 0.0000, 0.1109, 0.0527, 0.0741, 0.0000, 0.0024,\n","         0.0643, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0299,\n","         0.0536, 0.0000, 0.0000, 0.1006, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0015, 0.1025,\n","         0.0934],\n","        [0.0841, 0.0000, 0.0599, 0.1895, 0.0000, 0.0309, 0.0000, 0.1015, 0.0336,\n","         0.0000, 0.0000, 0.0607, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0007, 0.0000, 0.1339, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0174, 0.0296, 0.1109, 0.0658, 0.2103, 0.0000, 0.0197,\n","         0.1749, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0882,\n","         0.0564, 0.0374, 0.0000, 0.2000, 0.0000, 0.0113, 0.0000, 0.0430, 0.0000,\n","         0.0000, 0.0043, 0.1619, 0.0000, 0.0000, 0.0911, 0.0000, 0.1433, 0.1025,\n","         0.0934]], grad_fn=<MaxBackward0>), tensor([[3.7497e-02, 0.0000e+00, 1.1026e-01, 0.0000e+00, 5.8265e-02, 8.8408e-02,\n","         0.0000e+00, 0.0000e+00, 6.0533e-02, 0.0000e+00, 0.0000e+00, 1.2630e-01,\n","         3.4450e-02, 9.5189e-02, 3.8734e-02, 1.3133e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3612e-02, 1.1502e-01, 0.0000e+00, 6.1126e-02,\n","         0.0000e+00, 0.0000e+00, 1.0955e-01, 0.0000e+00, 5.6582e-02, 9.9909e-02,\n","         0.0000e+00, 5.7102e-03, 8.9526e-02, 0.0000e+00, 2.8296e-02, 0.0000e+00,\n","         0.0000e+00, 8.8715e-02, 2.9035e-02, 2.7350e-02, 3.7834e-02, 8.3177e-02,\n","         0.0000e+00, 5.1466e-02, 0.0000e+00, 0.0000e+00, 4.5797e-02, 1.4904e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2182e-01, 4.0573e-02, 1.8499e-02,\n","         1.2479e-01, 0.0000e+00, 6.6134e-02, 0.0000e+00, 0.0000e+00, 4.6404e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7731e-02, 0.0000e+00, 1.1108e-01, 0.0000e+00, 5.8776e-02, 8.8535e-02,\n","         0.0000e+00, 0.0000e+00, 6.0903e-02, 0.0000e+00, 0.0000e+00, 1.2663e-01,\n","         3.4351e-02, 9.5510e-02, 3.9525e-02, 1.3188e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3649e-02, 1.1535e-01, 0.0000e+00, 6.1003e-02,\n","         0.0000e+00, 0.0000e+00, 1.0981e-01, 0.0000e+00, 5.6477e-02, 9.9837e-02,\n","         0.0000e+00, 6.0162e-03, 8.9175e-02, 0.0000e+00, 2.8518e-02, 0.0000e+00,\n","         0.0000e+00, 8.9010e-02, 2.9298e-02, 2.7143e-02, 3.7585e-02, 8.3813e-02,\n","         0.0000e+00, 5.1488e-02, 0.0000e+00, 0.0000e+00, 4.5777e-02, 1.5130e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2152e-01, 4.0457e-02, 1.8520e-02,\n","         1.2475e-01, 0.0000e+00, 6.6028e-02, 0.0000e+00, 0.0000e+00, 4.5732e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7977e-02, 0.0000e+00, 1.1104e-01, 0.0000e+00, 5.8489e-02, 8.8691e-02,\n","         0.0000e+00, 0.0000e+00, 6.0734e-02, 0.0000e+00, 0.0000e+00, 1.2671e-01,\n","         3.4625e-02, 9.5404e-02, 3.8975e-02, 1.3148e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3556e-02, 1.1477e-01, 0.0000e+00, 6.0918e-02,\n","         0.0000e+00, 0.0000e+00, 1.0959e-01, 0.0000e+00, 5.6605e-02, 9.9779e-02,\n","         0.0000e+00, 5.9075e-03, 8.9319e-02, 0.0000e+00, 2.8207e-02, 0.0000e+00,\n","         0.0000e+00, 8.9077e-02, 2.9161e-02, 2.7111e-02, 3.7945e-02, 8.3870e-02,\n","         0.0000e+00, 5.1631e-02, 0.0000e+00, 0.0000e+00, 4.5892e-02, 1.4860e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2187e-01, 4.0482e-02, 1.8600e-02,\n","         1.2499e-01, 0.0000e+00, 6.6169e-02, 0.0000e+00, 0.0000e+00, 4.6024e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7816e-02, 0.0000e+00, 1.1120e-01, 0.0000e+00, 5.8717e-02, 8.8620e-02,\n","         0.0000e+00, 0.0000e+00, 6.0870e-02, 0.0000e+00, 0.0000e+00, 1.2676e-01,\n","         3.4435e-02, 9.5589e-02, 3.9344e-02, 1.3168e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3543e-02, 1.1501e-01, 0.0000e+00, 6.0785e-02,\n","         0.0000e+00, 0.0000e+00, 1.0982e-01, 0.0000e+00, 5.6490e-02, 9.9726e-02,\n","         0.0000e+00, 6.1794e-03, 8.9047e-02, 0.0000e+00, 2.8395e-02, 0.0000e+00,\n","         0.0000e+00, 8.9002e-02, 2.9406e-02, 2.6978e-02, 3.7727e-02, 8.3634e-02,\n","         0.0000e+00, 5.1610e-02, 0.0000e+00, 0.0000e+00, 4.5846e-02, 1.4972e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2151e-01, 4.0335e-02, 1.8570e-02,\n","         1.2500e-01, 0.0000e+00, 6.6094e-02, 0.0000e+00, 0.0000e+00, 4.5480e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7834e-02, 0.0000e+00, 1.1075e-01, 0.0000e+00, 5.8460e-02, 8.8586e-02,\n","         0.0000e+00, 0.0000e+00, 6.0655e-02, 0.0000e+00, 0.0000e+00, 1.2653e-01,\n","         3.4556e-02, 9.5283e-02, 3.8921e-02, 1.3146e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3622e-02, 1.1496e-01, 0.0000e+00, 6.1082e-02,\n","         0.0000e+00, 0.0000e+00, 1.0960e-01, 0.0000e+00, 5.6572e-02, 9.9846e-02,\n","         0.0000e+00, 5.7817e-03, 8.9479e-02, 0.0000e+00, 2.8340e-02, 0.0000e+00,\n","         0.0000e+00, 8.8961e-02, 2.9056e-02, 2.7259e-02, 3.7865e-02, 8.3720e-02,\n","         0.0000e+00, 5.1493e-02, 0.0000e+00, 0.0000e+00, 4.5810e-02, 1.4942e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2186e-01, 4.0567e-02, 1.8576e-02,\n","         1.2479e-01, 0.0000e+00, 6.6140e-02, 0.0000e+00, 0.0000e+00, 4.6269e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7769e-02, 0.0000e+00, 1.1032e-01, 0.0000e+00, 5.8199e-02, 8.8517e-02,\n","         0.0000e+00, 0.0000e+00, 6.0447e-02, 0.0000e+00, 0.0000e+00, 1.2635e-01,\n","         3.4630e-02, 9.5151e-02, 3.8484e-02, 1.3113e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3616e-02, 1.1475e-01, 0.0000e+00, 6.1164e-02,\n","         0.0000e+00, 0.0000e+00, 1.0948e-01, 0.0000e+00, 5.6638e-02, 9.9837e-02,\n","         0.0000e+00, 5.5827e-03, 8.9683e-02, 0.0000e+00, 2.8234e-02, 0.0000e+00,\n","         0.0000e+00, 8.8786e-02, 2.8896e-02, 2.7335e-02, 3.8045e-02, 8.3314e-02,\n","         0.0000e+00, 5.1467e-02, 0.0000e+00, 0.0000e+00, 4.5821e-02, 1.4840e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2198e-01, 4.0655e-02, 1.8630e-02,\n","         1.2482e-01, 0.0000e+00, 6.6192e-02, 0.0000e+00, 0.0000e+00, 4.6623e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7825e-02, 0.0000e+00, 1.1177e-01, 0.0000e+00, 5.9032e-02, 8.8754e-02,\n","         0.0000e+00, 0.0000e+00, 6.1166e-02, 0.0000e+00, 0.0000e+00, 1.2708e-01,\n","         3.4353e-02, 9.5944e-02, 3.9828e-02, 1.3195e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3472e-02, 1.1512e-01, 0.0000e+00, 6.0481e-02,\n","         0.0000e+00, 0.0000e+00, 1.1011e-01, 0.0000e+00, 5.6469e-02, 9.9559e-02,\n","         0.0000e+00, 6.6707e-03, 8.8575e-02, 0.0000e+00, 2.8500e-02, 0.0000e+00,\n","         0.0000e+00, 8.9124e-02, 2.9817e-02, 2.6700e-02, 3.7572e-02, 8.3686e-02,\n","         0.0000e+00, 5.1745e-02, 0.0000e+00, 0.0000e+00, 4.5873e-02, 1.5056e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2110e-01, 4.0068e-02, 1.8564e-02,\n","         1.2521e-01, 0.0000e+00, 6.6076e-02, 0.0000e+00, 0.0000e+00, 4.4576e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 1.2434e-04, 2.1180e-02, 0.0000e+00, 2.9298e-02, 4.5940e-02,\n","         0.0000e+00, 0.0000e+00, 2.6953e-02, 0.0000e+00, 0.0000e+00, 8.6390e-02,\n","         8.3276e-03, 1.0871e-01, 0.0000e+00, 9.2434e-02, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 7.3556e-02, 1.2467e-01, 0.0000e+00, 6.6447e-02,\n","         0.0000e+00, 0.0000e+00, 1.1208e-01, 0.0000e+00, 9.2472e-02, 1.1002e-01,\n","         0.0000e+00, 0.0000e+00, 1.2243e-01, 0.0000e+00, 3.3294e-02, 0.0000e+00,\n","         0.0000e+00, 3.2541e-02, 3.3098e-02, 5.2043e-02, 5.1355e-02, 0.0000e+00,\n","         0.0000e+00, 1.0478e-01, 0.0000e+00, 0.0000e+00, 6.7165e-02, 3.7826e-03,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0235e-01, 4.9874e-02, 2.9341e-02,\n","         1.2487e-01, 0.0000e+00, 8.3353e-02, 0.0000e+00, 0.0000e+00, 7.3997e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 1.2434e-04, 2.1180e-02, 0.0000e+00, 2.9298e-02, 4.5940e-02,\n","         0.0000e+00, 0.0000e+00, 2.6953e-02, 0.0000e+00, 0.0000e+00, 8.6390e-02,\n","         8.3276e-03, 1.0871e-01, 0.0000e+00, 9.2434e-02, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 7.3556e-02, 1.2467e-01, 0.0000e+00, 6.6447e-02,\n","         0.0000e+00, 0.0000e+00, 1.1208e-01, 0.0000e+00, 9.2472e-02, 1.1002e-01,\n","         0.0000e+00, 0.0000e+00, 1.2243e-01, 0.0000e+00, 3.3294e-02, 0.0000e+00,\n","         0.0000e+00, 3.2541e-02, 3.3098e-02, 5.2043e-02, 5.1355e-02, 0.0000e+00,\n","         0.0000e+00, 1.0478e-01, 0.0000e+00, 0.0000e+00, 6.7165e-02, 3.7826e-03,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0235e-01, 4.9874e-02, 2.9341e-02,\n","         1.2487e-01, 0.0000e+00, 8.3353e-02, 0.0000e+00, 0.0000e+00, 7.3997e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7509e-02, 0.0000e+00, 1.1059e-01, 0.0000e+00, 5.8611e-02, 8.8461e-02,\n","         0.0000e+00, 0.0000e+00, 6.0713e-02, 0.0000e+00, 0.0000e+00, 1.2640e-01,\n","         3.4358e-02, 9.5320e-02, 3.9185e-02, 1.3174e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3716e-02, 1.1547e-01, 0.0000e+00, 6.1219e-02,\n","         0.0000e+00, 0.0000e+00, 1.0974e-01, 0.0000e+00, 5.6541e-02, 9.9902e-02,\n","         0.0000e+00, 5.8497e-03, 8.9451e-02, 0.0000e+00, 2.8627e-02, 0.0000e+00,\n","         0.0000e+00, 8.8913e-02, 2.9112e-02, 2.7380e-02, 3.7602e-02, 8.3645e-02,\n","         0.0000e+00, 5.1383e-02, 0.0000e+00, 0.0000e+00, 4.5703e-02, 1.5157e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2168e-01, 4.0556e-02, 1.8481e-02,\n","         1.2452e-01, 0.0000e+00, 6.6056e-02, 0.0000e+00, 0.0000e+00, 4.6179e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n","       grad_fn=<MaxBackward0>)], tensor([[0.5167, 0.4833],\n","        [0.5178, 0.4822],\n","        [0.5154, 0.4846],\n","        [0.5172, 0.4828],\n","        [0.5180, 0.4820],\n","        [0.5178, 0.4822],\n","        [0.5170, 0.4830],\n","        [0.5107, 0.4893],\n","        [0.5107, 0.4893],\n","        [0.5150, 0.4850]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[7.9909e-02, 0.0000e+00, 5.7825e-02, 2.3418e-01, 0.0000e+00, 3.1647e-02,\n","         0.0000e+00, 1.2466e-01, 8.6035e-02, 0.0000e+00, 0.0000e+00, 4.5423e-02,\n","         4.8232e-02, 4.3495e-03, 8.9123e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.2712e-01, 0.0000e+00, 4.6066e-02, 0.0000e+00,\n","         0.0000e+00, 8.6236e-02, 0.0000e+00, 0.0000e+00, 7.1468e-02, 1.2702e-02,\n","         2.1996e-02, 9.7059e-02, 6.5367e-02, 2.0567e-01, 0.0000e+00, 4.0276e-02,\n","         1.6063e-01, 0.0000e+00, 1.3883e-01, 0.0000e+00, 1.1385e-01, 0.0000e+00,\n","         7.7403e-02, 0.0000e+00, 1.1928e-01, 1.3452e-01, 3.4369e-02, 0.0000e+00,\n","         1.8957e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7889e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0256e-01, 0.0000e+00, 0.0000e+00, 8.0398e-02,\n","         0.0000e+00, 1.7220e-01, 6.4099e-02, 1.2325e-01],\n","        [8.1599e-02, 0.0000e+00, 5.9064e-02, 2.3286e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2716e-01, 9.2928e-02, 0.0000e+00, 0.0000e+00, 5.4240e-02,\n","         7.0890e-02, 5.4064e-02, 1.0809e-01, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.4477e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.1241e-01, 0.0000e+00, 0.0000e+00, 9.3389e-02, 1.5451e-02,\n","         3.4154e-02, 1.1090e-01, 6.6067e-02, 2.2128e-01, 0.0000e+00, 5.4012e-02,\n","         1.6784e-01, 0.0000e+00, 1.6419e-01, 0.0000e+00, 1.1940e-01, 1.8134e-02,\n","         8.6433e-02, 7.9503e-03, 1.2671e-01, 1.4689e-01, 3.6709e-02, 0.0000e+00,\n","         1.9471e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.0722e-02, 0.0000e+00,\n","         0.0000e+00, 2.3851e-04, 2.0541e-01, 0.0000e+00, 0.0000e+00, 8.6702e-02,\n","         0.0000e+00, 1.8564e-01, 1.0255e-01, 1.3274e-01],\n","        [8.1398e-02, 0.0000e+00, 5.9411e-02, 2.3376e-01, 0.0000e+00, 3.1419e-02,\n","         0.0000e+00, 1.2381e-01, 8.4829e-02, 0.0000e+00, 0.0000e+00, 4.8895e-02,\n","         4.5624e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.3033e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4100e-02, 0.0000e+00, 0.0000e+00, 7.1065e-02, 1.5113e-02,\n","         2.4683e-02, 1.1090e-01, 6.6249e-02, 2.0624e-01, 0.0000e+00, 4.0317e-02,\n","         1.6577e-01, 0.0000e+00, 1.3676e-01, 0.0000e+00, 1.1146e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1651e-01, 1.3250e-01, 3.6955e-02, 0.0000e+00,\n","         1.9357e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.8131e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0090e-01, 0.0000e+00, 0.0000e+00, 8.3015e-02,\n","         0.0000e+00, 1.7200e-01, 1.0255e-01, 1.2190e-01],\n","        [8.1937e-02, 0.0000e+00, 5.6268e-02, 1.8203e-01, 0.0000e+00, 3.0867e-02,\n","         0.0000e+00, 9.8444e-02, 3.6386e-02, 0.0000e+00, 0.0000e+00, 4.8548e-02,\n","         3.0548e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2641e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 7.0989e-02, 0.0000e+00, 0.0000e+00, 2.9078e-02, 1.2630e-02,\n","         2.3871e-02, 1.1090e-01, 6.3093e-02, 1.9824e-01, 0.0000e+00, 1.7055e-02,\n","         1.6561e-01, 0.0000e+00, 1.2322e-01, 0.0000e+00, 1.0620e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.0647e-01, 8.3293e-02, 3.2134e-02, 0.0000e+00,\n","         1.9306e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.8857e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.7141e-01, 0.0000e+00, 0.0000e+00, 8.3825e-02,\n","         0.0000e+00, 1.3167e-01, 1.0255e-01, 9.8684e-02],\n","        [8.8691e-02, 0.0000e+00, 6.0870e-02, 2.3418e-01, 0.0000e+00, 3.1160e-02,\n","         0.0000e+00, 1.2466e-01, 8.6035e-02, 0.0000e+00, 0.0000e+00, 6.0544e-02,\n","         4.6727e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.3824e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4397e-02, 0.0000e+00, 0.0000e+00, 7.1468e-02, 1.6921e-02,\n","         2.9233e-02, 1.1090e-01, 6.6316e-02, 2.1065e-01, 0.0000e+00, 3.9864e-02,\n","         1.7977e-01, 0.0000e+00, 1.3682e-01, 0.0000e+00, 1.1241e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1751e-01, 1.3367e-01, 3.7011e-02, 0.0000e+00,\n","         2.0341e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.1923e-02, 0.0000e+00,\n","         0.0000e+00, 4.7840e-03, 2.0256e-01, 0.0000e+00, 0.0000e+00, 9.2698e-02,\n","         0.0000e+00, 1.7220e-01, 1.0255e-01, 1.2169e-01],\n","        [8.4213e-02, 0.0000e+00, 5.5008e-02, 2.3427e-01, 0.0000e+00, 3.1160e-02,\n","         0.0000e+00, 1.2716e-01, 9.2928e-02, 0.0000e+00, 0.0000e+00, 3.3339e-02,\n","         5.8754e-02, 5.4064e-02, 1.0809e-01, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.4477e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.7813e-02, 0.0000e+00, 0.0000e+00, 9.3389e-02, 5.6614e-03,\n","         3.4154e-02, 1.1090e-01, 6.2475e-02, 2.2128e-01, 0.0000e+00, 5.4012e-02,\n","         1.6095e-01, 0.0000e+00, 1.6419e-01, 0.0000e+00, 1.1232e-01, 1.8134e-02,\n","         8.6433e-02, 7.9503e-03, 1.1717e-01, 1.4456e-01, 2.5938e-02, 0.0000e+00,\n","         1.8397e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.3867e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0244e-01, 0.0000e+00, 0.0000e+00, 7.4764e-02,\n","         0.0000e+00, 1.8564e-01, 1.0255e-01, 1.2164e-01],\n","        [8.1057e-02, 0.0000e+00, 5.7303e-02, 2.4071e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2653e-01, 9.2130e-02, 0.0000e+00, 0.0000e+00, 4.9839e-02,\n","         7.0890e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2819e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.1241e-01, 0.0000e+00, 0.0000e+00, 8.7246e-02, 1.3593e-02,\n","         2.4103e-02, 1.1090e-01, 6.4742e-02, 2.1244e-01, 0.0000e+00, 4.1506e-02,\n","         1.6639e-01, 0.0000e+00, 1.5546e-01, 0.0000e+00, 1.1940e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.2671e-01, 1.4689e-01, 3.3532e-02, 0.0000e+00,\n","         1.9386e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.9470e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0552e-01, 0.0000e+00, 0.0000e+00, 8.4351e-02,\n","         0.0000e+00, 1.8060e-01, 1.0255e-01, 1.3274e-01],\n","        [8.4213e-02, 0.0000e+00, 5.5008e-02, 2.3555e-01, 0.0000e+00, 3.0867e-02,\n","         0.0000e+00, 1.2561e-01, 8.7775e-02, 0.0000e+00, 0.0000e+00, 3.3339e-02,\n","         4.5160e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2127e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.3315e-02, 0.0000e+00, 0.0000e+00, 7.1681e-02, 5.6614e-03,\n","         2.2092e-02, 1.1090e-01, 6.2475e-02, 2.0895e-01, 0.0000e+00, 3.9050e-02,\n","         1.6446e-01, 0.0000e+00, 1.3568e-01, 0.0000e+00, 1.1089e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1572e-01, 1.3319e-01, 2.5938e-02, 0.0000e+00,\n","         1.8588e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.3867e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0452e-01, 0.0000e+00, 0.0000e+00, 7.4764e-02,\n","         0.0000e+00, 1.7699e-01, 1.0255e-01, 1.2020e-01],\n","        [8.3592e-02, 0.0000e+00, 5.7792e-02, 2.3427e-01, 0.0000e+00, 3.1160e-02,\n","         0.0000e+00, 1.2716e-01, 9.2928e-02, 0.0000e+00, 0.0000e+00, 5.2400e-02,\n","         5.8754e-02, 5.4064e-02, 1.0809e-01, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.4477e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.7813e-02, 0.0000e+00, 0.0000e+00, 9.3389e-02, 1.2435e-02,\n","         3.4154e-02, 1.1090e-01, 6.3892e-02, 2.2128e-01, 0.0000e+00, 5.4012e-02,\n","         1.7164e-01, 0.0000e+00, 1.6419e-01, 0.0000e+00, 1.1232e-01, 1.8134e-02,\n","         8.6433e-02, 7.9503e-03, 1.1717e-01, 1.4456e-01, 3.0212e-02, 0.0000e+00,\n","         1.9710e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.9774e-02, 0.0000e+00,\n","         0.0000e+00, 1.5711e-03, 2.0244e-01, 0.0000e+00, 0.0000e+00, 8.6442e-02,\n","         0.0000e+00, 1.8564e-01, 1.0255e-01, 1.2164e-01],\n","        [7.8896e-02, 0.0000e+00, 5.2088e-02, 2.3286e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2236e-01, 9.2130e-02, 0.0000e+00, 0.0000e+00, 2.4976e-02,\n","         7.0890e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.1608e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.1241e-01, 0.0000e+00, 0.0000e+00, 8.7246e-02, 0.0000e+00,\n","         1.7932e-02, 1.1090e-01, 5.9366e-02, 1.9294e-01, 0.0000e+00, 2.7469e-02,\n","         1.5179e-01, 0.0000e+00, 1.5546e-01, 0.0000e+00, 1.1940e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.2671e-01, 1.4689e-01, 1.7825e-02, 0.0000e+00,\n","         1.7728e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.0052e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0541e-01, 0.0000e+00, 0.0000e+00, 6.9447e-02,\n","         0.0000e+00, 1.5793e-01, 1.0255e-01, 1.3274e-01]],\n","       grad_fn=<MaxBackward0>), tensor([[0.0375, 0.0000, 0.1119, 0.0000, 0.0595, 0.0889, 0.0000, 0.0000, 0.0617,\n","         0.0000, 0.0000, 0.1270, 0.0340, 0.0963, 0.0406, 0.1325, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1158, 0.0000, 0.0604, 0.0000, 0.0000, 0.1106,\n","         0.0000, 0.0563, 0.0996, 0.0000, 0.0070, 0.0884, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0893, 0.0302, 0.0267, 0.0370, 0.0838, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0458, 0.0155, 0.0000, 0.0000, 0.0000, 0.1204, 0.0399, 0.0183,\n","         0.1252, 0.0000, 0.0659, 0.0000, 0.0000, 0.0439, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1113, 0.0000, 0.0593, 0.0887, 0.0000, 0.0000, 0.0614,\n","         0.0000, 0.0000, 0.1267, 0.0340, 0.0960, 0.0403, 0.1323, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1159, 0.0000, 0.0608, 0.0000, 0.0000, 0.1104,\n","         0.0000, 0.0563, 0.0998, 0.0000, 0.0066, 0.0888, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0891, 0.0298, 0.0270, 0.0371, 0.0836, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1206, 0.0401, 0.0183,\n","         0.1249, 0.0000, 0.0658, 0.0000, 0.0000, 0.0446, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1109, 0.0000, 0.0589, 0.0887, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1265, 0.0342, 0.0957, 0.0398, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1157, 0.0000, 0.0610, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0564, 0.0999, 0.0000, 0.0062, 0.0892, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0891, 0.0295, 0.0272, 0.0373, 0.0837, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0154, 0.0000, 0.0000, 0.0000, 0.1211, 0.0403, 0.0184,\n","         0.1248, 0.0000, 0.0659, 0.0000, 0.0000, 0.0454, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1104, 0.0000, 0.0585, 0.0889, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1263, 0.0345, 0.0952, 0.0389, 0.1315, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1153, 0.0000, 0.0613, 0.0000, 0.0000, 0.1097,\n","         0.0000, 0.0566, 0.1000, 0.0000, 0.0057, 0.0899, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0892, 0.0289, 0.0276, 0.0376, 0.0841, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0457, 0.0152, 0.0000, 0.0000, 0.0000, 0.1218, 0.0406, 0.0184,\n","         0.1246, 0.0000, 0.0661, 0.0000, 0.0000, 0.0466, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1112, 0.0000, 0.0591, 0.0887, 0.0000, 0.0000, 0.0613,\n","         0.0000, 0.0000, 0.1266, 0.0341, 0.0959, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1158, 0.0000, 0.0609, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0563, 0.0999, 0.0000, 0.0064, 0.0890, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0892, 0.0296, 0.0271, 0.0372, 0.0838, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1209, 0.0402, 0.0183,\n","         0.1248, 0.0000, 0.0659, 0.0000, 0.0000, 0.0451, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0379, 0.0000, 0.1119, 0.0000, 0.0592, 0.0892, 0.0000, 0.0000, 0.0615,\n","         0.0000, 0.0000, 0.1271, 0.0344, 0.0960, 0.0400, 0.1321, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1153, 0.0000, 0.0606, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0066, 0.0889, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0896, 0.0297, 0.0269, 0.0374, 0.0845, 0.0000, 0.0518, 0.0000,\n","         0.0000, 0.0458, 0.0153, 0.0000, 0.0000, 0.0000, 0.1211, 0.0401, 0.0184,\n","         0.1252, 0.0000, 0.0660, 0.0000, 0.0000, 0.0448, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1115, 0.0000, 0.0591, 0.0889, 0.0000, 0.0000, 0.0614,\n","         0.0000, 0.0000, 0.1268, 0.0342, 0.0960, 0.0401, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1154, 0.0000, 0.0606, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0067, 0.0887, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0892, 0.0299, 0.0268, 0.0373, 0.0836, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0458, 0.0153, 0.0000, 0.0000, 0.0000, 0.1208, 0.0400, 0.0184,\n","         0.1253, 0.0000, 0.0659, 0.0000, 0.0000, 0.0446, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0379, 0.0000, 0.1112, 0.0000, 0.0588, 0.0890, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1267, 0.0345, 0.0956, 0.0394, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1152, 0.0000, 0.0610, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0565, 0.0999, 0.0000, 0.0060, 0.0894, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0894, 0.0293, 0.0272, 0.0376, 0.0843, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1216, 0.0404, 0.0184,\n","         0.1249, 0.0000, 0.0661, 0.0000, 0.0000, 0.0458, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1106, 0.0000, 0.0587, 0.0887, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1264, 0.0343, 0.0956, 0.0394, 0.1317, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1153, 0.0000, 0.0610, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0564, 0.0999, 0.0000, 0.0060, 0.0894, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0890, 0.0293, 0.0273, 0.0375, 0.0835, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0152, 0.0000, 0.0000, 0.0000, 0.1213, 0.0404, 0.0184,\n","         0.1249, 0.0000, 0.0660, 0.0000, 0.0000, 0.0458, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0381, 0.0000, 0.1108, 0.0000, 0.0584, 0.0891, 0.0000, 0.0000, 0.0609,\n","         0.0000, 0.0000, 0.1265, 0.0348, 0.0953, 0.0388, 0.1314, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1148, 0.0000, 0.0612, 0.0000, 0.0000, 0.1096,\n","         0.0000, 0.0566, 0.0999, 0.0000, 0.0057, 0.0898, 0.0000, 0.0281, 0.0000,\n","         0.0000, 0.0894, 0.0289, 0.0274, 0.0379, 0.0843, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0150, 0.0000, 0.0000, 0.0000, 0.1219, 0.0406, 0.0185,\n","         0.1249, 0.0000, 0.0662, 0.0000, 0.0000, 0.0465, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5158, 0.4842],\n","        [0.5186, 0.4814],\n","        [0.5169, 0.4831],\n","        [0.5142, 0.4858],\n","        [0.5174, 0.4826],\n","        [0.5176, 0.4824],\n","        [0.5181, 0.4819],\n","        [0.5165, 0.4835],\n","        [0.5182, 0.4818],\n","        [0.5159, 0.4841]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0842, 0.0000, 0.0593, 0.2343, 0.0000, 0.0312, 0.0000, 0.1246, 0.0859,\n","         0.0000, 0.0000, 0.0582, 0.0461, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1334, 0.0000, 0.0636, 0.0000, 0.0198, 0.0841, 0.0000,\n","         0.0000, 0.0714, 0.0171, 0.0281, 0.1109, 0.0780, 0.2078, 0.0000, 0.0415,\n","         0.1745, 0.0000, 0.1365, 0.0000, 0.1117, 0.0000, 0.0864, 0.0000, 0.1168,\n","         0.1332, 0.0359, 0.0000, 0.2144, 0.0000, 0.0113, 0.0000, 0.0423, 0.0000,\n","         0.0000, 0.0032, 0.2023, 0.0000, 0.0000, 0.0896, 0.0000, 0.1729, 0.1025,\n","         0.1216],\n","        [0.0880, 0.0000, 0.0610, 0.2345, 0.0000, 0.0312, 0.0000, 0.1244, 0.0858,\n","         0.0000, 0.0000, 0.0623, 0.0448, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1384, 0.0000, 0.0636, 0.0000, 0.0198, 0.0836, 0.0000,\n","         0.0000, 0.0712, 0.0173, 0.0303, 0.1109, 0.0649, 0.2127, 0.0000, 0.0397,\n","         0.1808, 0.0000, 0.1359, 0.0000, 0.1113, 0.0000, 0.0864, 0.0000, 0.1156,\n","         0.1321, 0.0334, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2018, 0.0000, 0.0000, 0.0931, 0.0000, 0.1742, 0.1025,\n","         0.1212],\n","        [0.0853, 0.0000, 0.0604, 0.2355, 0.0000, 0.0312, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0603, 0.0588, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.0878, 0.0000,\n","         0.0000, 0.0934, 0.0189, 0.0342, 0.1109, 0.0722, 0.2213, 0.0000, 0.0540,\n","         0.1758, 0.0000, 0.1642, 0.0000, 0.1123, 0.0181, 0.0864, 0.0080, 0.1227,\n","         0.1446, 0.0385, 0.0000, 0.2010, 0.0000, 0.0113, 0.0000, 0.0426, 0.0000,\n","         0.0000, 0.0033, 0.2125, 0.0000, 0.0000, 0.0919, 0.0000, 0.1856, 0.1025,\n","         0.1227],\n","        [0.0864, 0.0000, 0.0599, 0.2343, 0.0000, 0.0422, 0.0000, 0.1324, 0.0921,\n","         0.0000, 0.0000, 0.0738, 0.0709, 0.0043, 0.0921, 0.0000, 0.0000, 0.0042,\n","         0.0000, 0.0000, 0.1475, 0.0000, 0.0516, 0.0000, 0.0003, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0219, 0.0413, 0.0987, 0.0705, 0.2061, 0.0000, 0.0399,\n","         0.1912, 0.0000, 0.1555, 0.0000, 0.1194, 0.0055, 0.0829, 0.0000, 0.1267,\n","         0.1469, 0.0389, 0.0000, 0.2167, 0.0000, 0.0000, 0.0000, 0.0390, 0.0000,\n","         0.0000, 0.0034, 0.2054, 0.0000, 0.0000, 0.0915, 0.0000, 0.1726, 0.0881,\n","         0.1327],\n","        [0.0832, 0.0000, 0.0661, 0.2329, 0.0000, 0.0422, 0.0000, 0.1448, 0.0929,\n","         0.0000, 0.0000, 0.0519, 0.0793, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0158, 0.0342, 0.1109, 0.0907, 0.2213, 0.0000, 0.0540,\n","         0.1773, 0.0000, 0.1762, 0.0000, 0.1194, 0.0457, 0.1201, 0.0080, 0.1394,\n","         0.1469, 0.0352, 0.0000, 0.1945, 0.0000, 0.0113, 0.0000, 0.0390, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0863, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0809, 0.0000, 0.0585, 0.2329, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0513, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0134, 0.0342, 0.1109, 0.0660, 0.2213, 0.0000, 0.0540,\n","         0.1668, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0356, 0.0000, 0.1937, 0.0000, 0.0113, 0.0000, 0.0398, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0844, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0898, 0.0000, 0.0623, 0.2329, 0.0000, 0.0422, 0.0000, 0.1234, 0.0921,\n","         0.0000, 0.0000, 0.0519, 0.0709, 0.0043, 0.0921, 0.0000, 0.0000, 0.0016,\n","         0.0000, 0.0000, 0.1324, 0.0000, 0.0503, 0.0000, 0.0003, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0158, 0.0244, 0.0987, 0.0732, 0.2024, 0.0000, 0.0428,\n","         0.1965, 0.0000, 0.1555, 0.0000, 0.1194, 0.0031, 0.0844, 0.0000, 0.1267,\n","         0.1469, 0.0352, 0.0000, 0.2040, 0.0000, 0.0000, 0.0000, 0.0390, 0.0000,\n","         0.0000, 0.0041, 0.2054, 0.0000, 0.0000, 0.0863, 0.0000, 0.1682, 0.0673,\n","         0.1327],\n","        [0.0912, 0.0000, 0.0608, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0675, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1413, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0205, 0.0325, 0.1109, 0.0796, 0.2191, 0.0000, 0.0440,\n","         0.1865, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0349, 0.0000, 0.2238, 0.0000, 0.0113, 0.0000, 0.0441, 0.0000,\n","         0.0000, 0.0085, 0.2054, 0.0000, 0.0000, 0.0970, 0.0000, 0.1724, 0.1025,\n","         0.1327],\n","        [0.0976, 0.0000, 0.0619, 0.2067, 0.0000, 0.0309, 0.0000, 0.1025, 0.0532,\n","         0.0000, 0.0000, 0.0788, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0018, 0.0000, 0.1497, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0203, 0.0389, 0.1109, 0.0666, 0.2331, 0.0000, 0.0246,\n","         0.1983, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.1100,\n","         0.0562, 0.0379, 0.0000, 0.2178, 0.0000, 0.0113, 0.0000, 0.0458, 0.0000,\n","         0.0000, 0.0146, 0.1730, 0.0000, 0.0000, 0.1048, 0.0000, 0.1693, 0.1025,\n","         0.0934],\n","        [0.0822, 0.0000, 0.0661, 0.2329, 0.0000, 0.0535, 0.0000, 0.1262, 0.0921,\n","         0.0000, 0.0000, 0.0539, 0.0867, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1315, 0.0000, 0.0747, 0.0000, 0.0198, 0.1154, 0.0140,\n","         0.0000, 0.0872, 0.0167, 0.0255, 0.1109, 0.0766, 0.2011, 0.0000, 0.0398,\n","         0.1718, 0.0000, 0.1555, 0.0000, 0.1225, 0.0145, 0.1055, 0.0000, 0.1267,\n","         0.1469, 0.0370, 0.0000, 0.1953, 0.0000, 0.0113, 0.0000, 0.0405, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0032, 0.0871, 0.0000, 0.1579, 0.1025,\n","         0.1342]], grad_fn=<MaxBackward0>), tensor([[0.0375, 0.0000, 0.1113, 0.0000, 0.0590, 0.0883, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1268, 0.0341, 0.0957, 0.0399, 0.1321, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1155, 0.0000, 0.0608, 0.0000, 0.0000, 0.1100,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0064, 0.0887, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0888, 0.0296, 0.0270, 0.0374, 0.0834, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1212, 0.0403, 0.0185,\n","         0.1247, 0.0000, 0.0660, 0.0000, 0.0000, 0.0450, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1106, 0.0000, 0.0584, 0.0884, 0.0000, 0.0000, 0.0605,\n","         0.0000, 0.0000, 0.1265, 0.0346, 0.0952, 0.0388, 0.1314, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1150, 0.0000, 0.0611, 0.0000, 0.0000, 0.1095,\n","         0.0000, 0.0567, 0.0998, 0.0000, 0.0057, 0.0895, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0888, 0.0290, 0.0273, 0.0380, 0.0836, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0149, 0.0000, 0.0000, 0.0000, 0.1220, 0.0406, 0.0186,\n","         0.1247, 0.0000, 0.0662, 0.0000, 0.0000, 0.0464, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1115, 0.0000, 0.0591, 0.0883, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1269, 0.0340, 0.0958, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1156, 0.0000, 0.0606, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0562, 0.0997, 0.0000, 0.0067, 0.0885, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0887, 0.0298, 0.0268, 0.0372, 0.0832, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0151, 0.0000, 0.0000, 0.0000, 0.1209, 0.0401, 0.0184,\n","         0.1250, 0.0000, 0.0659, 0.0000, 0.0000, 0.0445, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1118, 0.0000, 0.0591, 0.0884, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1270, 0.0342, 0.0960, 0.0401, 0.1320, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0834, 0.1152, 0.0000, 0.0604, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0563, 0.0995, 0.0000, 0.0068, 0.0883, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0888, 0.0300, 0.0266, 0.0375, 0.0832, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0459, 0.0150, 0.0000, 0.0000, 0.0000, 0.1209, 0.0400, 0.0186,\n","         0.1253, 0.0000, 0.0660, 0.0000, 0.0000, 0.0443, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1100, 0.0000, 0.0581, 0.0880, 0.0000, 0.0000, 0.0602,\n","         0.0000, 0.0000, 0.1262, 0.0343, 0.0952, 0.0385, 0.1311, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1147, 0.0000, 0.0610, 0.0000, 0.0000, 0.1095,\n","         0.0000, 0.0564, 0.0998, 0.0000, 0.0058, 0.0893, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0882, 0.0291, 0.0272, 0.0379, 0.0822, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0458, 0.0147, 0.0000, 0.0000, 0.0000, 0.1217, 0.0406, 0.0186,\n","         0.1250, 0.0000, 0.0661, 0.0000, 0.0000, 0.0462, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1115, 0.0000, 0.0591, 0.0884, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1269, 0.0342, 0.0958, 0.0400, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1155, 0.0000, 0.0607, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0563, 0.0996, 0.0000, 0.0065, 0.0886, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0889, 0.0297, 0.0269, 0.0374, 0.0834, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0152, 0.0000, 0.0000, 0.0000, 0.1211, 0.0402, 0.0185,\n","         0.1248, 0.0000, 0.0660, 0.0000, 0.0000, 0.0448, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1119, 0.0000, 0.0592, 0.0885, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1271, 0.0342, 0.0959, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0834, 0.1153, 0.0000, 0.0605, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0564, 0.0996, 0.0000, 0.0068, 0.0884, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0890, 0.0298, 0.0267, 0.0374, 0.0837, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1210, 0.0401, 0.0186,\n","         0.1250, 0.0000, 0.0660, 0.0000, 0.0000, 0.0444, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1107, 0.0000, 0.0585, 0.0883, 0.0000, 0.0000, 0.0606,\n","         0.0000, 0.0000, 0.1265, 0.0344, 0.0953, 0.0391, 0.1316, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1151, 0.0000, 0.0610, 0.0000, 0.0000, 0.1096,\n","         0.0000, 0.0565, 0.0998, 0.0000, 0.0058, 0.0892, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0887, 0.0292, 0.0271, 0.0378, 0.0833, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0149, 0.0000, 0.0000, 0.0000, 0.1217, 0.0405, 0.0186,\n","         0.1248, 0.0000, 0.0661, 0.0000, 0.0000, 0.0460, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1107, 0.0000, 0.0585, 0.0885, 0.0000, 0.0000, 0.0606,\n","         0.0000, 0.0000, 0.1265, 0.0346, 0.0951, 0.0390, 0.1316, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1153, 0.0000, 0.0613, 0.0000, 0.0000, 0.1096,\n","         0.0000, 0.0567, 0.0999, 0.0000, 0.0057, 0.0896, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0890, 0.0290, 0.0275, 0.0378, 0.0840, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0457, 0.0151, 0.0000, 0.0000, 0.0000, 0.1220, 0.0406, 0.0186,\n","         0.1245, 0.0000, 0.0661, 0.0000, 0.0000, 0.0465, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1110, 0.0000, 0.0587, 0.0883, 0.0000, 0.0000, 0.0607,\n","         0.0000, 0.0000, 0.1267, 0.0343, 0.0955, 0.0393, 0.1317, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1151, 0.0000, 0.0609, 0.0000, 0.0000, 0.1098,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0062, 0.0890, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0887, 0.0293, 0.0270, 0.0377, 0.0832, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0149, 0.0000, 0.0000, 0.0000, 0.1215, 0.0404, 0.0186,\n","         0.1248, 0.0000, 0.0661, 0.0000, 0.0000, 0.0455, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5172, 0.4828],\n","        [0.5175, 0.4825],\n","        [0.5187, 0.4813],\n","        [0.5178, 0.4822],\n","        [0.5192, 0.4808],\n","        [0.5185, 0.4815],\n","        [0.5167, 0.4833],\n","        [0.5189, 0.4811],\n","        [0.5167, 0.4833],\n","        [0.5179, 0.4821]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0891, 0.0000, 0.0660, 0.2343, 0.0000, 0.0314, 0.0000, 0.1296, 0.0876,\n","         0.0000, 0.0000, 0.0233, 0.0482, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1307, 0.0000, 0.0636, 0.0000, 0.0198, 0.0841, 0.0000,\n","         0.0000, 0.0718, 0.0066, 0.0222, 0.1109, 0.0783, 0.2042, 0.0000, 0.0444,\n","         0.1979, 0.0000, 0.1390, 0.0000, 0.1120, 0.0134, 0.0870, 0.0000, 0.1198,\n","         0.1349, 0.0212, 0.0000, 0.1994, 0.0000, 0.0113, 0.0000, 0.0321, 0.0000,\n","         0.0000, 0.0026, 0.2055, 0.0000, 0.0000, 0.0637, 0.0000, 0.1712, 0.1025,\n","         0.1229],\n","        [0.0913, 0.0000, 0.0677, 0.2329, 0.0000, 0.0422, 0.0000, 0.1448, 0.0921,\n","         0.0000, 0.0000, 0.0443, 0.0793, 0.0028, 0.0921, 0.0000, 0.0000, 0.0040,\n","         0.0000, 0.0000, 0.1328, 0.0000, 0.0482, 0.0000, 0.0003, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0127, 0.0241, 0.1022, 0.0907, 0.1984, 0.0000, 0.0525,\n","         0.2061, 0.0000, 0.1762, 0.0000, 0.1194, 0.0457, 0.1201, 0.0000, 0.1394,\n","         0.1469, 0.0288, 0.0000, 0.2114, 0.0000, 0.0000, 0.0000, 0.0339, 0.0000,\n","         0.0000, 0.0034, 0.2138, 0.0000, 0.0000, 0.0865, 0.0000, 0.1579, 0.0656,\n","         0.1327],\n","        [0.0790, 0.0000, 0.0528, 0.2329, 0.0000, 0.0422, 0.0000, 0.1448, 0.0929,\n","         0.0000, 0.0000, 0.0301, 0.0793, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0090, 0.0342, 0.1109, 0.0907, 0.2213, 0.0000, 0.0540,\n","         0.1773, 0.0000, 0.1762, 0.0000, 0.1194, 0.0457, 0.1201, 0.0080, 0.1394,\n","         0.1469, 0.0230, 0.0000, 0.2051, 0.0000, 0.0113, 0.0000, 0.0232, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0771, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0782, 0.0000, 0.0555, 0.2353, 0.0000, 0.0314, 0.0000, 0.1243, 0.0862,\n","         0.0000, 0.0000, 0.0348, 0.0461, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1233, 0.0000, 0.0636, 0.0000, 0.0198, 0.0841, 0.0000,\n","         0.0000, 0.0723, 0.0061, 0.0224, 0.1109, 0.0750, 0.2059, 0.0000, 0.0434,\n","         0.1651, 0.0000, 0.1391, 0.0000, 0.1129, 0.0000, 0.0864, 0.0000, 0.1166,\n","         0.1345, 0.0268, 0.0000, 0.2106, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2015, 0.0000, 0.0000, 0.0774, 0.0000, 0.1732, 0.1025,\n","         0.1224],\n","        [0.0842, 0.0000, 0.0594, 0.2382, 0.0000, 0.0309, 0.0000, 0.1247, 0.0881,\n","         0.0000, 0.0000, 0.0590, 0.0448, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1335, 0.0000, 0.0636, 0.0000, 0.0198, 0.0816, 0.0000,\n","         0.0000, 0.0700, 0.0169, 0.0286, 0.1109, 0.0652, 0.2093, 0.0000, 0.0425,\n","         0.1746, 0.0000, 0.1350, 0.0000, 0.1128, 0.0000, 0.0864, 0.0000, 0.1193,\n","         0.1344, 0.0364, 0.0000, 0.2000, 0.0000, 0.0113, 0.0000, 0.0425, 0.0000,\n","         0.0000, 0.0035, 0.2031, 0.0000, 0.0000, 0.0901, 0.0000, 0.1761, 0.1025,\n","         0.1231],\n","        [0.0842, 0.0000, 0.0555, 0.2329, 0.0000, 0.0535, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0348, 0.0867, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1218, 0.0000, 0.0747, 0.0000, 0.0198, 0.1154, 0.0140,\n","         0.0000, 0.0872, 0.0061, 0.0185, 0.1109, 0.0629, 0.1929, 0.0000, 0.0275,\n","         0.1556, 0.0000, 0.1555, 0.0000, 0.1225, 0.0000, 0.1055, 0.0000, 0.1267,\n","         0.1469, 0.0268, 0.0000, 0.1814, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0032, 0.0713, 0.0000, 0.1579, 0.1025,\n","         0.1342],\n","        [0.0809, 0.0000, 0.0516, 0.2357, 0.0000, 0.0535, 0.0000, 0.1255, 0.0877,\n","         0.0000, 0.0000, 0.0313, 0.0867, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1250, 0.0000, 0.0747, 0.0000, 0.0198, 0.1154, 0.0140,\n","         0.0000, 0.0716, 0.0059, 0.0227, 0.1109, 0.0626, 0.2097, 0.0000, 0.0390,\n","         0.1703, 0.0000, 0.1357, 0.0000, 0.1225, 0.0000, 0.1055, 0.0000, 0.1197,\n","         0.1326, 0.0188, 0.0000, 0.1929, 0.0000, 0.0113, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0000, 0.2043, 0.0000, 0.0032, 0.0785, 0.0000, 0.1777, 0.1025,\n","         0.1342],\n","        [0.0911, 0.0000, 0.0610, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0690, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1416, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0194, 0.0335, 0.1109, 0.0658, 0.2208, 0.0000, 0.0275,\n","         0.1868, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0360, 0.0000, 0.2092, 0.0000, 0.0113, 0.0000, 0.0446, 0.0000,\n","         0.0000, 0.0092, 0.2054, 0.0000, 0.0000, 0.0979, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0320, 0.0000, 0.0453, 0.0950, 0.0000, 0.0309, 0.0000, 0.0781, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.0812, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0000, 0.0000, 0.1109, 0.0527, 0.0741, 0.0000, 0.0024,\n","         0.0643, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.0299,\n","         0.0536, 0.0000, 0.0000, 0.1006, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0015, 0.1025,\n","         0.0934],\n","        [0.0738, 0.0000, 0.0555, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0348, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1218, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0061, 0.0185, 0.1109, 0.0629, 0.1929, 0.0000, 0.0275,\n","         0.1521, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0268, 0.0000, 0.1814, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0713, 0.0000, 0.1579, 0.1025,\n","         0.1327]], grad_fn=<MaxBackward0>), tensor([[3.7517e-02, 0.0000e+00, 1.1024e-01, 0.0000e+00, 5.8078e-02, 8.7873e-02,\n","         0.0000e+00, 0.0000e+00, 6.0061e-02, 0.0000e+00, 0.0000e+00, 1.2637e-01,\n","         3.4389e-02, 9.5063e-02, 3.8430e-02, 1.3116e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3333e-02, 1.1470e-01, 0.0000e+00, 6.0944e-02,\n","         0.0000e+00, 0.0000e+00, 1.0937e-01, 0.0000e+00, 5.6527e-02, 9.9770e-02,\n","         0.0000e+00, 5.7983e-03, 8.9219e-02, 0.0000e+00, 2.8436e-02, 0.0000e+00,\n","         0.0000e+00, 8.8233e-02, 2.8986e-02, 2.7139e-02, 3.8046e-02, 8.2489e-02,\n","         0.0000e+00, 5.1375e-02, 0.0000e+00, 0.0000e+00, 4.5852e-02, 1.4515e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2202e-01, 4.0604e-02, 1.8688e-02,\n","         1.2475e-01, 0.0000e+00, 6.6165e-02, 0.0000e+00, 0.0000e+00, 4.6292e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7349e-02, 0.0000e+00, 1.1121e-01, 0.0000e+00, 5.8765e-02, 8.7853e-02,\n","         0.0000e+00, 0.0000e+00, 6.0656e-02, 0.0000e+00, 0.0000e+00, 1.2677e-01,\n","         3.3948e-02, 9.5667e-02, 3.9736e-02, 1.3194e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3296e-02, 1.1530e-01, 0.0000e+00, 6.0508e-02,\n","         0.0000e+00, 0.0000e+00, 1.0998e-01, 0.0000e+00, 5.6226e-02, 9.9651e-02,\n","         0.0000e+00, 6.6766e-03, 8.8361e-02, 0.0000e+00, 2.8807e-02, 0.0000e+00,\n","         0.0000e+00, 8.8274e-02, 2.9717e-02, 2.6760e-02, 3.7438e-02, 8.2456e-02,\n","         0.0000e+00, 5.1399e-02, 0.0000e+00, 0.0000e+00, 4.5838e-02, 1.4786e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2109e-01, 4.0205e-02, 1.8548e-02,\n","         1.2496e-01, 0.0000e+00, 6.5988e-02, 0.0000e+00, 0.0000e+00, 4.4649e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7327e-02, 0.0000e+00, 1.1014e-01, 0.0000e+00, 5.8004e-02, 8.7682e-02,\n","         0.0000e+00, 0.0000e+00, 6.0048e-02, 0.0000e+00, 0.0000e+00, 1.2638e-01,\n","         3.4179e-02, 9.5260e-02, 3.8534e-02, 1.3116e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3253e-02, 1.1458e-01, 0.0000e+00, 6.0772e-02,\n","         0.0000e+00, 0.0000e+00, 1.0948e-01, 0.0000e+00, 5.6371e-02, 9.9735e-02,\n","         0.0000e+00, 5.9692e-03, 8.8994e-02, 0.0000e+00, 2.8398e-02, 0.0000e+00,\n","         0.0000e+00, 8.7953e-02, 2.9169e-02, 2.7004e-02, 3.8029e-02, 8.1849e-02,\n","         0.0000e+00, 5.1370e-02, 0.0000e+00, 0.0000e+00, 4.5916e-02, 1.4437e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2177e-01, 4.0505e-02, 1.8648e-02,\n","         1.2504e-01, 0.0000e+00, 6.6065e-02, 0.0000e+00, 0.0000e+00, 4.5910e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7641e-02, 0.0000e+00, 1.1045e-01, 0.0000e+00, 5.8158e-02, 8.8083e-02,\n","         0.0000e+00, 0.0000e+00, 6.0174e-02, 0.0000e+00, 0.0000e+00, 1.2652e-01,\n","         3.4571e-02, 9.5034e-02, 3.8515e-02, 1.3129e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3313e-02, 1.1480e-01, 0.0000e+00, 6.1019e-02,\n","         0.0000e+00, 0.0000e+00, 1.0936e-01, 0.0000e+00, 5.6699e-02, 9.9741e-02,\n","         0.0000e+00, 5.7685e-03, 8.9292e-02, 0.0000e+00, 2.8500e-02, 0.0000e+00,\n","         0.0000e+00, 8.8463e-02, 2.9023e-02, 2.7220e-02, 3.8114e-02, 8.3015e-02,\n","         0.0000e+00, 5.1489e-02, 0.0000e+00, 0.0000e+00, 4.5831e-02, 1.4603e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2218e-01, 4.0567e-02, 1.8697e-02,\n","         1.2464e-01, 0.0000e+00, 6.6247e-02, 0.0000e+00, 0.0000e+00, 4.6382e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7826e-02, 0.0000e+00, 1.1129e-01, 0.0000e+00, 5.8703e-02, 8.8158e-02,\n","         0.0000e+00, 0.0000e+00, 6.0602e-02, 0.0000e+00, 0.0000e+00, 1.2684e-01,\n","         3.4382e-02, 9.5437e-02, 3.9391e-02, 1.3190e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3343e-02, 1.1514e-01, 0.0000e+00, 6.0857e-02,\n","         0.0000e+00, 0.0000e+00, 1.0965e-01, 0.0000e+00, 5.6523e-02, 9.9649e-02,\n","         0.0000e+00, 6.1313e-03, 8.8864e-02, 0.0000e+00, 2.8744e-02, 0.0000e+00,\n","         0.0000e+00, 8.8693e-02, 2.9334e-02, 2.6987e-02, 3.7765e-02, 8.3509e-02,\n","         0.0000e+00, 5.1467e-02, 0.0000e+00, 0.0000e+00, 4.5814e-02, 1.4813e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2175e-01, 4.0459e-02, 1.8685e-02,\n","         1.2460e-01, 0.0000e+00, 6.6126e-02, 0.0000e+00, 0.0000e+00, 4.5558e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.8378e-02, 0.0000e+00, 1.1181e-01, 0.0000e+00, 5.8699e-02, 8.8527e-02,\n","         0.0000e+00, 0.0000e+00, 6.0597e-02, 0.0000e+00, 0.0000e+00, 1.2716e-01,\n","         3.4710e-02, 9.5461e-02, 3.9114e-02, 1.3169e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3286e-02, 1.1466e-01, 0.0000e+00, 6.0768e-02,\n","         0.0000e+00, 0.0000e+00, 1.0954e-01, 0.0000e+00, 5.6655e-02, 9.9529e-02,\n","         0.0000e+00, 6.1301e-03, 8.8925e-02, 0.0000e+00, 2.8546e-02, 0.0000e+00,\n","         0.0000e+00, 8.9044e-02, 2.9259e-02, 2.6876e-02, 3.8046e-02, 8.4180e-02,\n","         0.0000e+00, 5.1618e-02, 0.0000e+00, 0.0000e+00, 4.5929e-02, 1.4657e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2206e-01, 4.0474e-02, 1.8823e-02,\n","         1.2473e-01, 0.0000e+00, 6.6288e-02, 0.0000e+00, 0.0000e+00, 4.5609e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.8272e-02, 0.0000e+00, 1.1142e-01, 0.0000e+00, 5.8481e-02, 8.8495e-02,\n","         0.0000e+00, 0.0000e+00, 6.0441e-02, 0.0000e+00, 0.0000e+00, 1.2699e-01,\n","         3.4768e-02, 9.5197e-02, 3.8831e-02, 1.3153e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3317e-02, 1.1467e-01, 0.0000e+00, 6.0919e-02,\n","         0.0000e+00, 0.0000e+00, 1.0942e-01, 0.0000e+00, 5.6746e-02, 9.9650e-02,\n","         0.0000e+00, 5.9408e-03, 8.9182e-02, 0.0000e+00, 2.8495e-02, 0.0000e+00,\n","         0.0000e+00, 8.8975e-02, 2.9103e-02, 2.7082e-02, 3.8136e-02, 8.4139e-02,\n","         0.0000e+00, 5.1588e-02, 0.0000e+00, 0.0000e+00, 4.5898e-02, 1.4641e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2229e-01, 4.0545e-02, 1.8778e-02,\n","         1.2466e-01, 0.0000e+00, 6.6310e-02, 0.0000e+00, 0.0000e+00, 4.6119e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7855e-02, 0.0000e+00, 1.1113e-01, 0.0000e+00, 5.8598e-02, 8.8137e-02,\n","         0.0000e+00, 0.0000e+00, 6.0500e-02, 0.0000e+00, 0.0000e+00, 1.2677e-01,\n","         3.4441e-02, 9.5396e-02, 3.9218e-02, 1.3174e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3357e-02, 1.1502e-01, 0.0000e+00, 6.0899e-02,\n","         0.0000e+00, 0.0000e+00, 1.0959e-01, 0.0000e+00, 5.6551e-02, 9.9623e-02,\n","         0.0000e+00, 6.0243e-03, 8.8950e-02, 0.0000e+00, 2.8686e-02, 0.0000e+00,\n","         0.0000e+00, 8.8638e-02, 2.9249e-02, 2.6989e-02, 3.7882e-02, 8.3358e-02,\n","         0.0000e+00, 5.1456e-02, 0.0000e+00, 0.0000e+00, 4.5824e-02, 1.4778e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2181e-01, 4.0503e-02, 1.8743e-02,\n","         1.2463e-01, 0.0000e+00, 6.6136e-02, 0.0000e+00, 0.0000e+00, 4.5717e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 1.2434e-04, 2.1180e-02, 0.0000e+00, 2.9298e-02, 4.5940e-02,\n","         0.0000e+00, 0.0000e+00, 2.6953e-02, 0.0000e+00, 0.0000e+00, 8.6390e-02,\n","         8.3276e-03, 1.0871e-01, 0.0000e+00, 9.2434e-02, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 7.3556e-02, 1.2467e-01, 0.0000e+00, 6.6447e-02,\n","         0.0000e+00, 0.0000e+00, 1.1208e-01, 0.0000e+00, 9.2472e-02, 1.1002e-01,\n","         0.0000e+00, 0.0000e+00, 1.2243e-01, 0.0000e+00, 3.3294e-02, 0.0000e+00,\n","         0.0000e+00, 3.2541e-02, 3.3098e-02, 5.2043e-02, 5.1355e-02, 0.0000e+00,\n","         0.0000e+00, 1.0478e-01, 0.0000e+00, 0.0000e+00, 6.7165e-02, 3.7826e-03,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0235e-01, 4.9874e-02, 2.9341e-02,\n","         1.2487e-01, 0.0000e+00, 8.3353e-02, 0.0000e+00, 0.0000e+00, 7.3997e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7729e-02, 0.0000e+00, 1.1059e-01, 0.0000e+00, 5.8270e-02, 8.8087e-02,\n","         0.0000e+00, 0.0000e+00, 6.0214e-02, 0.0000e+00, 0.0000e+00, 1.2656e-01,\n","         3.4549e-02, 9.5164e-02, 3.8636e-02, 1.3137e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3348e-02, 1.1481e-01, 0.0000e+00, 6.1018e-02,\n","         0.0000e+00, 0.0000e+00, 1.0942e-01, 0.0000e+00, 5.6664e-02, 9.9668e-02,\n","         0.0000e+00, 5.8019e-03, 8.9233e-02, 0.0000e+00, 2.8575e-02, 0.0000e+00,\n","         0.0000e+00, 8.8500e-02, 2.9038e-02, 2.7144e-02, 3.8094e-02, 8.3044e-02,\n","         0.0000e+00, 5.1454e-02, 0.0000e+00, 0.0000e+00, 4.5823e-02, 1.4655e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2208e-01, 4.0587e-02, 1.8758e-02,\n","         1.2460e-01, 0.0000e+00, 6.6210e-02, 0.0000e+00, 0.0000e+00, 4.6241e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n","       grad_fn=<MaxBackward0>)], tensor([[0.5158, 0.4842],\n","        [0.5172, 0.4828],\n","        [0.5180, 0.4820],\n","        [0.5162, 0.4838],\n","        [0.5173, 0.4827],\n","        [0.5168, 0.4832],\n","        [0.5170, 0.4830],\n","        [0.5191, 0.4809],\n","        [0.5107, 0.4893],\n","        [0.5164, 0.4836]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0792, 0.0000, 0.0529, 0.2325, 0.0000, 0.0314, 0.0000, 0.1236, 0.0843,\n","         0.0000, 0.0000, 0.0251, 0.0478, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1176, 0.0000, 0.0636, 0.0000, 0.0198, 0.0858, 0.0000,\n","         0.0000, 0.0712, 0.0000, 0.0209, 0.1109, 0.0598, 0.2029, 0.0000, 0.0398,\n","         0.1517, 0.0000, 0.1380, 0.0000, 0.1136, 0.0000, 0.0864, 0.0000, 0.1186,\n","         0.1345, 0.0174, 0.0000, 0.1819, 0.0000, 0.0113, 0.0000, 0.0303, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0707, 0.0000, 0.1688, 0.1025,\n","         0.1230],\n","        [0.0822, 0.0000, 0.0594, 0.2343, 0.0000, 0.0422, 0.0000, 0.1246, 0.0921,\n","         0.0000, 0.0000, 0.0539, 0.0709, 0.0043, 0.0921, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1315, 0.0000, 0.0461, 0.0000, 0.0003, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0167, 0.0255, 0.0972, 0.0659, 0.2065, 0.0000, 0.0398,\n","         0.1685, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0790, 0.0000, 0.1267,\n","         0.1469, 0.0370, 0.0000, 0.1953, 0.0000, 0.0000, 0.0000, 0.0405, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0871, 0.0000, 0.1729, 0.0640,\n","         0.1327],\n","        [0.0819, 0.0000, 0.0563, 0.2329, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0485, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0126, 0.0342, 0.1109, 0.0631, 0.2213, 0.0000, 0.0540,\n","         0.1656, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0321, 0.0000, 0.1931, 0.0000, 0.0113, 0.0000, 0.0389, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0838, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0901, 0.0000, 0.0627, 0.2337, 0.0000, 0.0314, 0.0000, 0.1239, 0.0849,\n","         0.0000, 0.0000, 0.0643, 0.0460, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1409, 0.0000, 0.0636, 0.0000, 0.0198, 0.0843, 0.0000,\n","         0.0000, 0.0711, 0.0221, 0.0301, 0.1109, 0.0671, 0.2133, 0.0000, 0.0404,\n","         0.1821, 0.0000, 0.1370, 0.0000, 0.1116, 0.0000, 0.0864, 0.0000, 0.1170,\n","         0.1328, 0.0378, 0.0000, 0.2046, 0.0000, 0.0113, 0.0000, 0.0427, 0.0000,\n","         0.0000, 0.0052, 0.2011, 0.0000, 0.0000, 0.0963, 0.0000, 0.1716, 0.1025,\n","         0.1220],\n","        [0.0816, 0.0000, 0.0555, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0348, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1218, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0078, 0.0185, 0.1109, 0.0717, 0.1929, 0.0000, 0.0335,\n","         0.1599, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0268, 0.0000, 0.1997, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0816, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0782, 0.0000, 0.0555, 0.2346, 0.0000, 0.0314, 0.0000, 0.1241, 0.0858,\n","         0.0000, 0.0000, 0.0348, 0.0465, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1218, 0.0000, 0.0636, 0.0000, 0.0198, 0.0844, 0.0000,\n","         0.0000, 0.0719, 0.0090, 0.0222, 0.1109, 0.0724, 0.2053, 0.0000, 0.0413,\n","         0.1596, 0.0000, 0.1386, 0.0000, 0.1129, 0.0000, 0.0864, 0.0000, 0.1171,\n","         0.1341, 0.0268, 0.0000, 0.2054, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2014, 0.0000, 0.0000, 0.0803, 0.0000, 0.1722, 0.1025,\n","         0.1223],\n","        [0.0837, 0.0000, 0.0593, 0.2357, 0.0000, 0.0309, 0.0000, 0.1255, 0.0877,\n","         0.0000, 0.0000, 0.0575, 0.0445, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1335, 0.0000, 0.0636, 0.0000, 0.0198, 0.0831, 0.0000,\n","         0.0000, 0.0716, 0.0162, 0.0288, 0.1109, 0.0656, 0.2097, 0.0000, 0.0390,\n","         0.1737, 0.0000, 0.1357, 0.0000, 0.1109, 0.0000, 0.0864, 0.0000, 0.1151,\n","         0.1326, 0.0362, 0.0000, 0.1985, 0.0000, 0.0113, 0.0000, 0.0415, 0.0000,\n","         0.0000, 0.0033, 0.2043, 0.0000, 0.0000, 0.0888, 0.0000, 0.1777, 0.1025,\n","         0.1200],\n","        [0.0880, 0.0000, 0.0610, 0.2329, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0623, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0173, 0.0342, 0.1109, 0.0649, 0.2213, 0.0000, 0.0540,\n","         0.1808, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0334, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2054, 0.0000, 0.0000, 0.0931, 0.0000, 0.1856, 0.1025,\n","         0.1327],\n","        [0.0430, 0.0000, 0.0453, 0.2225, 0.0000, 0.0309, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0000, 0.0588, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.0878, 0.0000,\n","         0.0000, 0.0934, 0.0000, 0.0342, 0.1109, 0.0562, 0.2213, 0.0000, 0.0540,\n","         0.1436, 0.0000, 0.1642, 0.0000, 0.1123, 0.0181, 0.0864, 0.0080, 0.0795,\n","         0.1446, 0.0000, 0.0000, 0.1530, 0.0000, 0.0113, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1915, 0.0000, 0.0000, 0.0000, 0.0000, 0.1856, 0.1025,\n","         0.1102],\n","        [0.0837, 0.0000, 0.0593, 0.2225, 0.0000, 0.0309, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0575, 0.0588, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.0878, 0.0000,\n","         0.0000, 0.0934, 0.0162, 0.0342, 0.1109, 0.0656, 0.2213, 0.0000, 0.0540,\n","         0.1737, 0.0000, 0.1642, 0.0000, 0.1123, 0.0181, 0.0864, 0.0080, 0.0896,\n","         0.1446, 0.0362, 0.0000, 0.1985, 0.0000, 0.0113, 0.0000, 0.0415, 0.0000,\n","         0.0000, 0.0033, 0.1915, 0.0000, 0.0000, 0.0888, 0.0000, 0.1856, 0.1025,\n","         0.1102]], grad_fn=<MaxBackward0>), tensor([[0.0381, 0.0000, 0.1111, 0.0000, 0.0585, 0.0887, 0.0000, 0.0000, 0.0606,\n","         0.0000, 0.0000, 0.1268, 0.0348, 0.0953, 0.0388, 0.1315, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1147, 0.0000, 0.0610, 0.0000, 0.0000, 0.1095,\n","         0.0000, 0.0567, 0.0998, 0.0000, 0.0058, 0.0894, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0891, 0.0290, 0.0272, 0.0381, 0.0842, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0459, 0.0148, 0.0000, 0.0000, 0.0000, 0.1222, 0.0406, 0.0187,\n","         0.1247, 0.0000, 0.0663, 0.0000, 0.0000, 0.0463, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1118, 0.0000, 0.0592, 0.0885, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1270, 0.0342, 0.0960, 0.0401, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1155, 0.0000, 0.0606, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0564, 0.0996, 0.0000, 0.0067, 0.0885, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0889, 0.0298, 0.0267, 0.0374, 0.0835, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1209, 0.0401, 0.0186,\n","         0.1249, 0.0000, 0.0660, 0.0000, 0.0000, 0.0445, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0379, 0.0000, 0.1112, 0.0000, 0.0587, 0.0885, 0.0000, 0.0000, 0.0607,\n","         0.0000, 0.0000, 0.1268, 0.0345, 0.0955, 0.0393, 0.1317, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1150, 0.0000, 0.0609, 0.0000, 0.0000, 0.1097,\n","         0.0000, 0.0565, 0.0997, 0.0000, 0.0061, 0.0891, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0889, 0.0293, 0.0270, 0.0378, 0.0837, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0149, 0.0000, 0.0000, 0.0000, 0.1217, 0.0404, 0.0186,\n","         0.1248, 0.0000, 0.0661, 0.0000, 0.0000, 0.0457, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0379, 0.0000, 0.1109, 0.0000, 0.0585, 0.0885, 0.0000, 0.0000, 0.0606,\n","         0.0000, 0.0000, 0.1266, 0.0346, 0.0952, 0.0390, 0.1316, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1151, 0.0000, 0.0611, 0.0000, 0.0000, 0.1096,\n","         0.0000, 0.0566, 0.0998, 0.0000, 0.0058, 0.0894, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0889, 0.0291, 0.0273, 0.0379, 0.0838, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0149, 0.0000, 0.0000, 0.0000, 0.1220, 0.0406, 0.0186,\n","         0.1247, 0.0000, 0.0661, 0.0000, 0.0000, 0.0463, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1109, 0.0000, 0.0585, 0.0884, 0.0000, 0.0000, 0.0606,\n","         0.0000, 0.0000, 0.1266, 0.0345, 0.0954, 0.0390, 0.1315, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1150, 0.0000, 0.0610, 0.0000, 0.0000, 0.1096,\n","         0.0000, 0.0566, 0.0997, 0.0000, 0.0059, 0.0892, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0888, 0.0292, 0.0271, 0.0378, 0.0834, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0149, 0.0000, 0.0000, 0.0000, 0.1218, 0.0405, 0.0186,\n","         0.1248, 0.0000, 0.0661, 0.0000, 0.0000, 0.0459, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1103, 0.0000, 0.0583, 0.0882, 0.0000, 0.0000, 0.0604,\n","         0.0000, 0.0000, 0.1264, 0.0344, 0.0952, 0.0388, 0.1314, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1150, 0.0000, 0.0611, 0.0000, 0.0000, 0.1095,\n","         0.0000, 0.0566, 0.0998, 0.0000, 0.0058, 0.0893, 0.0000, 0.0284, 0.0000,\n","         0.0000, 0.0886, 0.0291, 0.0273, 0.0379, 0.0830, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0148, 0.0000, 0.0000, 0.0000, 0.1218, 0.0406, 0.0186,\n","         0.1247, 0.0000, 0.0661, 0.0000, 0.0000, 0.0462, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1116, 0.0000, 0.0591, 0.0884, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1269, 0.0342, 0.0958, 0.0401, 0.1323, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1156, 0.0000, 0.0608, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0564, 0.0997, 0.0000, 0.0065, 0.0887, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0890, 0.0297, 0.0269, 0.0373, 0.0838, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0152, 0.0000, 0.0000, 0.0000, 0.1211, 0.0403, 0.0185,\n","         0.1247, 0.0000, 0.0660, 0.0000, 0.0000, 0.0449, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0381, 0.0000, 0.1120, 0.0000, 0.0589, 0.0887, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1272, 0.0345, 0.0958, 0.0398, 0.1319, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0833, 0.1149, 0.0000, 0.0605, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0565, 0.0995, 0.0000, 0.0066, 0.0886, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0891, 0.0298, 0.0267, 0.0378, 0.0839, 0.0000, 0.0518, 0.0000,\n","         0.0000, 0.0459, 0.0149, 0.0000, 0.0000, 0.0000, 0.1214, 0.0402, 0.0187,\n","         0.1252, 0.0000, 0.0662, 0.0000, 0.0000, 0.0448, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0353, 0.0000, 0.1059, 0.0000, 0.0564, 0.0870, 0.0000, 0.0000, 0.0587,\n","         0.0000, 0.0000, 0.1245, 0.0341, 0.0942, 0.0354, 0.1290, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0832, 0.1145, 0.0000, 0.0616, 0.0000, 0.0000, 0.1090,\n","         0.0000, 0.0570, 0.1000, 0.0000, 0.0046, 0.0905, 0.0000, 0.0282, 0.0000,\n","         0.0000, 0.0866, 0.0283, 0.0280, 0.0385, 0.0784, 0.0000, 0.0512, 0.0000,\n","         0.0000, 0.0456, 0.0142, 0.0000, 0.0000, 0.0000, 0.1222, 0.0409, 0.0185,\n","         0.1245, 0.0000, 0.0664, 0.0000, 0.0000, 0.0482, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1108, 0.0000, 0.0587, 0.0883, 0.0000, 0.0000, 0.0607,\n","         0.0000, 0.0000, 0.1265, 0.0343, 0.0954, 0.0393, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1154, 0.0000, 0.0611, 0.0000, 0.0000, 0.1097,\n","         0.0000, 0.0565, 0.0998, 0.0000, 0.0060, 0.0892, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0888, 0.0292, 0.0272, 0.0376, 0.0835, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0457, 0.0151, 0.0000, 0.0000, 0.0000, 0.1216, 0.0405, 0.0185,\n","         0.1246, 0.0000, 0.0660, 0.0000, 0.0000, 0.0459, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5156, 0.4844],\n","        [0.5170, 0.4830],\n","        [0.5185, 0.4815],\n","        [0.5177, 0.4823],\n","        [0.5163, 0.4837],\n","        [0.5162, 0.4838],\n","        [0.5173, 0.4827],\n","        [0.5187, 0.4813],\n","        [0.5160, 0.4840],\n","        [0.5187, 0.4813]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0810, 0.0000, 0.0580, 0.2335, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0489, 0.0468, 0.0043, 0.0891, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1293, 0.0000, 0.0460, 0.0000, 0.0000, 0.0847, 0.0000,\n","         0.0000, 0.0712, 0.0129, 0.0240, 0.0971, 0.0655, 0.2051, 0.0000, 0.0403,\n","         0.1664, 0.0000, 0.1373, 0.0000, 0.1124, 0.0000, 0.0773, 0.0000, 0.1177,\n","         0.1333, 0.0347, 0.0000, 0.1936, 0.0000, 0.0000, 0.0000, 0.0390, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0828, 0.0000, 0.1710, 0.0641,\n","         0.1221],\n","        [0.0818, 0.0000, 0.0572, 0.2327, 0.0000, 0.0314, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0455, 0.0588, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.0878, 0.0000,\n","         0.0000, 0.0934, 0.0115, 0.0342, 0.1109, 0.0634, 0.2213, 0.0000, 0.0540,\n","         0.1651, 0.0000, 0.1642, 0.0000, 0.1140, 0.0181, 0.0864, 0.0080, 0.1188,\n","         0.1446, 0.0297, 0.0000, 0.1923, 0.0000, 0.0113, 0.0000, 0.0371, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0821, 0.0000, 0.1856, 0.1025,\n","         0.1234],\n","        [0.0809, 0.0000, 0.0589, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0506, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1298, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0134, 0.0250, 0.1109, 0.0659, 0.1988, 0.0000, 0.0275,\n","         0.1667, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0354, 0.0000, 0.1937, 0.0000, 0.0113, 0.0000, 0.0395, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0839, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0809, 0.0000, 0.0589, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0506, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1298, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0134, 0.0250, 0.1109, 0.0659, 0.1988, 0.0000, 0.0275,\n","         0.1667, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0354, 0.0000, 0.1937, 0.0000, 0.0113, 0.0000, 0.0395, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0839, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0908, 0.0000, 0.0606, 0.2336, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0652, 0.0469, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1409, 0.0000, 0.0636, 0.0000, 0.0198, 0.0847, 0.0000,\n","         0.0000, 0.0712, 0.0167, 0.0323, 0.1109, 0.0649, 0.2176, 0.0000, 0.0404,\n","         0.1855, 0.0000, 0.1373, 0.0000, 0.1125, 0.0000, 0.0864, 0.0000, 0.1178,\n","         0.1333, 0.0319, 0.0000, 0.2077, 0.0000, 0.0113, 0.0000, 0.0430, 0.0000,\n","         0.0000, 0.0080, 0.2013, 0.0000, 0.0000, 0.0952, 0.0000, 0.1713, 0.1025,\n","         0.1221],\n","        [0.0809, 0.0000, 0.0586, 0.2334, 0.0000, 0.0314, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0506, 0.0588, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.0878, 0.0000,\n","         0.0000, 0.0934, 0.0138, 0.0342, 0.1109, 0.0750, 0.2213, 0.0000, 0.0540,\n","         0.1667, 0.0000, 0.1642, 0.0000, 0.1125, 0.0181, 0.0864, 0.0080, 0.1178,\n","         0.1446, 0.0349, 0.0000, 0.2106, 0.0000, 0.0113, 0.0000, 0.0395, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0839, 0.0000, 0.1856, 0.1025,\n","         0.1221],\n","        [0.0810, 0.0000, 0.0588, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0506, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1298, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0133, 0.0250, 0.1109, 0.0658, 0.1988, 0.0000, 0.0275,\n","         0.1667, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0352, 0.0000, 0.1937, 0.0000, 0.0113, 0.0000, 0.0395, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0839, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0907, 0.0000, 0.0607, 0.1959, 0.0000, 0.0309, 0.0000, 0.1006, 0.0431,\n","         0.0000, 0.0000, 0.0659, 0.0266, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1410, 0.0000, 0.0636, 0.0000, 0.0198, 0.0670, 0.0000,\n","         0.0000, 0.0291, 0.0169, 0.0327, 0.1109, 0.0656, 0.2182, 0.0000, 0.0227,\n","         0.1857, 0.0000, 0.1232, 0.0000, 0.1015, 0.0000, 0.0864, 0.0000, 0.1001,\n","         0.0562, 0.0362, 0.0000, 0.2078, 0.0000, 0.0113, 0.0000, 0.0433, 0.0000,\n","         0.0000, 0.0083, 0.1671, 0.0000, 0.0000, 0.0956, 0.0000, 0.1531, 0.1025,\n","         0.0934],\n","        [0.0847, 0.0000, 0.0550, 0.2542, 0.0000, 0.0312, 0.0000, 0.1323, 0.0911,\n","         0.0000, 0.0000, 0.0421, 0.0461, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1396, 0.0000, 0.0636, 0.0000, 0.0198, 0.0841, 0.0000,\n","         0.0000, 0.0714, 0.0057, 0.0344, 0.1109, 0.0899, 0.2381, 0.0000, 0.0714,\n","         0.1896, 0.0000, 0.1365, 0.0000, 0.1117, 0.0175, 0.0864, 0.0018, 0.1168,\n","         0.1332, 0.0259, 0.0000, 0.2428, 0.0000, 0.0113, 0.0000, 0.0339, 0.0000,\n","         0.0000, 0.0000, 0.2023, 0.0000, 0.0000, 0.0879, 0.0000, 0.2131, 0.1025,\n","         0.1216],\n","        [0.0831, 0.0000, 0.0555, 0.2343, 0.0000, 0.0422, 0.0000, 0.1272, 0.0929,\n","         0.0000, 0.0000, 0.0455, 0.0709, 0.0541, 0.1081, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1448, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0934, 0.0155, 0.0342, 0.1109, 0.0743, 0.2213, 0.0000, 0.0540,\n","         0.1705, 0.0000, 0.1642, 0.0000, 0.1194, 0.0181, 0.0864, 0.0080, 0.1267,\n","         0.1469, 0.0298, 0.0000, 0.2130, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0880, 0.0000, 0.1856, 0.1025,\n","         0.1327]], grad_fn=<MaxBackward0>), tensor([[0.0372, 0.0000, 0.1118, 0.0000, 0.0596, 0.0889, 0.0000, 0.0000, 0.0619,\n","         0.0000, 0.0000, 0.1269, 0.0339, 0.0964, 0.0409, 0.1327, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1162, 0.0000, 0.0605, 0.0000, 0.0000, 0.1107,\n","         0.0000, 0.0562, 0.0997, 0.0000, 0.0071, 0.0884, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0894, 0.0302, 0.0268, 0.0367, 0.0838, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0157, 0.0000, 0.0000, 0.0000, 0.1202, 0.0399, 0.0182,\n","         0.1251, 0.0000, 0.0658, 0.0000, 0.0000, 0.0438, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0376, 0.0000, 0.1120, 0.0000, 0.0594, 0.0892, 0.0000, 0.0000, 0.0618,\n","         0.0000, 0.0000, 0.1271, 0.0342, 0.0963, 0.0406, 0.1323, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0837, 0.1156, 0.0000, 0.0603, 0.0000, 0.0000, 0.1106,\n","         0.0000, 0.0563, 0.0997, 0.0000, 0.0071, 0.0885, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0895, 0.0302, 0.0267, 0.0371, 0.0840, 0.0000, 0.0519, 0.0000,\n","         0.0000, 0.0458, 0.0155, 0.0000, 0.0000, 0.0000, 0.1204, 0.0398, 0.0183,\n","         0.1256, 0.0000, 0.0659, 0.0000, 0.0000, 0.0439, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1114, 0.0000, 0.0593, 0.0889, 0.0000, 0.0000, 0.0615,\n","         0.0000, 0.0000, 0.1267, 0.0341, 0.0962, 0.0403, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1158, 0.0000, 0.0607, 0.0000, 0.0000, 0.1105,\n","         0.0000, 0.0563, 0.0997, 0.0000, 0.0067, 0.0888, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0892, 0.0299, 0.0269, 0.0371, 0.0836, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0156, 0.0000, 0.0000, 0.0000, 0.1205, 0.0400, 0.0183,\n","         0.1251, 0.0000, 0.0658, 0.0000, 0.0000, 0.0445, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1114, 0.0000, 0.0593, 0.0889, 0.0000, 0.0000, 0.0615,\n","         0.0000, 0.0000, 0.1267, 0.0341, 0.0962, 0.0403, 0.1322, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1158, 0.0000, 0.0607, 0.0000, 0.0000, 0.1105,\n","         0.0000, 0.0563, 0.0997, 0.0000, 0.0067, 0.0888, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0892, 0.0299, 0.0269, 0.0371, 0.0836, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0156, 0.0000, 0.0000, 0.0000, 0.1205, 0.0400, 0.0183,\n","         0.1251, 0.0000, 0.0658, 0.0000, 0.0000, 0.0445, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0375, 0.0000, 0.1112, 0.0000, 0.0591, 0.0889, 0.0000, 0.0000, 0.0614,\n","         0.0000, 0.0000, 0.1266, 0.0342, 0.0959, 0.0401, 0.1321, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1157, 0.0000, 0.0608, 0.0000, 0.0000, 0.1103,\n","         0.0000, 0.0564, 0.0999, 0.0000, 0.0064, 0.0890, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0893, 0.0297, 0.0271, 0.0372, 0.0839, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0155, 0.0000, 0.0000, 0.0000, 0.1208, 0.0402, 0.0183,\n","         0.1251, 0.0000, 0.0659, 0.0000, 0.0000, 0.0450, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0371, 0.0000, 0.1114, 0.0000, 0.0594, 0.0888, 0.0000, 0.0000, 0.0617,\n","         0.0000, 0.0000, 0.1267, 0.0339, 0.0962, 0.0407, 0.1325, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1162, 0.0000, 0.0607, 0.0000, 0.0000, 0.1106,\n","         0.0000, 0.0562, 0.0999, 0.0000, 0.0068, 0.0887, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0892, 0.0300, 0.0270, 0.0368, 0.0836, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0456, 0.0157, 0.0000, 0.0000, 0.0000, 0.1203, 0.0400, 0.0182,\n","         0.1250, 0.0000, 0.0658, 0.0000, 0.0000, 0.0443, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1114, 0.0000, 0.0593, 0.0889, 0.0000, 0.0000, 0.0615,\n","         0.0000, 0.0000, 0.1267, 0.0340, 0.0961, 0.0403, 0.1323, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1159, 0.0000, 0.0608, 0.0000, 0.0000, 0.1105,\n","         0.0000, 0.0563, 0.0998, 0.0000, 0.0067, 0.0888, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0893, 0.0298, 0.0270, 0.0370, 0.0837, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0457, 0.0156, 0.0000, 0.0000, 0.0000, 0.1206, 0.0401, 0.0183,\n","         0.1250, 0.0000, 0.0659, 0.0000, 0.0000, 0.0445, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0374, 0.0000, 0.1101, 0.0000, 0.0585, 0.0888, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1261, 0.0344, 0.0953, 0.0390, 0.1315, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0840, 0.1155, 0.0000, 0.0614, 0.0000, 0.0000, 0.1098,\n","         0.0000, 0.0565, 0.1001, 0.0000, 0.0056, 0.0899, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0891, 0.0290, 0.0277, 0.0375, 0.0837, 0.0000, 0.0513, 0.0000,\n","         0.0000, 0.0457, 0.0154, 0.0000, 0.0000, 0.0000, 0.1215, 0.0406, 0.0183,\n","         0.1247, 0.0000, 0.0660, 0.0000, 0.0000, 0.0466, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0372, 0.0000, 0.1102, 0.0000, 0.0585, 0.0887, 0.0000, 0.0000, 0.0610,\n","         0.0000, 0.0000, 0.1261, 0.0342, 0.0955, 0.0392, 0.1315, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0839, 0.1154, 0.0000, 0.0611, 0.0000, 0.0000, 0.1099,\n","         0.0000, 0.0564, 0.1001, 0.0000, 0.0059, 0.0896, 0.0000, 0.0282, 0.0000,\n","         0.0000, 0.0889, 0.0293, 0.0274, 0.0374, 0.0831, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0457, 0.0152, 0.0000, 0.0000, 0.0000, 0.1212, 0.0404, 0.0183,\n","         0.1250, 0.0000, 0.0660, 0.0000, 0.0000, 0.0460, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0372, 0.0000, 0.1106, 0.0000, 0.0588, 0.0887, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1264, 0.0341, 0.0958, 0.0396, 0.1317, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0838, 0.1153, 0.0000, 0.0607, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0563, 0.0999, 0.0000, 0.0064, 0.0891, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0889, 0.0297, 0.0270, 0.0374, 0.0830, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0457, 0.0153, 0.0000, 0.0000, 0.0000, 0.1208, 0.0401, 0.0183,\n","         0.1254, 0.0000, 0.0659, 0.0000, 0.0000, 0.0451, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5157, 0.4843],\n","        [0.5178, 0.4822],\n","        [0.5173, 0.4827],\n","        [0.5173, 0.4827],\n","        [0.5177, 0.4823],\n","        [0.5180, 0.4820],\n","        [0.5173, 0.4827],\n","        [0.5157, 0.4843],\n","        [0.5172, 0.4828],\n","        [0.5182, 0.4818]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[7.6593e-02, 0.0000e+00, 5.1483e-02, 2.3427e-01, 0.0000e+00, 3.1419e-02,\n","         0.0000e+00, 1.2464e-01, 8.5993e-02, 0.0000e+00, 0.0000e+00, 3.2841e-02,\n","         4.6865e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.1923e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4745e-02, 0.0000e+00, 0.0000e+00, 7.1444e-02, 6.3950e-03,\n","         2.2124e-02, 1.1090e-01, 6.2452e-02, 2.0610e-01, 0.0000e+00, 4.0319e-02,\n","         1.5410e-01, 0.0000e+00, 1.3733e-01, 0.0000e+00, 1.1252e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1777e-01, 1.3348e-01, 2.3028e-02, 0.0000e+00,\n","         1.8735e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.0450e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0244e-01, 0.0000e+00, 0.0000e+00, 7.4685e-02,\n","         0.0000e+00, 1.7255e-01, 1.0255e-01, 1.2212e-01],\n","        [7.2312e-02, 0.0000e+00, 5.1564e-02, 2.3427e-01, 0.0000e+00, 3.1160e-02,\n","         0.0000e+00, 1.2464e-01, 8.5993e-02, 0.0000e+00, 0.0000e+00, 2.1349e-02,\n","         4.6386e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.1527e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.4205e-02, 0.0000e+00, 0.0000e+00, 7.1444e-02, 0.0000e+00,\n","         2.1947e-02, 1.1090e-01, 6.0250e-02, 2.0610e-01, 0.0000e+00, 3.9863e-02,\n","         1.5250e-01, 0.0000e+00, 1.3666e-01, 0.0000e+00, 1.1208e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.1717e-01, 1.3348e-01, 1.4241e-02, 0.0000e+00,\n","         1.8397e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 2.8939e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0244e-01, 0.0000e+00, 0.0000e+00, 6.3729e-02,\n","         0.0000e+00, 1.7255e-01, 1.0255e-01, 1.2164e-01],\n","        [8.1347e-02, 0.0000e+00, 5.8027e-02, 2.3286e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2372e-01, 9.2130e-02, 0.0000e+00, 0.0000e+00, 4.7357e-02,\n","         7.0890e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2970e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.1241e-01, 0.0000e+00, 0.0000e+00, 8.7246e-02, 1.1059e-02,\n","         2.3676e-02, 1.1090e-01, 6.5002e-02, 2.0335e-01, 0.0000e+00, 3.9895e-02,\n","         1.6553e-01, 0.0000e+00, 1.5546e-01, 0.0000e+00, 1.1940e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.2671e-01, 1.4689e-01, 3.2762e-02, 0.0000e+00,\n","         1.9247e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.7847e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0541e-01, 0.0000e+00, 0.0000e+00, 8.1874e-02,\n","         0.0000e+00, 1.6932e-01, 1.0255e-01, 1.3274e-01],\n","        [9.0825e-02, 0.0000e+00, 6.7406e-02, 2.3433e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.3013e-01, 9.2130e-02, 0.0000e+00, 0.0000e+00, 3.8941e-02,\n","         7.0890e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.3343e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.1241e-01, 0.0000e+00, 0.0000e+00, 8.7246e-02, 9.4487e-03,\n","         2.5910e-02, 1.1090e-01, 8.1445e-02, 2.0646e-01, 0.0000e+00, 4.6080e-02,\n","         1.9965e-01, 0.0000e+00, 1.5546e-01, 0.0000e+00, 1.1940e-01, 1.5213e-02,\n","         8.6518e-02, 0.0000e+00, 1.2671e-01, 1.4689e-01, 2.6841e-02, 0.0000e+00,\n","         2.1837e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.4146e-02, 0.0000e+00,\n","         0.0000e+00, 2.3961e-03, 2.0689e-01, 0.0000e+00, 0.0000e+00, 8.1807e-02,\n","         0.0000e+00, 1.7289e-01, 1.0255e-01, 1.3274e-01],\n","        [8.7532e-02, 0.0000e+00, 6.4070e-02, 2.3433e-01, 0.0000e+00, 3.1647e-02,\n","         0.0000e+00, 1.3042e-01, 8.8262e-02, 0.0000e+00, 0.0000e+00, 3.3339e-02,\n","         5.0592e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.2756e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.5120e-02, 0.0000e+00, 0.0000e+00, 7.2045e-02, 6.3798e-03,\n","         2.2282e-02, 1.1090e-01, 7.9551e-02, 2.0646e-01, 0.0000e+00, 4.8835e-02,\n","         1.9549e-01, 0.0000e+00, 1.4252e-01, 0.0000e+00, 1.1172e-01, 1.6175e-02,\n","         8.7050e-02, 0.0000e+00, 1.2285e-01, 1.3678e-01, 2.5938e-02, 0.0000e+00,\n","         2.1072e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 3.3867e-02, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 2.0715e-01, 0.0000e+00, 0.0000e+00, 7.0159e-02,\n","         0.0000e+00, 1.7289e-01, 1.0255e-01, 1.2396e-01],\n","        [9.0142e-02, 0.0000e+00, 6.0633e-02, 1.9471e-01, 0.0000e+00, 3.0867e-02,\n","         0.0000e+00, 9.8920e-02, 4.2221e-02, 0.0000e+00, 0.0000e+00, 6.4248e-02,\n","         2.6636e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         8.2992e-05, 0.0000e+00, 1.4073e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 6.6979e-02, 0.0000e+00, 0.0000e+00, 2.9078e-02, 1.5236e-02,\n","         3.2895e-02, 1.1090e-01, 6.5646e-02, 2.1738e-01, 0.0000e+00, 2.2907e-02,\n","         1.8486e-01, 0.0000e+00, 1.2322e-01, 0.0000e+00, 1.0148e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.0133e-01, 5.5863e-02, 3.5698e-02, 0.0000e+00,\n","         2.0633e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.2382e-02, 0.0000e+00,\n","         0.0000e+00, 8.0912e-03, 1.6586e-01, 0.0000e+00, 0.0000e+00, 9.4224e-02,\n","         0.0000e+00, 1.5117e-01, 1.0255e-01, 9.3367e-02],\n","        [8.8382e-02, 0.0000e+00, 5.0301e-02, 2.3243e-01, 0.0000e+00, 3.1419e-02,\n","         0.0000e+00, 1.2716e-01, 9.2928e-02, 0.0000e+00, 0.0000e+00, 3.1465e-02,\n","         5.8754e-02, 5.4064e-02, 1.0809e-01, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.4477e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.7813e-02, 0.0000e+00, 0.0000e+00, 9.3389e-02, 0.0000e+00,\n","         3.4154e-02, 1.1090e-01, 5.8140e-02, 2.2128e-01, 0.0000e+00, 5.4012e-02,\n","         1.7087e-01, 0.0000e+00, 1.6419e-01, 0.0000e+00, 1.1394e-01, 1.8134e-02,\n","         8.6433e-02, 7.9503e-03, 1.1865e-01, 1.4456e-01, 1.1624e-02, 0.0000e+00,\n","         1.9181e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 2.7317e-02, 0.0000e+00,\n","         0.0000e+00, 1.2552e-03, 2.0120e-01, 0.0000e+00, 0.0000e+00, 8.0992e-02,\n","         0.0000e+00, 1.8564e-01, 1.0255e-01, 1.2335e-01],\n","        [8.8116e-02, 0.0000e+00, 6.4735e-02, 2.3783e-01, 0.0000e+00, 3.0867e-02,\n","         0.0000e+00, 1.4483e-01, 9.2928e-02, 0.0000e+00, 0.0000e+00, 6.2273e-02,\n","         7.9313e-02, 5.4064e-02, 1.0809e-01, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.4477e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 8.7813e-02, 0.0000e+00, 0.0000e+00, 9.3389e-02, 1.7344e-02,\n","         3.4154e-02, 1.1090e-01, 9.0703e-02, 2.2128e-01, 0.0000e+00, 5.4012e-02,\n","         1.9871e-01, 0.0000e+00, 1.7620e-01, 0.0000e+00, 1.1347e-01, 4.5663e-02,\n","         1.2013e-01, 7.9503e-03, 1.3941e-01, 1.4456e-01, 3.3350e-02, 0.0000e+00,\n","         2.0386e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.2084e-02, 0.0000e+00,\n","         0.0000e+00, 5.2672e-03, 2.1403e-01, 0.0000e+00, 0.0000e+00, 9.3058e-02,\n","         0.0000e+00, 1.8564e-01, 1.0255e-01, 1.2526e-01],\n","        [8.7489e-02, 0.0000e+00, 5.8887e-02, 2.3346e-01, 0.0000e+00, 4.2233e-02,\n","         0.0000e+00, 1.2392e-01, 9.2130e-02, 0.0000e+00, 0.0000e+00, 5.6418e-02,\n","         7.0890e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 1.3502e-01, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 1.1241e-01, 0.0000e+00, 0.0000e+00, 8.7246e-02, 1.3931e-02,\n","         2.7816e-02, 1.1090e-01, 6.4965e-02, 2.0823e-01, 0.0000e+00, 4.0317e-02,\n","         1.7797e-01, 0.0000e+00, 1.5546e-01, 0.0000e+00, 1.1940e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 1.2671e-01, 1.4689e-01, 3.3589e-02, 0.0000e+00,\n","         2.0183e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 4.0818e-02, 0.0000e+00,\n","         0.0000e+00, 4.0001e-03, 2.0541e-01, 0.0000e+00, 0.0000e+00, 8.9811e-02,\n","         0.0000e+00, 1.7074e-01, 1.0255e-01, 1.3274e-01],\n","        [3.2036e-02, 0.0000e+00, 4.5298e-02, 9.4956e-02, 0.0000e+00, 3.0867e-02,\n","         0.0000e+00, 7.8121e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         2.6636e-02, 5.4064e-02, 9.9631e-02, 0.0000e+00, 0.0000e+00, 6.6524e-02,\n","         0.0000e+00, 0.0000e+00, 8.1202e-02, 0.0000e+00, 6.3583e-02, 0.0000e+00,\n","         1.9830e-02, 6.6979e-02, 0.0000e+00, 0.0000e+00, 2.9078e-02, 0.0000e+00,\n","         0.0000e+00, 1.1090e-01, 5.2723e-02, 7.4077e-02, 0.0000e+00, 2.4479e-03,\n","         6.4332e-02, 0.0000e+00, 1.2322e-01, 0.0000e+00, 1.0148e-01, 0.0000e+00,\n","         8.6433e-02, 0.0000e+00, 2.9859e-02, 5.3649e-02, 0.0000e+00, 0.0000e+00,\n","         1.0061e-01, 0.0000e+00, 1.1301e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 1.1500e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 1.4643e-03, 1.0255e-01, 9.3367e-02]],\n","       grad_fn=<MaxBackward0>), tensor([[3.7334e-02, 0.0000e+00, 1.1164e-01, 0.0000e+00, 5.9410e-02, 8.9320e-02,\n","         0.0000e+00, 0.0000e+00, 6.1910e-02, 0.0000e+00, 0.0000e+00, 1.2687e-01,\n","         3.4067e-02, 9.6344e-02, 4.0534e-02, 1.3224e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3912e-02, 1.1576e-01, 0.0000e+00, 6.0435e-02,\n","         0.0000e+00, 0.0000e+00, 1.1069e-01, 0.0000e+00, 5.6281e-02, 9.9776e-02,\n","         0.0000e+00, 7.0215e-03, 8.8635e-02, 0.0000e+00, 2.8357e-02, 0.0000e+00,\n","         0.0000e+00, 8.9556e-02, 3.0198e-02, 2.6786e-02, 3.6982e-02, 8.3833e-02,\n","         0.0000e+00, 5.1827e-02, 0.0000e+00, 0.0000e+00, 4.5769e-02, 1.5675e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2022e-01, 3.9757e-02, 1.8174e-02,\n","         1.2563e-01, 0.0000e+00, 6.5844e-02, 0.0000e+00, 0.0000e+00, 4.3983e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7326e-02, 0.0000e+00, 1.1006e-01, 0.0000e+00, 5.8430e-02, 8.9081e-02,\n","         0.0000e+00, 0.0000e+00, 6.1185e-02, 0.0000e+00, 0.0000e+00, 1.2608e-01,\n","         3.4350e-02, 9.5498e-02, 3.8985e-02, 1.3132e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4031e-02, 1.1523e-01, 0.0000e+00, 6.1156e-02,\n","         0.0000e+00, 0.0000e+00, 1.0990e-01, 0.0000e+00, 5.6457e-02, 1.0009e-01,\n","         0.0000e+00, 5.7844e-03, 8.9855e-02, 0.0000e+00, 2.7936e-02, 0.0000e+00,\n","         0.0000e+00, 8.9185e-02, 2.9158e-02, 2.7499e-02, 3.7474e-02, 8.3449e-02,\n","         0.0000e+00, 5.1510e-02, 0.0000e+00, 0.0000e+00, 4.5760e-02, 1.5337e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2120e-01, 4.0482e-02, 1.8203e-02,\n","         1.2523e-01, 0.0000e+00, 6.6013e-02, 0.0000e+00, 0.0000e+00, 4.6263e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7283e-02, 0.0000e+00, 1.1115e-01, 0.0000e+00, 5.9203e-02, 8.9185e-02,\n","         0.0000e+00, 0.0000e+00, 6.1674e-02, 0.0000e+00, 0.0000e+00, 1.2660e-01,\n","         3.4099e-02, 9.6165e-02, 4.0190e-02, 1.3204e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.3990e-02, 1.1572e-01, 0.0000e+00, 6.0687e-02,\n","         0.0000e+00, 0.0000e+00, 1.1053e-01, 0.0000e+00, 5.6297e-02, 9.9840e-02,\n","         0.0000e+00, 6.6644e-03, 8.8957e-02, 0.0000e+00, 2.8340e-02, 0.0000e+00,\n","         0.0000e+00, 8.9423e-02, 2.9896e-02, 2.6961e-02, 3.7089e-02, 8.3634e-02,\n","         0.0000e+00, 5.1702e-02, 0.0000e+00, 0.0000e+00, 4.5738e-02, 1.5658e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2043e-01, 3.9971e-02, 1.8220e-02,\n","         1.2543e-01, 0.0000e+00, 6.5840e-02, 0.0000e+00, 0.0000e+00, 4.4573e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.6926e-02, 0.0000e+00, 1.1093e-01, 0.0000e+00, 5.9226e-02, 8.8939e-02,\n","         0.0000e+00, 0.0000e+00, 6.1655e-02, 0.0000e+00, 0.0000e+00, 1.2641e-01,\n","         3.3802e-02, 9.6173e-02, 4.0340e-02, 1.3211e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4044e-02, 1.1599e-01, 0.0000e+00, 6.0637e-02,\n","         0.0000e+00, 0.0000e+00, 1.1066e-01, 0.0000e+00, 5.6107e-02, 9.9947e-02,\n","         0.0000e+00, 6.8453e-03, 8.8840e-02, 0.0000e+00, 2.8452e-02, 0.0000e+00,\n","         0.0000e+00, 8.9177e-02, 2.9973e-02, 2.6985e-02, 3.6806e-02, 8.3113e-02,\n","         0.0000e+00, 5.1572e-02, 0.0000e+00, 0.0000e+00, 4.5696e-02, 1.5691e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2014e-01, 3.9928e-02, 1.8095e-02,\n","         1.2545e-01, 0.0000e+00, 6.5746e-02, 0.0000e+00, 0.0000e+00, 4.4349e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.6833e-02, 0.0000e+00, 1.1088e-01, 0.0000e+00, 5.9187e-02, 8.8913e-02,\n","         0.0000e+00, 0.0000e+00, 6.1648e-02, 0.0000e+00, 0.0000e+00, 1.2639e-01,\n","         3.3740e-02, 9.6137e-02, 4.0323e-02, 1.3210e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4041e-02, 1.1599e-01, 0.0000e+00, 6.0579e-02,\n","         0.0000e+00, 0.0000e+00, 1.1068e-01, 0.0000e+00, 5.6045e-02, 1.0000e-01,\n","         0.0000e+00, 6.9420e-03, 8.8813e-02, 0.0000e+00, 2.8435e-02, 0.0000e+00,\n","         0.0000e+00, 8.9128e-02, 3.0001e-02, 2.7009e-02, 3.6744e-02, 8.3018e-02,\n","         0.0000e+00, 5.1557e-02, 0.0000e+00, 0.0000e+00, 4.5692e-02, 1.5652e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2012e-01, 3.9894e-02, 1.8025e-02,\n","         1.2552e-01, 0.0000e+00, 6.5733e-02, 0.0000e+00, 0.0000e+00, 4.4305e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7290e-02, 0.0000e+00, 1.1014e-01, 0.0000e+00, 5.8665e-02, 8.9047e-02,\n","         0.0000e+00, 0.0000e+00, 6.1291e-02, 0.0000e+00, 0.0000e+00, 1.2600e-01,\n","         3.4239e-02, 9.5462e-02, 3.9348e-02, 1.3169e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4196e-02, 1.1575e-01, 0.0000e+00, 6.1432e-02,\n","         0.0000e+00, 0.0000e+00, 1.0998e-01, 0.0000e+00, 5.6395e-02, 1.0019e-01,\n","         0.0000e+00, 5.6874e-03, 8.9982e-02, 0.0000e+00, 2.8248e-02, 0.0000e+00,\n","         0.0000e+00, 8.9305e-02, 2.9059e-02, 2.7696e-02, 3.7212e-02, 8.3901e-02,\n","         0.0000e+00, 5.1323e-02, 0.0000e+00, 0.0000e+00, 4.5639e-02, 1.5603e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2117e-01, 4.0612e-02, 1.8147e-02,\n","         1.2478e-01, 0.0000e+00, 6.5927e-02, 0.0000e+00, 0.0000e+00, 4.6434e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7851e-02, 0.0000e+00, 1.1187e-01, 0.0000e+00, 5.9317e-02, 8.9666e-02,\n","         0.0000e+00, 0.0000e+00, 6.1831e-02, 0.0000e+00, 0.0000e+00, 1.2697e-01,\n","         3.4432e-02, 9.6086e-02, 4.0125e-02, 1.3213e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4028e-02, 1.1550e-01, 0.0000e+00, 6.0741e-02,\n","         0.0000e+00, 0.0000e+00, 1.1039e-01, 0.0000e+00, 5.6397e-02, 9.9880e-02,\n","         0.0000e+00, 6.6147e-03, 8.9187e-02, 0.0000e+00, 2.8264e-02, 0.0000e+00,\n","         0.0000e+00, 9.0016e-02, 2.9758e-02, 2.7079e-02, 3.7211e-02, 8.4997e-02,\n","         0.0000e+00, 5.1824e-02, 0.0000e+00, 0.0000e+00, 4.5763e-02, 1.5622e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2091e-01, 4.0039e-02, 1.8222e-02,\n","         1.2537e-01, 0.0000e+00, 6.5991e-02, 0.0000e+00, 0.0000e+00, 4.4873e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.6817e-02, 0.0000e+00, 1.0962e-01, 0.0000e+00, 5.8340e-02, 8.8716e-02,\n","         0.0000e+00, 0.0000e+00, 6.1061e-02, 0.0000e+00, 0.0000e+00, 1.2584e-01,\n","         3.3956e-02, 9.5539e-02, 3.9019e-02, 1.3125e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4042e-02, 1.1539e-01, 0.0000e+00, 6.1041e-02,\n","         0.0000e+00, 0.0000e+00, 1.1011e-01, 0.0000e+00, 5.6186e-02, 1.0017e-01,\n","         0.0000e+00, 6.0252e-03, 8.9685e-02, 0.0000e+00, 2.8043e-02, 0.0000e+00,\n","         0.0000e+00, 8.8720e-02, 2.9295e-02, 2.7477e-02, 3.7226e-02, 8.2436e-02,\n","         0.0000e+00, 5.1323e-02, 0.0000e+00, 0.0000e+00, 4.5713e-02, 1.5321e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2080e-01, 4.0387e-02, 1.8068e-02,\n","         1.2539e-01, 0.0000e+00, 6.5864e-02, 0.0000e+00, 0.0000e+00, 4.5929e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [3.7240e-02, 0.0000e+00, 1.1102e-01, 0.0000e+00, 5.9212e-02, 8.9129e-02,\n","         0.0000e+00, 0.0000e+00, 6.1642e-02, 0.0000e+00, 0.0000e+00, 1.2648e-01,\n","         3.4057e-02, 9.6089e-02, 4.0198e-02, 1.3211e-01, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 8.4070e-02, 1.1589e-01, 0.0000e+00, 6.0860e-02,\n","         0.0000e+00, 0.0000e+00, 1.1049e-01, 0.0000e+00, 5.6281e-02, 9.9911e-02,\n","         0.0000e+00, 6.5131e-03, 8.9106e-02, 0.0000e+00, 2.8426e-02, 0.0000e+00,\n","         0.0000e+00, 8.9423e-02, 2.9768e-02, 2.7094e-02, 3.7015e-02, 8.3731e-02,\n","         0.0000e+00, 5.1600e-02, 0.0000e+00, 0.0000e+00, 4.5691e-02, 1.5734e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2049e-01, 4.0085e-02, 1.8197e-02,\n","         1.2521e-01, 0.0000e+00, 6.5812e-02, 0.0000e+00, 0.0000e+00, 4.4828e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","        [0.0000e+00, 1.2434e-04, 2.1180e-02, 0.0000e+00, 2.9298e-02, 4.5940e-02,\n","         0.0000e+00, 0.0000e+00, 2.6953e-02, 0.0000e+00, 0.0000e+00, 8.6390e-02,\n","         8.3276e-03, 1.0871e-01, 0.0000e+00, 9.2434e-02, 0.0000e+00, 0.0000e+00,\n","         0.0000e+00, 0.0000e+00, 7.3556e-02, 1.2467e-01, 0.0000e+00, 6.6447e-02,\n","         0.0000e+00, 0.0000e+00, 1.1208e-01, 0.0000e+00, 9.2472e-02, 1.1002e-01,\n","         0.0000e+00, 0.0000e+00, 1.2243e-01, 0.0000e+00, 3.3294e-02, 0.0000e+00,\n","         0.0000e+00, 3.2541e-02, 3.3098e-02, 5.2043e-02, 5.1355e-02, 0.0000e+00,\n","         0.0000e+00, 1.0478e-01, 0.0000e+00, 0.0000e+00, 6.7165e-02, 3.7826e-03,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0235e-01, 4.9874e-02, 2.9341e-02,\n","         1.2487e-01, 0.0000e+00, 8.3353e-02, 0.0000e+00, 0.0000e+00, 7.3997e-02,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n","       grad_fn=<MaxBackward0>)], tensor([[0.5161, 0.4839],\n","        [0.5157, 0.4843],\n","        [0.5174, 0.4826],\n","        [0.5167, 0.4833],\n","        [0.5162, 0.4838],\n","        [0.5154, 0.4846],\n","        [0.5169, 0.4831],\n","        [0.5196, 0.4804],\n","        [0.5180, 0.4820],\n","        [0.5107, 0.4893]], grad_fn=<SoftmaxBackward0>))\n","([tensor([[0.0835, 0.0000, 0.0453, 0.2323, 0.0000, 0.0314, 0.0000, 0.1234, 0.0840,\n","         0.0000, 0.0000, 0.0047, 0.0481, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1108, 0.0000, 0.0636, 0.0000, 0.0198, 0.0862, 0.0000,\n","         0.0000, 0.0714, 0.0000, 0.0207, 0.1109, 0.0542, 0.2024, 0.0000, 0.0396,\n","         0.1578, 0.0000, 0.1386, 0.0000, 0.1140, 0.0000, 0.0864, 0.0000, 0.1186,\n","         0.1348, 0.0046, 0.0000, 0.1811, 0.0000, 0.0113, 0.0000, 0.0174, 0.0000,\n","         0.0000, 0.0000, 0.2013, 0.0000, 0.0000, 0.0707, 0.0000, 0.1682, 0.1025,\n","         0.1234],\n","        [0.0880, 0.0000, 0.0610, 0.2324, 0.0000, 0.0314, 0.0000, 0.1233, 0.0839,\n","         0.0000, 0.0000, 0.0623, 0.0479, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1384, 0.0000, 0.0636, 0.0000, 0.0198, 0.0862, 0.0000,\n","         0.0000, 0.0715, 0.0173, 0.0303, 0.1109, 0.0649, 0.2127, 0.0000, 0.0394,\n","         0.1808, 0.0000, 0.1384, 0.0000, 0.1139, 0.0000, 0.0864, 0.0000, 0.1186,\n","         0.1348, 0.0334, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2012, 0.0000, 0.0000, 0.0931, 0.0000, 0.1683, 0.1025,\n","         0.1234],\n","        [0.0809, 0.0000, 0.0584, 0.2335, 0.0000, 0.0422, 0.0000, 0.1239, 0.0921,\n","         0.0000, 0.0000, 0.0513, 0.0709, 0.0043, 0.0921, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1298, 0.0000, 0.0460, 0.0000, 0.0003, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0134, 0.0255, 0.0969, 0.0659, 0.2048, 0.0000, 0.0403,\n","         0.1668, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0790, 0.0000, 0.1267,\n","         0.1469, 0.0353, 0.0000, 0.1937, 0.0000, 0.0000, 0.0000, 0.0398, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0844, 0.0000, 0.1707, 0.0638,\n","         0.1327],\n","        [0.0864, 0.0000, 0.0555, 0.2329, 0.0000, 0.0422, 0.0000, 0.1253, 0.0921,\n","         0.0000, 0.0000, 0.0768, 0.0709, 0.0043, 0.0921, 0.0000, 0.0000, 0.0019,\n","         0.0000, 0.0000, 0.1453, 0.0000, 0.0500, 0.0000, 0.0003, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0175, 0.0440, 0.0958, 0.0629, 0.2119, 0.0000, 0.0399,\n","         0.1796, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0790, 0.0000, 0.1267,\n","         0.1469, 0.0347, 0.0000, 0.2168, 0.0000, 0.0000, 0.0000, 0.0345, 0.0000,\n","         0.0000, 0.0050, 0.2054, 0.0000, 0.0000, 0.0961, 0.0000, 0.1693, 0.0896,\n","         0.1327],\n","        [0.0880, 0.0000, 0.0610, 0.1907, 0.0000, 0.0353, 0.0000, 0.1067, 0.0374,\n","         0.0000, 0.0000, 0.0603, 0.0425, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1383, 0.0000, 0.0636, 0.0000, 0.0198, 0.0820, 0.0000,\n","         0.0000, 0.0489, 0.0153, 0.0303, 0.1109, 0.0654, 0.2110, 0.0000, 0.0214,\n","         0.1792, 0.0000, 0.1260, 0.0000, 0.1145, 0.0000, 0.0864, 0.0000, 0.0961,\n","         0.1038, 0.0345, 0.0000, 0.2022, 0.0000, 0.0113, 0.0000, 0.0414, 0.0000,\n","         0.0000, 0.0052, 0.1762, 0.0000, 0.0000, 0.0921, 0.0000, 0.1463, 0.1025,\n","         0.1129],\n","        [0.0880, 0.0000, 0.0610, 0.2382, 0.0000, 0.0422, 0.0000, 0.1247, 0.0921,\n","         0.0000, 0.0000, 0.0623, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1384, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0173, 0.0303, 0.1109, 0.0649, 0.2127, 0.0000, 0.0425,\n","         0.1808, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0334, 0.0000, 0.2039, 0.0000, 0.0113, 0.0000, 0.0421, 0.0000,\n","         0.0000, 0.0053, 0.2054, 0.0000, 0.0000, 0.0931, 0.0000, 0.1761, 0.1025,\n","         0.1327],\n","        [0.0738, 0.0000, 0.0555, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0348, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1218, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0061, 0.0185, 0.1109, 0.0629, 0.1929, 0.0000, 0.0275,\n","         0.1521, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0268, 0.0000, 0.1814, 0.0000, 0.0113, 0.0000, 0.0341, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0713, 0.0000, 0.1579, 0.1025,\n","         0.1327],\n","        [0.0779, 0.0000, 0.0546, 0.2329, 0.0000, 0.0422, 0.0000, 0.1224, 0.0921,\n","         0.0000, 0.0000, 0.0338, 0.0709, 0.0541, 0.0996, 0.0000, 0.0000, 0.0665,\n","         0.0000, 0.0000, 0.1206, 0.0000, 0.0636, 0.0000, 0.0198, 0.1124, 0.0000,\n","         0.0000, 0.0872, 0.0061, 0.0179, 0.1109, 0.0617, 0.1929, 0.0000, 0.0275,\n","         0.1557, 0.0000, 0.1555, 0.0000, 0.1194, 0.0000, 0.0864, 0.0000, 0.1267,\n","         0.1469, 0.0254, 0.0000, 0.1849, 0.0000, 0.0113, 0.0000, 0.0333, 0.0000,\n","         0.0000, 0.0000, 0.2054, 0.0000, 0.0000, 0.0757, 0.0000, 0.1579, 0.1025,\n","         0.1327]], grad_fn=<MaxBackward0>), tensor([[0.0383, 0.0000, 0.1112, 0.0000, 0.0584, 0.0888, 0.0000, 0.0000, 0.0606,\n","         0.0000, 0.0000, 0.1268, 0.0349, 0.0952, 0.0387, 0.1314, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1147, 0.0000, 0.0611, 0.0000, 0.0000, 0.1094,\n","         0.0000, 0.0568, 0.0998, 0.0000, 0.0058, 0.0896, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0893, 0.0289, 0.0273, 0.0381, 0.0845, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0459, 0.0148, 0.0000, 0.0000, 0.0000, 0.1223, 0.0406, 0.0187,\n","         0.1247, 0.0000, 0.0663, 0.0000, 0.0000, 0.0465, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0380, 0.0000, 0.1113, 0.0000, 0.0587, 0.0886, 0.0000, 0.0000, 0.0608,\n","         0.0000, 0.0000, 0.1268, 0.0346, 0.0954, 0.0392, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1150, 0.0000, 0.0610, 0.0000, 0.0000, 0.1096,\n","         0.0000, 0.0566, 0.0998, 0.0000, 0.0060, 0.0892, 0.0000, 0.0285, 0.0000,\n","         0.0000, 0.0891, 0.0292, 0.0271, 0.0378, 0.0841, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0149, 0.0000, 0.0000, 0.0000, 0.1219, 0.0405, 0.0186,\n","         0.1247, 0.0000, 0.0661, 0.0000, 0.0000, 0.0459, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0377, 0.0000, 0.1118, 0.0000, 0.0592, 0.0885, 0.0000, 0.0000, 0.0612,\n","         0.0000, 0.0000, 0.1270, 0.0342, 0.0960, 0.0402, 0.1323, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1155, 0.0000, 0.0606, 0.0000, 0.0000, 0.1102,\n","         0.0000, 0.0564, 0.0996, 0.0000, 0.0067, 0.0885, 0.0000, 0.0288, 0.0000,\n","         0.0000, 0.0889, 0.0298, 0.0267, 0.0374, 0.0835, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0458, 0.0151, 0.0000, 0.0000, 0.0000, 0.1210, 0.0401, 0.0186,\n","         0.1249, 0.0000, 0.0660, 0.0000, 0.0000, 0.0445, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1119, 0.0000, 0.0591, 0.0885, 0.0000, 0.0000, 0.0611,\n","         0.0000, 0.0000, 0.1271, 0.0342, 0.0960, 0.0401, 0.1321, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0834, 0.1152, 0.0000, 0.0605, 0.0000, 0.0000, 0.1101,\n","         0.0000, 0.0564, 0.0995, 0.0000, 0.0067, 0.0884, 0.0000, 0.0287, 0.0000,\n","         0.0000, 0.0889, 0.0300, 0.0266, 0.0375, 0.0835, 0.0000, 0.0517, 0.0000,\n","         0.0000, 0.0458, 0.0150, 0.0000, 0.0000, 0.0000, 0.1210, 0.0400, 0.0186,\n","         0.1251, 0.0000, 0.0660, 0.0000, 0.0000, 0.0444, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1109, 0.0000, 0.0586, 0.0885, 0.0000, 0.0000, 0.0606,\n","         0.0000, 0.0000, 0.1266, 0.0345, 0.0953, 0.0391, 0.1317, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0836, 0.1152, 0.0000, 0.0611, 0.0000, 0.0000, 0.1096,\n","         0.0000, 0.0566, 0.0998, 0.0000, 0.0059, 0.0894, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0890, 0.0291, 0.0273, 0.0378, 0.0839, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0150, 0.0000, 0.0000, 0.0000, 0.1219, 0.0406, 0.0186,\n","         0.1246, 0.0000, 0.0661, 0.0000, 0.0000, 0.0462, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1106, 0.0000, 0.0583, 0.0883, 0.0000, 0.0000, 0.0605,\n","         0.0000, 0.0000, 0.1265, 0.0345, 0.0953, 0.0388, 0.1313, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1147, 0.0000, 0.0610, 0.0000, 0.0000, 0.1095,\n","         0.0000, 0.0566, 0.0997, 0.0000, 0.0058, 0.0893, 0.0000, 0.0283, 0.0000,\n","         0.0000, 0.0887, 0.0291, 0.0271, 0.0380, 0.0832, 0.0000, 0.0516, 0.0000,\n","         0.0000, 0.0459, 0.0148, 0.0000, 0.0000, 0.0000, 0.1219, 0.0405, 0.0187,\n","         0.1249, 0.0000, 0.0661, 0.0000, 0.0000, 0.0462, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0373, 0.0000, 0.1091, 0.0000, 0.0575, 0.0882, 0.0000, 0.0000, 0.0598,\n","         0.0000, 0.0000, 0.1259, 0.0347, 0.0946, 0.0373, 0.1304, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1145, 0.0000, 0.0614, 0.0000, 0.0000, 0.1092,\n","         0.0000, 0.0569, 0.0999, 0.0000, 0.0052, 0.0901, 0.0000, 0.0282, 0.0000,\n","         0.0000, 0.0882, 0.0286, 0.0277, 0.0384, 0.0823, 0.0000, 0.0514, 0.0000,\n","         0.0000, 0.0458, 0.0146, 0.0000, 0.0000, 0.0000, 0.1224, 0.0408, 0.0187,\n","         0.1247, 0.0000, 0.0664, 0.0000, 0.0000, 0.0475, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.0378, 0.0000, 0.1112, 0.0000, 0.0587, 0.0885, 0.0000, 0.0000, 0.0607,\n","         0.0000, 0.0000, 0.1267, 0.0344, 0.0956, 0.0393, 0.1318, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0835, 0.1151, 0.0000, 0.0609, 0.0000, 0.0000, 0.1097,\n","         0.0000, 0.0565, 0.0997, 0.0000, 0.0061, 0.0890, 0.0000, 0.0286, 0.0000,\n","         0.0000, 0.0889, 0.0293, 0.0270, 0.0377, 0.0836, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0458, 0.0149, 0.0000, 0.0000, 0.0000, 0.1216, 0.0405, 0.0186,\n","         0.1247, 0.0000, 0.0661, 0.0000, 0.0000, 0.0456, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5150, 0.4850],\n","        [0.5175, 0.4825],\n","        [0.5167, 0.4833],\n","        [0.5178, 0.4822],\n","        [0.5150, 0.4850],\n","        [0.5185, 0.4815],\n","        [0.5165, 0.4835],\n","        [0.5163, 0.4837]], grad_fn=<SoftmaxBackward0>))\n"]}]},{"cell_type":"code","source":["output_diffpool = diffpool_model_example(dataset[2], None)\n","print(output_diffpool)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xsMEt15OYlVb","executionInfo":{"status":"ok","timestamp":1694880567386,"user_tz":-120,"elapsed":248,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"e07b5b58-f5d4-42ac-9c21-81926d2e5a94"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["([tensor([[0.0768, 0.0000, 0.0510, 0.2335, 0.0000, 0.0314, 0.0000, 0.1239, 0.0850,\n","         0.0000, 0.0000, 0.0278, 0.0465, 0.0043, 0.0891, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1145, 0.0000, 0.0460, 0.0000, 0.0000, 0.0846, 0.0000,\n","         0.0000, 0.0712, 0.0026, 0.0225, 0.0947, 0.0606, 0.2051, 0.0000, 0.0403,\n","         0.1530, 0.0000, 0.1372, 0.0000, 0.1122, 0.0000, 0.0773, 0.0000, 0.1174,\n","         0.1331, 0.0192, 0.0000, 0.1844, 0.0000, 0.0000, 0.0000, 0.0281, 0.0000,\n","         0.0000, 0.0000, 0.2012, 0.0000, 0.0000, 0.0737, 0.0000, 0.1710, 0.0610,\n","         0.1221]], grad_fn=<MaxBackward0>), tensor([[0.0384, 0.0000, 0.1117, 0.0000, 0.0582, 0.0877, 0.0000, 0.0000, 0.0597,\n","         0.0000, 0.0000, 0.1274, 0.0350, 0.0947, 0.0383, 0.1314, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0826, 0.1143, 0.0000, 0.0607, 0.0000, 0.0000, 0.1090,\n","         0.0000, 0.0570, 0.0993, 0.0000, 0.0061, 0.0887, 0.0000, 0.0290, 0.0000,\n","         0.0000, 0.0883, 0.0291, 0.0269, 0.0387, 0.0836, 0.0000, 0.0515, 0.0000,\n","         0.0000, 0.0459, 0.0140, 0.0000, 0.0000, 0.0000, 0.1230, 0.0406, 0.0191,\n","         0.1243, 0.0000, 0.0666, 0.0000, 0.0000, 0.0461, 0.0000, 0.0000, 0.0000,\n","         0.0000]], grad_fn=<MaxBackward0>)], tensor([[0.5148, 0.4852]], grad_fn=<SoftmaxBackward0>))\n"]}]},{"cell_type":"code","source":["GNN_Model_optimizer = torch.optim.Adam(diffpool_model_example.parameters(), lr=0.01, weight_decay=1e-14)"],"metadata":{"id":"QJ8IS6qZxy1N","executionInfo":{"status":"ok","timestamp":1694881004630,"user_tz":-120,"elapsed":263,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.CrossEntropyLoss()\n","def loss_calculations(preds, gtruth):\n","    loss_per_epoch = criterion(preds, gtruth)\n","    return loss_per_epoch"],"metadata":{"id":"MQkUGgt6x9_2","executionInfo":{"status":"ok","timestamp":1694881028808,"user_tz":-120,"elapsed":257,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def loading_model(load_index):\n","    GNN_Model = diffpool_model.DIFFPOOL_Model(embedding_input_dim=7, embedding_num_block_layers=1, embedding_hid_dim=64,\n","                                              new_feature_size=64, assignment_input_dim=7, assignment_num_block_layers=1,\n","                                              assignment_hid_dim=64, max_number_of_nodes=256, prediction_hid_layers=[50],\n","                                              concat_neighborhood=False, num_classes=2, Weight_Initializer=1, Bias=classifier_bias,\n","                                              dropout_rate=0, normalize_graphsage=False, aggregation=\"mean\", act_fun=\"ReLu\",\n","                                              concat_diffpools_outputs=True, num_pooling=1, pooling=\"mean\")\n","    GNN_Model_optimizer = torch.optim.Adam(GNN_Model.parameters(), lr=classifier_lr, weight_decay=classifier_weight_decay)\n","    checkpoint = torch.load(\"/content/drive/My Drive/Explainability Methods/\"+str(Explainability_name) + \" on \" + str(Task_name) + \"/Model/\" + File_Name + str(epoch + load_index + 1) + \".pt\")\n","    GNN_Model.load_state_dict(checkpoint['model_state_dict'])\n","    GNN_Model_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    epoch = checkpoint['epoch']\n","    loss = checkpoint['loss']\n","\n","    return GNN_Model, GNN_Model_optimizer, epoch"],"metadata":{"id":"X9hR9GOJyDeq","executionInfo":{"status":"ok","timestamp":1694881038668,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def visualize_losses(g_losses, epoch_history):\n","    g_losses_list = torch.stack(g_losses).cpu().detach().numpy()\n","\n","    fig = plt.figure(figsize=(27,20))\n","\n","    ax = plt.subplot2grid((3, 1), (0, 0), colspan=1)\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title(\"SA Model Loss in Epoch: \" + str(epoch_history))\n","\n","    ax.plot(g_losses_list, color='r')\n","\n","    #plt.savefig('/content/drive/My Drive/Explainability Methods/'+str(Explainability_name)+' on ' + str(Task_name) + '/Experimental Results/' + File_Name + 'Loss_til_epoch_{:04d}.png'.format(epoch_history))\n","    plt.show()\n","\n","\n"],"metadata":{"id":"cUC80AityGFt","executionInfo":{"status":"ok","timestamp":1694881053782,"user_tz":-120,"elapsed":2,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["def train_step():\n","    GNN_Model_loss_batch = []\n","    Pred_Labels = []\n","    Real_Labels = []\n","\n","    GNN_Model.train()\n","    GNN_Model.zero_grad()\n","    #torch.autograd.set_detect_anomaly(True)\n","    for batch_of_graphs in train_loader:\n","\n","        concatination_list_of_poolings, softmaxed_h2 = GNN_Model(batch_of_graphs, None)\n","        batch_loss = loss_calculations(softmaxed_h2, batch_of_graphs.y)\n","\n","\n","        Pred_Labels.extend(softmaxed_h2.argmax(dim=1).detach().tolist())\n","        Real_Labels.extend(batch_of_graphs.y.detach().tolist())\n","        GNN_Model_loss_batch.append(batch_loss)\n","\n","        batch_loss.backward()\n","\n","        GNN_Model_optimizer.step()\n","\n","    return torch.mean(torch.tensor(GNN_Model_loss_batch)), metrics.accuracy_score(Real_Labels, Pred_Labels)\n"],"metadata":{"id":"hov_hA3dyJt4","executionInfo":{"status":"ok","timestamp":1694881063220,"user_tz":-120,"elapsed":221,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def batching_adjacency(whole_graphs_adjacency, batch_feat, batch_size):\n","    \"\"\"\n","        transform a batched graph to batched adjacency tensor and node feature tensor\n","    \"\"\"\n","    #print(\"whole_graphs_adjacency.size()[0]: \", whole_graphs_adjacency.size()[0])\n","    new_number_of_nodes = int(whole_graphs_adjacency.size()[0] / batch_size)\n","    #print(batch_size)\n","    adjacency_list = []\n","    feature_list = []\n","    for i in range(batch_size):\n","        start = i * new_number_of_nodes\n","        end = (i + 1) * new_number_of_nodes\n","        adjacency_list.append(whole_graphs_adjacency[start:end, start:end])\n","        feature_list.append(batch_feat[start:end, :])\n","    adjacency_list = list(map(lambda x: torch.unsqueeze(x, 0), adjacency_list))\n","    feature_list = list(map(lambda x: torch.unsqueeze(x, 0), feature_list))\n","    new_adjacecny = torch.cat(adjacency_list, dim=0)\n","    new_features = torch.cat(feature_list, dim=0)\n","\n","    return new_features, new_adjacecny"],"metadata":{"id":"z671puW8nF0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","batched_dataset = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","\n","for batched_graph in batched_dataset:\n","    x, edge_index, batch, y = batched_graph.x, batched_graph.edge_index, batched_graph.batch, batched_graph.y\n","    tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graph.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graph.edge_index).todense())))\n","    feat,adj = batching_adjacency(tilda_adjacency_matrix, x, batch_size)\n","    break\n","print(adj.size())\n","print(feat.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZLKQhMHbf10J","executionInfo":{"status":"ok","timestamp":1678023494677,"user_tz":-60,"elapsed":385,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"644b020b-2d50-4ad8-f097-d1c2eaae1dab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["whole_graphs_adjacency.size()[0]:  585\n","32\n","torch.Size([32, 18, 18])\n","torch.Size([32, 18, 7])\n"]}]},{"cell_type":"code","source":["        #tilda_degree_vector = torch.sum(tilda_adjacency_matrix, dim=1)\n","\n","        #k = tilda_degree_vector.size(0)\n","        #tilda_degree_matrix = torch.zeros(k, k)\n","        #tilda_degree_matrix.as_strided([k], [k + 1]).copy_(tilda_degree_vector)\n","        #tilda_degree_matrix = tilda_degree_matrix.to(torch.float32)\n","\n","        #ones_matrix = torch.ones_like(tilda_degree_matrix)\n","\n","        #reciprocal_tilda_degree_matrix = ones_matrix.div(tilda_degree_matrix)\n","        #reciprocal_tilda_degree_matrix = torch.nan_to_num(reciprocal_tilda_degree_matrix, nan=0, posinf=0, neginf=0)\n","\n","        #return tilda_adjacency_matrix, reciprocal_tilda_degree_matrix\n","        #tilda_degree_matrix = torch.nan_to_num(tilda_degree_matrix, nan=0, posinf=0, neginf=0)"],"metadata":{"id":"tSjrOjKSGI7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def diffpool_new_number_of_nodes(your_dataset):\n","    size_list = []\n","    for graph in your_dataset:\n","        size_list.append(len(graph.x))\n","    return max(size_list)\n","print(diffpool_new_number_of_nodes(dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dp55wbAt9Eci","executionInfo":{"status":"ok","timestamp":1687971847101,"user_tz":-120,"elapsed":310,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"e8305492-9450-4d27-f0df-d6cf56b13449"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["28\n"]}]},{"cell_type":"code","source":["def computational_matricess(batched_graphs, edge_mask):\n","    if edge_mask == None:\n","        joint_tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())))\n","    else:\n","        joint_tilda_adjacency_matrix = torch.tensor(csr_matrix((np.array(edge_mask), (np.array(batched_graphs.edge_index[0]), np.array(batched_graphs.edge_index[1])))).todense())\n","    #joint_tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())))\n","    joint_tilda_adjacency_matrix = joint_tilda_adjacency_matrix.type(torch.float32)\n","    batch_size = batched_graphs.num_graphs\n","\n","\n","    if batched_graphs.batch is not None:\n","        graph_sizes = [len(batched_graphs[i].x) for i in range(len(batched_graphs))]\n","    else:\n","        graph_sizes = [len(batched_graphs.x)]\n","    max_number_of_nodes_in_batch_of_graphs = max(graph_sizes)\n","    print(\"max_number_of_nodes_in_batch_of_graphs: \", max_number_of_nodes_in_batch_of_graphs)\n","\n","\n","    #print(\"whole_graphs_adjacency.size()[0]: \", whole_graphs_adjacency.size()[0])\n","    new_number_of_nodes = int(joint_tilda_adjacency_matrix.size()[0] / batch_size)\n","\n","    adjacency_list = []\n","    feature_list = []\n","    for i in range(batch_size):\n","        start = i * graph_sizes[i]\n","        end = (i + 1) * graph_sizes[i]\n","        un_padded_adj = joint_tilda_adjacency_matrix[start:end, start:end]\n","        off_set = max_number_of_nodes_in_batch_of_graphs - un_padded_adj.size()[0]\n","        if un_padded_adj.size()[0] < max_number_of_nodes_in_batch_of_graphs:\n","            un_padded_adj = un_padded_adj.numpy()\n","            un_padded_adj = np.pad(un_padded_adj, [(0, off_set), (0, off_set)], mode='constant')\n","            un_padded_adj = torch.from_numpy(un_padded_adj)\n","        adjacency_list.append(un_padded_adj)\n","\n","        un_padded_feat = batched_graphs.x[start:end, :].numpy()\n","        un_padded_feat = torch.from_numpy(np.pad(un_padded_feat, [(0, off_set), (0, 0)], mode='constant'))\n","        feature_list.append(un_padded_feat)\n","\n","\n","    adjacency_list = list(map(lambda x: torch.unsqueeze(x, 0), adjacency_list))\n","    feature_list = list(map(lambda x: torch.unsqueeze(x, 0), feature_list))\n","    new_adjacecny = torch.cat(adjacency_list, dim=0)\n","    print(\"new_adjacecny: \", new_adjacecny.size())\n","    new_features = torch.cat(feature_list, dim=0)\n","    print(\"new_features: \", new_features.size())\n","    #new_adjacecny = new_adjacecny.view(batch_size, new_number_of_nodes, new_number_of_nodes)\n","\n","    return new_adjacecny, new_features\n","\n","\n","\n","batch_size = 10\n","batched_dataset = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","\n","\n","for batched_graph in batched_dataset:\n","    x, edge_index, batch, y = batched_graph.x, batched_graph.edge_index, batched_graph.batch, batched_graph.y\n","    concatination_list_of_poolings, prediction_output = computational_matricess(batched_graph, None)\n","    print(\"Final Output: \", prediction_output)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMHveieCz1Sq","executionInfo":{"status":"ok","timestamp":1689553354043,"user_tz":-120,"elapsed":351,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"899b0ec2-92eb-4c11-d577-8e24062dca6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["max_number_of_nodes_in_batch_of_graphs:  28\n","new_adjacecny:  torch.Size([10, 28, 28])\n","new_features:  torch.Size([10, 28, 7])\n","Final Output:  tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n","         [1., 0., 0.,  ..., 0., 0., 0.],\n","         [1., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[1., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 1., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 1.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[1., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 1., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 1.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        ...,\n","\n","        [[0., 1., 0.,  ..., 0., 0., 0.],\n","         [1., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 1., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 1.,  ..., 0., 0., 0.],\n","         [0., 0., 1.,  ..., 0., 0., 0.],\n","         [0., 1., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[1., 0., 0.,  ..., 0., 0., 0.],\n","         [1., 0., 0.,  ..., 0., 0., 0.],\n","         [1., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"]}]},{"cell_type":"code","source":["import numpy as np\n","a = np.array([[ 1.,  1.,  1.,  1.,  1.],\n","               [ 1.,  1.,  1.,  1.,  1.],\n","               [ 1.,  1.,  1.,  1.,  1.]])\n","a = np.pad(a, [(0, 1), (0, 2)], mode='constant')\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANAO87yaEPvV","executionInfo":{"status":"ok","timestamp":1689550696835,"user_tz":-120,"elapsed":256,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"64f758da-a505-49ee-eeca-bb91537fd9e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1. 1. 1. 1. 1. 0. 0.]\n"," [1. 1. 1. 1. 1. 0. 0.]\n"," [1. 1. 1. 1. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]]\n"]}]}]}