{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJ8A6QoosYV+BmaU7TqrtO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Install required packages.\n","import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install --upgrade scipy networkx numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1-wH0UGhxdC","executionInfo":{"status":"ok","timestamp":1713302468147,"user_tz":-120,"elapsed":88422,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"d9b04a57-357f-4d44-e485-6bd6c22bc098"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.1+cu121\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n","Collecting scipy\n","  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Collecting numpy\n","  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, scipy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.11.4\n","    Uninstalling scipy-1.11.4:\n","      Successfully uninstalled scipy-1.11.4\n","Successfully installed numpy-1.26.4 scipy-1.13.0\n"]}]},{"cell_type":"code","source":["\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import math\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","import torch_geometric\n","#from torch_geometric.utils.convert import to_scipy_sparse_matrix\n","#from torch_geometric.utils.train_test_split_edges import torch_geometric\n","from scipy.sparse import csr_matrix\n","import networkx as nx\n","import numpy as np\n","from torch_geometric.nn import GCNConv\n","from importlib import reload\n","from torch_geometric.datasets import TUDataset\n","from sklearn import metrics\n","from time import perf_counter\n","import statistics\n","import torch_geometric.nn as gnn"],"metadata":{"id":"EP7eQC93ZWGk","executionInfo":{"status":"ok","timestamp":1713302754566,"user_tz":-120,"elapsed":235,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZ266IRTj0ZL","executionInfo":{"status":"ok","timestamp":1713302770737,"user_tz":-120,"elapsed":15231,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"cd398e05-9ce4-4aee-d177-cac3b771e229"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","#import matrix_util as Mat_Util\n","import DGCNN_layer as dgcnn_layer\n","import DGCNN_GNN_Layers as dgcnn_gnn_layers\n","import SortPooling_Layer as sortpooling_layer\n","import MLP_DGCNN as mlp_dgcnn\n","\n"],"metadata":{"id":"_8LQR2emiy-b","executionInfo":{"status":"ok","timestamp":1713302773257,"user_tz":-120,"elapsed":2523,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class MySpMM(torch.autograd.Function):\n","\t@staticmethod\n","\tdef forward(ctx, sp_mat, dense_mat):\n","\t\tctx.save_for_backward(sp_mat, dense_mat)\n","\t\treturn torch.bmm(sp_mat, dense_mat)\n","\n","\t@staticmethod\n","\tdef backward(ctx, grad_output):\n","\t\tsp_mat, dense_mat = ctx.saved_variables\n","\t\tgrad_matrix1 = grad_matrix2 = None\n","\n","\t\tassert not ctx.needs_input_grad[0]\n","\t\tif ctx.needs_input_grad[1]:\n","\t\t\tgrad_matrix2 = Variable(torch.bmm(sp_mat.data.t(), grad_output.data), requires_grad=True)\n","\n","\t\treturn grad_matrix1, grad_matrix2\n","\n","\n","def gnn_spmm(sp_mat, dense_mat):\n","\treturn MySpMM.apply(sp_mat, dense_mat)"],"metadata":{"id":"atmcM0f59u6N","executionInfo":{"status":"ok","timestamp":1713302773257,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":86,"metadata":{"id":"rp-nqzfOfoV1","executionInfo":{"status":"ok","timestamp":1713308414643,"user_tz":-120,"elapsed":212,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","#import matrix_util as Mat_Util\n","from torch.autograd import Variable\n","class GNN_DGCNN(nn.Module):\n","    '''\n","\t\tA single DGCNN Layer, using propagation matrix defined by Zhang et al. in DGCNN\n","\t'''\n","    def __init__(self, input_dim, latent_dim, Bias):\n","\n","        super(GNN_DGCNN, self).__init__()\n","        self.input_dim = input_dim\n","        self.latent_dim = latent_dim\n","        self.conv_params = nn.Linear(input_dim, latent_dim, bias=Bias)\n","\n","\n","    def forward(self, input_tensor, tilda_adjacency_matrix, reciprocal_tilda_degree_matrix):\n","\n","        adjacency_matrix_multiplied = torch.bmm(tilda_adjacency_matrix, input_tensor)  # Y = A~ * X\n","        node_linear = self.conv_params(adjacency_matrix_multiplied) # Y = Y * W\n","        normalized_linear = torch.bmm(reciprocal_tilda_degree_matrix, node_linear)  # Y = D^-1 * Y\n","\n","        return normalized_linear"]},{"cell_type":"code","source":["from torch_geometric.loader import DataLoader\n","mutag_dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n","mutag_batched_dataset = DataLoader(mutag_dataset, batch_size=10, shuffle=False)\n","#DGCNN_layer = dgcnn_layer.GraphConvolutionLayer_DGCNN(7, 7)"],"metadata":{"id":"H0kyReLpk2xn","executionInfo":{"status":"ok","timestamp":1713302794011,"user_tz":-120,"elapsed":2,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#import DGCNN_layer as dgcnn_layer\n","from scipy.sparse import csr_matrix\n","class dgcnn_gnn_layers(nn.Module):\n","    def __init__(self, GNN_layers, node_feat_size, Bias, dgcnn_act_fun):\n","        super(dgcnn_gnn_layers, self).__init__()\n","        self.GNN_layers = GNN_layers\n","        self.num_GNN_layers = len(GNN_layers)\n","        self.node_feat_size = node_feat_size\n","        self.output_dim = GNN_layers[-1]\n","        self.Bias = Bias\n","\n","        self.gnn_layers = []\n","\n","        for i in range(self.num_GNN_layers):\n","            if self.num_GNN_layers == 1:\n","                self.gnn_layers.append(GNN_DGCNN(input_dim=self.node_feat_size, latent_dim=self.output_dim, Bias=self.Bias))\n","            elif self.num_GNN_layers > 1:\n","                if i == 0:\n","                    self.gnn_layers.append(GNN_DGCNN(input_dim=self.node_feat_size, latent_dim=self.GNN_layers[i], Bias=self.Bias))\n","                elif 0 < i < self.num_GNN_layers-1:\n","                    self.gnn_layers.append(GNN_DGCNN(input_dim=self.GNN_layers[i-1], latent_dim=self.GNN_layers[i], Bias=self.Bias))\n","                elif i == self.num_GNN_layers-1:\n","                    self.gnn_layers.append(GNN_DGCNN(input_dim=self.GNN_layers[i-1], latent_dim=self.output_dim, Bias=self.Bias))\n","            else:\n","                print(\"please enter layer config\")\n","        self.gnn_layers = nn.Sequential(*self.gnn_layers)\n","\n","        if dgcnn_act_fun == 'ReLu':\n","            self.dgcnn_act_fun = F.relu\n","            print('ReLu is Selected.')\n","        elif dgcnn_act_fun == 'eLu':\n","            self.dgcnn_act_fun = nn.functional.elu\n","            print('eLu is Selected.')\n","        elif dgcnn_act_fun == 'tanh':\n","            self.dgcnn_act_fun = torch.tanh\n","            print('tanh is Selected.')\n","\n","\n","    def computational_matrices(self, batched_graphs, edge_mask):\n","        if edge_mask == None:\n","            tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())))\n","        else:\n","            tilda_adjacency_matrix = torch.tensor(csr_matrix((np.array(edge_mask), (np.array(batched_graphs.edge_index[0]), np.array(batched_graphs.edge_index[1])))).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())))\n","        tilda_adjacency_matrix = tilda_adjacency_matrix.type(torch.float32)\n","\n","        if batched_graphs.batch is not None:\n","            graph_sizes = [len(batched_graphs[i].x) for i in range(len(batched_graphs))]\n","            batch_size = batched_graphs.num_graphs\n","        else:\n","            graph_sizes = [len(batched_graphs.x)]\n","            batch_size = 1\n","        max_number_of_nodes_in_batch_of_graphs = max(graph_sizes)\n","\n","        adjacency_list = []\n","        degree_list = []\n","        feature_list = []\n","        start = 0\n","        for i in range(batch_size):\n","            end = start + graph_sizes[i]\n","            un_padded_adj = tilda_adjacency_matrix[start:end, start:end]\n","            adj_off_set = max_number_of_nodes_in_batch_of_graphs - un_padded_adj.size()[0]\n","            if un_padded_adj.size()[0] <= max_number_of_nodes_in_batch_of_graphs:\n","                un_padded_adj = F.pad(un_padded_adj, (0, adj_off_set, 0, adj_off_set), mode='constant', value=0)\n","                un_padded_adj = un_padded_adj.type(torch.float32)\n","                tilda_degree_vector = torch.sum(un_padded_adj, dim=1)\n","                num_nodes = max_number_of_nodes_in_batch_of_graphs\n","                tilda_degree_matrix = torch.zeros(num_nodes, num_nodes)\n","                tilda_degree_matrix.as_strided([num_nodes], [num_nodes + 1]).copy_(tilda_degree_vector)\n","            tilda_degree_matrix = tilda_degree_matrix.type(torch.float32)\n","            un_padded_adj = un_padded_adj.type(torch.float32)\n","            adjacency_list.append(un_padded_adj)\n","            degree_list.append(tilda_degree_matrix)\n","            un_padded_feat = batched_graphs.x[start:end, :]\n","            node_feat_off_set = max_number_of_nodes_in_batch_of_graphs - graph_sizes[i]\n","            un_padded_feat = F.pad(un_padded_feat, (0, 0, 0, node_feat_off_set), mode='constant', value=0)\n","            un_padded_feat = un_padded_feat.type(torch.float32)\n","            un_padded_feat.require_grad = True\n","            feature_list.append(un_padded_feat)\n","            start = end\n","\n","        adjacency_list = list(map(lambda x: torch.unsqueeze(x, 0), adjacency_list))\n","        degree_list = list(map(lambda x: torch.unsqueeze(x, 0), degree_list))\n","        feature_list = list(map(lambda x: torch.unsqueeze(x, 0), feature_list))\n","\n","        new_adjacecny = torch.cat(adjacency_list, dim=0)\n","        new_degree = torch.cat(degree_list, dim=0)\n","        new_features = torch.cat(feature_list, dim=0)\n","\n","        reciprocal_tilda_degree_matrix = torch.reciprocal(new_degree)\n","        reciprocal_tilda_degree_matrix = torch.nan_to_num(reciprocal_tilda_degree_matrix, nan=0, neginf=0.0, posinf=0.0)\n","\n","        return new_adjacecny, reciprocal_tilda_degree_matrix, new_features\n","\n","    def forward(self, graph, edge_mask):\n","        x, edge_index, batch, y = graph.x, graph.edge_index, graph.batch, graph.y\n","\n","        if batch is not None:\n","            graph_sizes = [len(graph[i].x) for i in range(len(graph))]\n","        else:\n","            graph_sizes = [len(graph.x)]\n","\n","        Output_of_GNN_Layers = []\n","        new_adjacecny, reciprocal_tilda_degree_matrix, x = self.computational_matrices(graph, edge_mask)\n","\n","        for i in range(self.num_GNN_layers):\n","            x = self.gnn_layers[i](x, new_adjacecny, reciprocal_tilda_degree_matrix)\n","            x = self.dgcnn_act_fun(x)\n","            Output_of_GNN_Layers.append(x)\n","        return x#Output_of_GNN_Layers\n","\n","\n","\n","dgcnn_layers_example = dgcnn_gnn_layers(GNN_layers=[32, 32, 32, 7], node_feat_size=7, Bias=True, dgcnn_act_fun=\"tanh\")\n"],"metadata":{"id":"s_9nVxiqKPTk","executionInfo":{"status":"ok","timestamp":1713310047259,"user_tz":-120,"elapsed":2,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"90c7b7e3-f8e6-4881-c58b-320b2cc74015"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["tanh is Selected.\n"]}]},{"cell_type":"code","source":["example = mutag_dataset[0]\n","e_ind = [[0, 0, 1], [1, 2, 0]]\n","e_ind = np.array(e_ind)\n","e_ind_t = torch.from_numpy(e_ind)\n","example.edge_index = e_ind_t\n","print(example.edge_index)\n","print(example.x.size())\n","print(example)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4An5_RKB0N06","executionInfo":{"status":"ok","timestamp":1713308357339,"user_tz":-120,"elapsed":240,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"db936647-23a7-4230-ddfa-a2c2900c29bd"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 0, 1],\n","        [1, 2, 0]])\n","torch.Size([17, 7])\n","Data(edge_index=[2, 3], x=[17, 7], edge_attr=[38, 4], y=[1])\n"]}]},{"cell_type":"code","source":["Output_of_GNN_Layers = dgcnn_layers_example(example, None)\n","print(Output_of_GNN_Layers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFJqQnEr0T8q","executionInfo":{"status":"ok","timestamp":1713310062192,"user_tz":-120,"elapsed":230,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"85d71c79-796d-4c49-edce-bd230217cd4d"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-0.0160,  0.0086,  0.1299,  0.0369,  0.0136, -0.0698,  0.0021],\n","         [-0.0520,  0.0189,  0.1408,  0.0292,  0.0249, -0.0898,  0.0010],\n","         [-0.0868,  0.0278,  0.2448,  0.0391,  0.0078, -0.1711, -0.0630],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n","       grad_fn=<TanhBackward0>)\n"]}]},{"cell_type":"code","source":["from torch_geometric.loader import DataLoader\n","dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n","batched_dataset = DataLoader(dataset, batch_size=10, shuffle=False)"],"metadata":{"id":"idF3BmmOYOoB","executionInfo":{"status":"ok","timestamp":1713308976424,"user_tz":-120,"elapsed":2,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["for i,batch in enumerate(mutag_batched_dataset):\n","    #print(batch)\n","    print(batch.x.size())\n","    Output_of_GNN_Layers = dgcnn_layers_example(batch, None)\n","    print(\"here:\", len(Output_of_GNN_Layers), Output_of_GNN_Layers.size())\n","    print(Output_of_GNN_Layers)\n","    break\n","\n","    #if i == 176:\n","    #    #print(i, Output_of_GNN_Layers[-1],tilda_degree_matrix, reciprocal_tilda_degree_matrix)\n","    #    print(i, Output_of_GNN_Layers)"],"metadata":{"id":"ECsBYhyBtpl1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713310081161,"user_tz":-120,"elapsed":322,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"48d8edb5-109b-4ca0-d676-f592469479b2"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([166, 7])\n","here: 10 torch.Size([10, 28, 7])\n","tensor([[[-0.0414,  0.0006,  0.1046,  ...,  0.0368, -0.0622,  0.0056],\n","         [-0.0414,  0.0006,  0.1045,  ...,  0.0369, -0.0621,  0.0055],\n","         [-0.0430,  0.0014,  0.1028,  ...,  0.0378, -0.0616,  0.0072],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[-0.0415,  0.0029,  0.1026,  ...,  0.0350, -0.0625,  0.0024],\n","         [-0.0420,  0.0047,  0.1019,  ...,  0.0358, -0.0626,  0.0056],\n","         [-0.0306,  0.0046,  0.0881,  ...,  0.0327, -0.0510,  0.0097],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[-0.0411,  0.0045,  0.1021,  ...,  0.0340, -0.0629,  0.0015],\n","         [-0.0409,  0.0091,  0.1005,  ...,  0.0329, -0.0639,  0.0030],\n","         [-0.0295,  0.0088,  0.0867,  ...,  0.0299, -0.0523,  0.0072],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        ...,\n","\n","        [[-0.0741,  0.0017,  0.1191,  ...,  0.0336, -0.0734, -0.0206],\n","         [-0.0396, -0.0121,  0.0847,  ...,  0.0299, -0.0372, -0.0065],\n","         [-0.0765,  0.0003,  0.1167,  ...,  0.0331, -0.0708, -0.0232],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[-0.0427,  0.0101,  0.0974,  ...,  0.0307, -0.0622, -0.0013],\n","         [-0.0409,  0.0119,  0.0985,  ...,  0.0306, -0.0643, -0.0003],\n","         [-0.0271,  0.0166,  0.0845,  ...,  0.0250, -0.0548,  0.0031],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[-0.0623,  0.0068,  0.1305,  ...,  0.0377, -0.0868, -0.0077],\n","         [-0.0287, -0.0039,  0.0943,  ...,  0.0347, -0.0506,  0.0099],\n","         [-0.0422,  0.0027,  0.1031,  ...,  0.0371, -0.0618,  0.0078],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n","       grad_fn=<TanhBackward0>)\n"]}]},{"cell_type":"code","source":["\n","import os\n","import sys\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","class SortPooling_updated(nn.Module):\n","    def __init__(self, sort_pooling_k, node_feat_size):\n","        super(SortPooling_updated, self).__init__()\n","        self.sort_pooling_k, = sort_pooling_k,\n","        self.node_feat_size = node_feat_size\n","\n","\n","    def max_sort(self, row):\n","        return torch.max(row)\n","\n","    #def index_select(self, tensor, dim, index):\n","    #    return tensor.gather(dim, index.unsqueeze(dim)).squeeze(dim)\n","\n","    def forward(self, output_of_dgcnn_layer, batch_graphs):\n","        if batch_graphs.batch is not None:\n","            graph_sizes = [len(batch_graphs[i].x) for i in range(len(batch_graphs))]\n","        else:\n","            graph_sizes = [len(batch_graphs.x)]\n","\n","\n","        start_index = 0\n","        batch_graphs_ready_to_sort = []\n","        if batch_graphs.batch is not None:\n","            if output_of_dgcnn_layer.size()[1] >= self.sort_pooling_k:\n","\n","                values, indexes = torch.topk(output_of_dgcnn_layer, k=1, dim=-1)\n","                vals, indxs = torch.topk(values, k=self.sort_pooling_k, dim=1)\n","                indxs = torch.squeeze(indxs, -1)\n","                dummy = indxs.unsqueeze(2).expand(indxs.size(0), indxs.size(1), output_of_dgcnn_layer.size(2))\n","                sorted_graph = torch.gather(output_of_dgcnn_layer, 1, dummy)\n","\n","            else:\n","                off_set = self.sort_pooling_k - output_of_dgcnn_layer.size()[1]\n","                output_of_dgcnn_layer = F.pad(output_of_dgcnn_layer, (0, 0, 0, off_set), mode='constant', value=0)\n","                output_of_dgcnn_layer = output_of_dgcnn_layer.type(torch.float32)\n","\n","\n","                values, indexes = torch.topk(output_of_dgcnn_layer, k=1, dim=-1)\n","                vals, indxs = torch.topk(values, k=output_of_dgcnn_layer.size()[1], dim=1)\n","                indxs = torch.squeeze(indxs, -1)\n","                dummy = indxs.unsqueeze(2).expand(indxs.size(0), indxs.size(1), output_of_dgcnn_layer.size(2))\n","                sorted_graph = torch.gather(output_of_dgcnn_layer, 1, dummy)\n","\n","                batch_graphs_ready_to_sort.append(sorted_graph)\n","\n","\n","        else:\n","            for i in range(len([batch_graphs])):\n","\n","                if output_of_dgcnn_layer[i].size()[0] >= self.sort_pooling_k:\n","                    top_max_values, top_max_indexes = torch.topk(output_of_dgcnn_layer[i], k=1, dim=1)\n","                    top_k_values, top_k_indexes = torch.topk(top_max_values, k=self.sort_pooling_k, dim=0)\n","\n","                    sorted_graph = output_of_dgcnn_layer[i].index_select(dim=0, index=torch.reshape(top_k_indexes, (-1,)))\n","\n","                else:\n","                    off_set = self.sort_pooling_k - output_of_dgcnn_layer[i].size()[0]\n","                    output_of_dgcnn_layer = F.pad(output_of_dgcnn_layer, (0, 0, 0, off_set), mode='constant', value=0)\n","                    output_of_dgcnn_layer = output_of_dgcnn_layer.type(torch.float32)\n","\n","                    top_max_values, top_max_indexes = torch.topk(output_of_dgcnn_layer[i], k=1, dim=1)\n","                    top_k_values, top_k_indexes = torch.topk(top_max_values, k=output_of_dgcnn_layer[i].size()[0], dim=0)\n","                    sorted_graph = output_of_dgcnn_layer[i].index_select(dim=0, index=torch.reshape(top_k_indexes, (-1,)))\n","\n","\n","        return sorted_graph\n"],"metadata":{"id":"IOxBcASLk8Zs","executionInfo":{"status":"ok","timestamp":1713310112546,"user_tz":-120,"elapsed":214,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["sortpooling_exaple = SortPooling_updated(sort_pooling_k=17, node_feat_size=7)"],"metadata":{"id":"iRg0zA7enpgE","executionInfo":{"status":"ok","timestamp":1713310115586,"user_tz":-120,"elapsed":213,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["for i,batch in enumerate(dataset):\n","    #print(batch)\n","\n","    Output_of_GNN_Layers = dgcnn_layers_example(batch, None)\n","\n","    output_of_sortpooling = sortpooling_exaple(Output_of_GNN_Layers, batch)\n","\n","\n","    #print(Output_of_GNN_Layers[-1])\n","\n","    #if i == 176:\n","    #    #print(i, Output_of_GNN_Layers[-1],tilda_degree_matrix, reciprocal_tilda_degree_matrix)\n","    #    print(i, Output_of_GNN_Layers)"],"metadata":{"id":"-fD91I8Inn3t","executionInfo":{"status":"ok","timestamp":1713310116875,"user_tz":-120,"elapsed":371,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["example = torch.arange(70)\n","example = torch.reshape(example, (10, 7))\n","print(example)\n","\n","example2 = F.pad(example, (0, 1, 0, 1), mode='constant', value=0)\n","example2 = example2.type(torch.float32)\n","example2 = Variable(example2, requires_grad=True)\n","print(example2)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cztQxBNFk2hF","executionInfo":{"status":"ok","timestamp":1713310118877,"user_tz":-120,"elapsed":219,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"001277dd-6d4b-488a-b463-f66980676cab"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0,  1,  2,  3,  4,  5,  6],\n","        [ 7,  8,  9, 10, 11, 12, 13],\n","        [14, 15, 16, 17, 18, 19, 20],\n","        [21, 22, 23, 24, 25, 26, 27],\n","        [28, 29, 30, 31, 32, 33, 34],\n","        [35, 36, 37, 38, 39, 40, 41],\n","        [42, 43, 44, 45, 46, 47, 48],\n","        [49, 50, 51, 52, 53, 54, 55],\n","        [56, 57, 58, 59, 60, 61, 62],\n","        [63, 64, 65, 66, 67, 68, 69]])\n","tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  0.],\n","        [ 7.,  8.,  9., 10., 11., 12., 13.,  0.],\n","        [14., 15., 16., 17., 18., 19., 20.,  0.],\n","        [21., 22., 23., 24., 25., 26., 27.,  0.],\n","        [28., 29., 30., 31., 32., 33., 34.,  0.],\n","        [35., 36., 37., 38., 39., 40., 41.,  0.],\n","        [42., 43., 44., 45., 46., 47., 48.,  0.],\n","        [49., 50., 51., 52., 53., 54., 55.,  0.],\n","        [56., 57., 58., 59., 60., 61., 62.,  0.],\n","        [63., 64., 65., 66., 67., 68., 69.,  0.],\n","        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], requires_grad=True)\n"]}]},{"cell_type":"code","source":["example = torch.arange(140)\n","example = torch.reshape(example, (2, 10, 7))\n","print(example)\n","\n","example = F.pad(example, (0, 0, 0, 1), mode='constant', value=0)\n","example = example.type(torch.float32)\n","example = Variable(example, requires_grad=True)\n","print(example)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OHC55-fUvozW","executionInfo":{"status":"ok","timestamp":1694477801851,"user_tz":-120,"elapsed":238,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"40458824-24d5-4b06-e300-1d8dd1931cb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[  0,   1,   2,   3,   4,   5,   6],\n","         [  7,   8,   9,  10,  11,  12,  13],\n","         [ 14,  15,  16,  17,  18,  19,  20],\n","         [ 21,  22,  23,  24,  25,  26,  27],\n","         [ 28,  29,  30,  31,  32,  33,  34],\n","         [ 35,  36,  37,  38,  39,  40,  41],\n","         [ 42,  43,  44,  45,  46,  47,  48],\n","         [ 49,  50,  51,  52,  53,  54,  55],\n","         [ 56,  57,  58,  59,  60,  61,  62],\n","         [ 63,  64,  65,  66,  67,  68,  69]],\n","\n","        [[ 70,  71,  72,  73,  74,  75,  76],\n","         [ 77,  78,  79,  80,  81,  82,  83],\n","         [ 84,  85,  86,  87,  88,  89,  90],\n","         [ 91,  92,  93,  94,  95,  96,  97],\n","         [ 98,  99, 100, 101, 102, 103, 104],\n","         [105, 106, 107, 108, 109, 110, 111],\n","         [112, 113, 114, 115, 116, 117, 118],\n","         [119, 120, 121, 122, 123, 124, 125],\n","         [126, 127, 128, 129, 130, 131, 132],\n","         [133, 134, 135, 136, 137, 138, 139]]])\n","tensor([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.],\n","         [  7.,   8.,   9.,  10.,  11.,  12.,  13.],\n","         [ 14.,  15.,  16.,  17.,  18.,  19.,  20.],\n","         [ 21.,  22.,  23.,  24.,  25.,  26.,  27.],\n","         [ 28.,  29.,  30.,  31.,  32.,  33.,  34.],\n","         [ 35.,  36.,  37.,  38.,  39.,  40.,  41.],\n","         [ 42.,  43.,  44.,  45.,  46.,  47.,  48.],\n","         [ 49.,  50.,  51.,  52.,  53.,  54.,  55.],\n","         [ 56.,  57.,  58.,  59.,  60.,  61.,  62.],\n","         [ 63.,  64.,  65.,  66.,  67.,  68.,  69.],\n","         [  0.,   0.,   0.,   0.,   0.,   0.,   0.]],\n","\n","        [[ 70.,  71.,  72.,  73.,  74.,  75.,  76.],\n","         [ 77.,  78.,  79.,  80.,  81.,  82.,  83.],\n","         [ 84.,  85.,  86.,  87.,  88.,  89.,  90.],\n","         [ 91.,  92.,  93.,  94.,  95.,  96.,  97.],\n","         [ 98.,  99., 100., 101., 102., 103., 104.],\n","         [105., 106., 107., 108., 109., 110., 111.],\n","         [112., 113., 114., 115., 116., 117., 118.],\n","         [119., 120., 121., 122., 123., 124., 125.],\n","         [126., 127., 128., 129., 130., 131., 132.],\n","         [133., 134., 135., 136., 137., 138., 139.],\n","         [  0.,   0.,   0.,   0.,   0.,   0.,   0.]]], requires_grad=True)\n"]}]},{"cell_type":"code","source":["example = torch.arange(140)\n","example = torch.reshape(example, (2, 10, 7))\n","print(example)\n","\n","pad = torch.zeros(28)\n","pad = torch.reshape(pad, (2, 2, 7))\n","print(pad)\n","\n","\n","\n","sorted_graph = torch.cat((example, pad), 1)\n","print(sorted_graph)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F8GnYpIc7xOu","executionInfo":{"status":"ok","timestamp":1694464422141,"user_tz":-120,"elapsed":228,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"382a7153-0f30-44c8-a882-7cf5533d3d50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[  0,   1,   2,   3,   4,   5,   6],\n","         [  7,   8,   9,  10,  11,  12,  13],\n","         [ 14,  15,  16,  17,  18,  19,  20],\n","         [ 21,  22,  23,  24,  25,  26,  27],\n","         [ 28,  29,  30,  31,  32,  33,  34],\n","         [ 35,  36,  37,  38,  39,  40,  41],\n","         [ 42,  43,  44,  45,  46,  47,  48],\n","         [ 49,  50,  51,  52,  53,  54,  55],\n","         [ 56,  57,  58,  59,  60,  61,  62],\n","         [ 63,  64,  65,  66,  67,  68,  69]],\n","\n","        [[ 70,  71,  72,  73,  74,  75,  76],\n","         [ 77,  78,  79,  80,  81,  82,  83],\n","         [ 84,  85,  86,  87,  88,  89,  90],\n","         [ 91,  92,  93,  94,  95,  96,  97],\n","         [ 98,  99, 100, 101, 102, 103, 104],\n","         [105, 106, 107, 108, 109, 110, 111],\n","         [112, 113, 114, 115, 116, 117, 118],\n","         [119, 120, 121, 122, 123, 124, 125],\n","         [126, 127, 128, 129, 130, 131, 132],\n","         [133, 134, 135, 136, 137, 138, 139]]])\n","tensor([[[0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.]],\n","\n","        [[0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.]]])\n","tensor([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.],\n","         [  7.,   8.,   9.,  10.,  11.,  12.,  13.],\n","         [ 14.,  15.,  16.,  17.,  18.,  19.,  20.],\n","         [ 21.,  22.,  23.,  24.,  25.,  26.,  27.],\n","         [ 28.,  29.,  30.,  31.,  32.,  33.,  34.],\n","         [ 35.,  36.,  37.,  38.,  39.,  40.,  41.],\n","         [ 42.,  43.,  44.,  45.,  46.,  47.,  48.],\n","         [ 49.,  50.,  51.,  52.,  53.,  54.,  55.],\n","         [ 56.,  57.,  58.,  59.,  60.,  61.,  62.],\n","         [ 63.,  64.,  65.,  66.,  67.,  68.,  69.],\n","         [  0.,   0.,   0.,   0.,   0.,   0.,   0.],\n","         [  0.,   0.,   0.,   0.,   0.,   0.,   0.]],\n","\n","        [[ 70.,  71.,  72.,  73.,  74.,  75.,  76.],\n","         [ 77.,  78.,  79.,  80.,  81.,  82.,  83.],\n","         [ 84.,  85.,  86.,  87.,  88.,  89.,  90.],\n","         [ 91.,  92.,  93.,  94.,  95.,  96.,  97.],\n","         [ 98.,  99., 100., 101., 102., 103., 104.],\n","         [105., 106., 107., 108., 109., 110., 111.],\n","         [112., 113., 114., 115., 116., 117., 118.],\n","         [119., 120., 121., 122., 123., 124., 125.],\n","         [126., 127., 128., 129., 130., 131., 132.],\n","         [133., 134., 135., 136., 137., 138., 139.],\n","         [  0.,   0.,   0.,   0.,   0.,   0.,   0.],\n","         [  0.,   0.,   0.,   0.,   0.,   0.,   0.]]])\n"]}]},{"cell_type":"code","source":["example = torch.arange(70)\n","#print(\"example: \", example)\n","example = torch.reshape(example, (10,7))\n","print(\"example: \", example)\n","print()\n","values, indexes = torch.topk(example, k=1, dim=1)\n","print(values)\n","print()\n","vals, indxs = torch.topk(values, k=5, dim=0)\n","print(vals, indxs)\n","\n","xx = example.index_select(dim=0, index=torch.reshape(indxs, (-1,)))\n","print(xx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YYyJrVrwFkR4","executionInfo":{"status":"ok","timestamp":1694455145856,"user_tz":-120,"elapsed":293,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"f1952edf-aceb-441b-e28a-037be060075f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["example:  tensor([[ 0,  1,  2,  3,  4,  5,  6],\n","        [ 7,  8,  9, 10, 11, 12, 13],\n","        [14, 15, 16, 17, 18, 19, 20],\n","        [21, 22, 23, 24, 25, 26, 27],\n","        [28, 29, 30, 31, 32, 33, 34],\n","        [35, 36, 37, 38, 39, 40, 41],\n","        [42, 43, 44, 45, 46, 47, 48],\n","        [49, 50, 51, 52, 53, 54, 55],\n","        [56, 57, 58, 59, 60, 61, 62],\n","        [63, 64, 65, 66, 67, 68, 69]])\n","\n","tensor([[ 6],\n","        [13],\n","        [20],\n","        [27],\n","        [34],\n","        [41],\n","        [48],\n","        [55],\n","        [62],\n","        [69]])\n","\n","tensor([[69],\n","        [62],\n","        [55],\n","        [48],\n","        [41]]) tensor([[9],\n","        [8],\n","        [7],\n","        [6],\n","        [5]])\n","tensor([[63, 64, 65, 66, 67, 68, 69],\n","        [56, 57, 58, 59, 60, 61, 62],\n","        [49, 50, 51, 52, 53, 54, 55],\n","        [42, 43, 44, 45, 46, 47, 48],\n","        [35, 36, 37, 38, 39, 40, 41]])\n"]}]},{"cell_type":"code","source":["example = torch.arange(140)\n","#print(\"example: \", example)\n","example = torch.reshape(example, (2, 10, 7))\n","print(\"example: \", example)\n","print()\n","values, indexes = torch.topk(example, k=1, dim=-1)\n","print(values)\n","print()\n","vals, indxs = torch.topk(values, k=2, dim=1)\n","print(vals)\n","print(\"indxs: \",indxs)\n","indxs = torch.squeeze(indxs, -1)\n","print(\"indxs: \",indxs)\n","dummy = indxs.unsqueeze(2).expand(indxs.size(0), indxs.size(1), example.size(2))\n","out = torch.gather(example, 1, dummy)\n","print(out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_IN-XopZc4J","executionInfo":{"status":"ok","timestamp":1694460956877,"user_tz":-120,"elapsed":249,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"47d5c4bd-4f68-4e42-e10d-a33f197d191e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["example:  tensor([[[  0,   1,   2,   3,   4,   5,   6],\n","         [  7,   8,   9,  10,  11,  12,  13],\n","         [ 14,  15,  16,  17,  18,  19,  20],\n","         [ 21,  22,  23,  24,  25,  26,  27],\n","         [ 28,  29,  30,  31,  32,  33,  34],\n","         [ 35,  36,  37,  38,  39,  40,  41],\n","         [ 42,  43,  44,  45,  46,  47,  48],\n","         [ 49,  50,  51,  52,  53,  54,  55],\n","         [ 56,  57,  58,  59,  60,  61,  62],\n","         [ 63,  64,  65,  66,  67,  68,  69]],\n","\n","        [[ 70,  71,  72,  73,  74,  75,  76],\n","         [ 77,  78,  79,  80,  81,  82,  83],\n","         [ 84,  85,  86,  87,  88,  89,  90],\n","         [ 91,  92,  93,  94,  95,  96,  97],\n","         [ 98,  99, 100, 101, 102, 103, 104],\n","         [105, 106, 107, 108, 109, 110, 111],\n","         [112, 113, 114, 115, 116, 117, 118],\n","         [119, 120, 121, 122, 123, 124, 125],\n","         [126, 127, 128, 129, 130, 131, 132],\n","         [133, 134, 135, 136, 137, 138, 139]]])\n","\n","tensor([[[  6],\n","         [ 13],\n","         [ 20],\n","         [ 27],\n","         [ 34],\n","         [ 41],\n","         [ 48],\n","         [ 55],\n","         [ 62],\n","         [ 69]],\n","\n","        [[ 76],\n","         [ 83],\n","         [ 90],\n","         [ 97],\n","         [104],\n","         [111],\n","         [118],\n","         [125],\n","         [132],\n","         [139]]])\n","\n","tensor([[[ 69],\n","         [ 62]],\n","\n","        [[139],\n","         [132]]])\n","indxs:  tensor([[[9],\n","         [8]],\n","\n","        [[9],\n","         [8]]])\n","indxs:  tensor([[9, 8],\n","        [9, 8]])\n","tensor([[[ 63,  64,  65,  66,  67,  68,  69],\n","         [ 56,  57,  58,  59,  60,  61,  62]],\n","\n","        [[133, 134, 135, 136, 137, 138, 139],\n","         [126, 127, 128, 129, 130, 131, 132]]])\n"]}]},{"cell_type":"code","source":["values, indexes = torch.topk(dataset[0].x, k=5, dim=0)\n","print(len(dataset[0].x), dataset[0].x,\"\\n\",\"\\n\", values,\"\\n\", indexes)\n","#print(torch.reshape(dataset[0].x, (-1,)))\n","xx = dataset[0].x.index_select(dim=0, index=torch.reshape(indexes, (-1,)))\n","print(xx.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-oAQcg9u53E","executionInfo":{"status":"ok","timestamp":1694449811620,"user_tz":-120,"elapsed":252,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"d2409f63-486e-4b91-cbdf-e5994f08c155"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["17 tensor([[1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0.]]) \n"," \n"," tensor([[1., 1., 1., 0., 0., 0., 0.],\n","        [1., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.]]) \n"," tensor([[11, 14, 16, 10, 10, 10, 10],\n","        [ 8, 10, 15, 12, 12, 12, 12],\n","        [ 9, 11, 11, 11, 11, 11, 11],\n","        [10, 13,  9, 13, 13, 13, 13],\n","        [ 1,  9, 10,  9,  9,  9,  9]])\n","torch.Size([35, 7])\n"]}]},{"cell_type":"code","source":["x = torch.tensor([[1, 2, 3, 4],[5, 6, 7 , 8],[9, 10, 11, 12],[13, 14, 15, 16]])\n","\n","vals, idx = torch.topk(x, k=2, dim=0)\n","print(idx )\n","x.scatter_(0, idx, 0)\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kbc-OZFpSsov","executionInfo":{"status":"ok","timestamp":1693826627182,"user_tz":-120,"elapsed":292,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"24c8e1bb-2958-4927-8cac-f846db2f12ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3, 3, 3, 3],\n","        [2, 2, 2, 2]])\n","tensor([[1, 2, 3, 4],\n","        [5, 6, 7, 8],\n","        [0, 0, 0, 0],\n","        [0, 0, 0, 0]])\n"]}]},{"cell_type":"code","source":["x = torch.tensor([1.0, 2], requires_grad=True)\n","x = x+5 # x now has a grad_fn\n","y = x.type(torch.double)\n","z = x.type(torch.uint8)\n","\n","print(y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h__iRYLVqOuA","executionInfo":{"status":"ok","timestamp":1693754925519,"user_tz":-120,"elapsed":248,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"47c950df-de8d-45d9-e509-79b7e26aafa9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([6., 7.], dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n","tensor([6, 7], dtype=torch.uint8)\n"]}]},{"cell_type":"code","source":["\n","import os\n","import sys\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","class SortPooling_old(nn.Module):\n","    def __init__(self, sort_pooling_k, node_feat_size):\n","        super(SortPooling_old, self).__init__()\n","        self.sort_pooling_k, = sort_pooling_k,\n","        self.node_feat_size = node_feat_size\n","\n","\n","    def max_sort(self, row):\n","        return max(row)\n","\n","\n","    def forward(self, output_of_dgcnn_layer, batch_graphs):\n","        graph_sizes = [len(batch_graphs[i].x) for i in range(len(batch_graphs))]\n","        batch_sortpooling_zero_graphs = torch.zeros(len(graph_sizes), self.sort_pooling_k, self.node_feat_size)\n","        #print(\"batch of graphs reshaped: \", batch_sortpooling_zero_graphs.size())\n","\n","        start_index = 0\n","        batch_graphs_ready_to_sort = []\n","        if batch_graphs.batch is not None:\n","            for i in range(len(batch_graphs)):\n","                graph_to_sort = output_of_dgcnn_layer[start_index: start_index + graph_sizes[i]]\n","                graph_to_sort = torch.reshape(graph_to_sort, (graph_sizes[i], self.node_feat_size))\n","\n","                sorted_graph = torch.Tensor(sorted(graph_to_sort.cpu().detach().tolist(), key = lambda row : max(row), reverse=True))\n","                if sorted_graph.size()[0] >= self.sort_pooling_k:\n","                    batch_sortpooling_zero_graphs[i][:self.sort_pooling_k, 0:self.node_feat_size] = Variable(sorted_graph[:self.sort_pooling_k, 0:self.node_feat_size])\n","                    #print(batch_sortpooling_zero_graphs[i])\n","                else:\n","                    batch_sortpooling_zero_graphs[i][:sorted_graph.size()[0], 0:self.node_feat_size] = Variable(sorted_graph[:sorted_graph.size()[0], 0:self.node_feat_size])\n","                    #print(batch_sortpooling_zero_graphs[i])\n","\n","                batch_graphs_ready_to_sort.append(sorted_graph)\n","                strat_index = start_index + graph_sizes[i]\n","        else:\n","            for i in range(len([batch_graphs])):\n","                graph_to_sort = output_of_dgcnn_layer[start_index: start_index + graph_sizes[i]]\n","                graph_to_sort = torch.reshape(graph_to_sort, (graph_sizes[i], self.node_feat_size))\n","\n","                sorted_graph = torch.Tensor(sorted(graph_to_sort.cpu().detach().tolist(), key = lambda row : max(row), reverse=True))\n","                if sorted_graph.size()[0] >= self.sort_pooling_k:\n","                    batch_sortpooling_zero_graphs[i][:self.sort_pooling_k, 0:self.node_feat_size] = sorted_graph[:self.sort_pooling_k, 0:self.node_feat_size]\n","                    #print(batch_sortpooling_zero_graphs[i])\n","                else:\n","                    batch_sortpooling_zero_graphs[i][:sorted_graph.size()[0], 0:self.node_feat_size] = sorted_graph[:sorted_graph.size()[0], 0:self.node_feat_size]\n","\n","\n","                batch_graphs_ready_to_sort.append(sorted_graph)\n","                strat_index = start_index + graph_sizes[i]\n","\n","        return batch_sortpooling_zero_graphs\n"],"metadata":{"id":"lY0zS0CyZ6mq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","\n","class MLP_DGCNN(nn.Module):\n","    def __init__(self, num_class, node_feat_size, mlp_act_fun, dropout_rate, hid_channels, conv1d_kernels, dgcnn_k, ffn_layer_size,\n","                 Bias, strides):\n","\n","        super(MLP_DGCNN, self).__init__()\n","        self.dgcnn_k = dgcnn_k\n","        self.node_feat_size = node_feat_size\n","        self.hid_channels = hid_channels\n","        self.conv1d_kernels = conv1d_kernels\n","        self.padding = 0\n","        self.ffn_layer_size = ffn_layer_size\n","        self.num_class = num_class\n","        self.Bias = Bias\n","        self.strides = strides\n","\n","        self.conv1d_1 = nn.Conv1d(in_channels=1, out_channels=self.hid_channels[0], kernel_size=self.conv1d_kernels[0], stride=self.strides[0], padding=self.padding, bias=self.Bias)\n","\n","        self.maxpool1d = nn.MaxPool1d(kernel_size=2, stride=2)\n","\n","        self.conv1d_2 = nn.Conv1d(in_channels=self.hid_channels[0], out_channels=self.hid_channels[1], kernel_size=self.conv1d_kernels[1], stride=self.strides[1], bias=self.Bias)\n","\n","        dim_conv1_out = int((self.dgcnn_k*self.node_feat_size + 2*self.padding -2)/(self.strides[0]) + 1)\n","        dim_conv1_out = dim_conv1_out/2\n","\n","        dim_conv2_out = int((dim_conv1_out - self.conv1d_kernels[1])/(self.strides[1])+1)\n","\n","        self.linear1 = nn.Linear(self.hid_channels[1]*dim_conv2_out, self.ffn_layer_size, bias=self.Bias)\n","        self.linear2 = nn.Linear(self.ffn_layer_size, self.num_class, bias=self.Bias)\n","\n","        if mlp_act_fun == 'ReLu':\n","            self.mlp_act_fun = F.relu\n","        self.soft_fun = F.softmax\n","        self.dropout_linear1 = nn.Dropout(p=dropout_rate)\n","\n","\n","    def forward(self, sortpooled_embedings, graph_sizes):\n","\n","        to_conv1d_1 = sortpooled_embedings.view((-1, 1, self.dgcnn_k * self.node_feat_size))\n","\n","        conv1d_1_res = self.conv1d_1(to_conv1d_1)\n","        output_conv1d_1 = self.mlp_act_fun(conv1d_1_res)\n","\n","        maxpooled_output_conv1d_1 = self.maxpool1d(output_conv1d_1)\n","\n","        conv1d_2_res = self.conv1d_2(maxpooled_output_conv1d_1)\n","        output_conv1d_2 = self.mlp_act_fun(conv1d_2_res)\n","\n","        all_but_last_two_dims = output_conv1d_2.size()[:-2]\n","\n","        to_dense = output_conv1d_2.view(*all_but_last_two_dims, 1, -1)\n","        to_dense = torch.squeeze(to_dense, 1)\n","\n","        ffn_1 = self.linear1(to_dense)\n","        ffn_1 = self.mlp_act_fun(ffn_1)\n","\n","        dropout_ffn_1 = self.dropout_linear1(ffn_1)\n","\n","        ffn_2 = self.linear2(dropout_ffn_1)\n","        softmaxed_ffn_2 = self.soft_fun(ffn_2, dim=1)\n","\n","        return output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, ffn_1, dropout_ffn_1, ffn_2, softmaxed_ffn_2\n"],"metadata":{"id":"631sSqhYntN-","executionInfo":{"status":"ok","timestamp":1713310133694,"user_tz":-120,"elapsed":213,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["layers = MLP_DGCNN(node_feat_size=7, num_class=2, mlp_act_fun='ReLu', dropout_rate=0.5, Bias=False, dgcnn_k=17,\n","                   hid_channels=[16,32], conv1d_kernels=[2,5], ffn_layer_size=128, strides=[2,1])"],"metadata":{"id":"4azyOAL1mKuU","executionInfo":{"status":"ok","timestamp":1713310140917,"user_tz":-120,"elapsed":207,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":116,"outputs":[]},{"cell_type":"code","source":["for i,batch in enumerate(dataset):\n","    #print(batch)\n","\n","    Output_of_GNN_Layers = dgcnn_layers_example(batch, None)\n","    #print(\"here:\", len(Output_of_GNN_Layers), Output_of_GNN_Layers[0].size())\n","    output_of_sortpooling = sortpooling_exaple(Output_of_GNN_Layers, batch)\n","    #print(\"output_of_sortpooling: \", output_of_sortpooling.size())\n","    #print(Output_of_GNN_Layers.requires_grad)\n","    if batch.batch is not None:\n","        graph_sizes = [len(batch[i].x) for i in range(len(batch))]\n","    else:\n","        graph_sizes = [len(batch.x)]\n","    output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, ffn_1, dropout_ffn_1, ffn_2, softmaxed_ffn_2 = layers(output_of_sortpooling, graph_sizes)"],"metadata":{"id":"uVXgdVeCQ54i","executionInfo":{"status":"ok","timestamp":1713310143386,"user_tz":-120,"elapsed":770,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":117,"outputs":[]},{"cell_type":"code","source":["\n","#from torch_geometric.typing import torch_sparse\n","graph = dataset[0]\n","#adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(graph.edge_index).todense())\n","#identity_sized_adjacency_matrix = torch.eye(len(adjacency_matrix))\n","\n","#tilda_adjacency_matrix = adjacency_matrix + identity_sized_adjacency_matrix\n","tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(graph.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(graph.edge_index).todense())))\n","tilda_adjacency_matrix = tilda_adjacency_matrix.type(torch.float32)\n","\n","\n","tilda_degree_vector = torch.sum(tilda_adjacency_matrix, dim=1)\n","\n","k = tilda_degree_vector.size(0)\n","\n","tilda_degree_matrix = torch.zeros(k, k)\n","tilda_degree_matrix.as_strided([k], [k + 1]).copy_(tilda_degree_vector)\n","tilda_degree_matrix = tilda_degree_matrix.to(torch.float32)\n","\n","input_tensor = graph.x.to(torch.float32)\n","\n","ones_matrix = torch.ones_like(tilda_degree_matrix)\n","\n","reciprocal_tilda_degree_matrix = ones_matrix.div(tilda_degree_matrix)\n","reciprocal_tilda_degree_matrix = torch.nan_to_num(reciprocal_tilda_degree_matrix, nan=0, posinf=0, neginf=0)\n","\n","#node_degs = torch.transpose(torch.sum(tilda_adjacency_matrix, dim=0, keepdim=True).add(1), 0, 1)\n","#print(node_degs)\n","layer = GraphConvolutionLayer_DGCNN(7,7)\n","output = layer(input_tensor, tilda_adjacency_matrix, reciprocal_tilda_degree_matrix)\n","print(\"final output:\", output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"_JMyuJJqlKWL","executionInfo":{"status":"error","timestamp":1677606047245,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"b64b9dcc-e41a-407b-88e6-c07fd4ff8e01"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-85-01aca01533da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#node_degs = torch.transpose(torch.sum(tilda_adjacency_matrix, dim=0, keepdim=True).add(1), 0, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#print(node_degs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConvolutionLayer_DGCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtilda_adjacency_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreciprocal_tilda_degree_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"final output:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'GraphConvolutionLayer_DGCNN' is not defined"]}]},{"cell_type":"code","source":["a = [[1, 2, 3], [4, 5], [6, 7, 8, 9,5]]\n","import numpy as np\n","b = np.zeros([len(a),len(max(a,key = lambda x: len(x)))])\n","print(b)\n","for i,j in enumerate(a):\n","    b[i][0:len(j)] = j\n","\n","\n","t = torch.tensor([[2., 2., 2., 2.],\n","                  [2., 2., 2., 2.],\n","                  [2., 2., 2., 2.]])\n","sm = F.softmax\n","\n","t[0:1,0:4] = 1\n","t[2:3,0:4] = 3\n","print(t)\n","print(sm(t, dim=1))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzUwrrGRdYIr","executionInfo":{"status":"ok","timestamp":1677607554468,"user_tz":-60,"elapsed":255,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"3187ecf6-1ae4-4b11-9d73-460f50266bea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0.]]\n","tensor([[1., 1., 1., 1.],\n","        [2., 2., 2., 2.],\n","        [3., 3., 3., 3.]])\n","tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n","        [0.2500, 0.2500, 0.2500, 0.2500],\n","        [0.2500, 0.2500, 0.2500, 0.2500]])\n"]}]},{"cell_type":"code","source":["#from IPython.core.display import deepcopy\n","#from __future__ import print_function\n","\n","\n","\n","\n","#sortpooling_example = SortPooling(32, 7)\n","#test_list = [[5, 7, 8], [9, 10, 3],\n","#             [10, 18, 3], [0, 3, 5]]\n","#out = sortedpool([dataset[0].x])\n","#print(out)"],"metadata":{"id":"y9-n_sOfvQlT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#[32, 32, 32, 7]\n","for batch_graphs in batched_dataset:\n","    graph_sizes = [len(batch_graphs[i].x) for i in range(len(batch_graphs))]\n","    print(graph_sizes)\n","    softed = sortpooling_example(batch_graphs, graph_sizes)\n","    print(\"softmax: \", softmaxed_h2)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":259},"id":"cQIxcMFLYUo0","executionInfo":{"status":"error","timestamp":1693494576624,"user_tz":-120,"elapsed":351,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"e2ccd7f7-32fc-44bc-d37d-0cdc72457aff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[17, 13, 13, 19, 11, 28, 16, 20, 12, 17, 17, 20, 22, 13, 19, 22, 11, 17, 13, 18]\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-ce514c026504>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgraph_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msofted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msortpooling_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmaxed_h2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'sortpooling_example' is not defined"]}]},{"cell_type":"code","source":["#sortedpool = SortPooling(2)"],"metadata":{"id":"371_-TdK7SG4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test_list = [[5, 7, 8], [9, 10, 3],\n","#             [10, 18, 3], [0, 3, 5]]\n","#out = sortedpool([dataset[0].x])\n","#print(out)"],"metadata":{"id":"v8kNRG7j7dlQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import math\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","from torch_geometric.utils.convert import to_scipy_sparse_matrix\n","#from torch_geometric.utils.train_test_split_edges import torch_geometric\n","import networkx as nx\n","import numpy as np\n","from torch_geometric.nn import GCNConv\n","import sys\n","from torch_geometric.datasets import TUDataset\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","#import matrix_util as Mat_Util\n","#import DGCNN_layer as dgcnn_layer\n","#import DGCNN_GNN_Layers as dgcnn_gnn_layers\n","#import SortPooling_Layer as sortpooling_layer\n","#import MLP_DGCNN as mlp_dgcnn\n","\n","class GlobalMeanPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return gnn.global_mean_pool(x, batch)\n","################################################################################\n","class IdenticalPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return x\n","\n","################################################################################\n","class DGCNN_Model(nn.Module):\n","    '''\n","        DGCNN Layers using sparse adjacency matrix\n","    '''\n","    def __init__(self, GNN_layers, mlp_act_fun, dgcnn_act_fun, mlp_dropout_rate, Weight_Initializer, Bias, num_classes, dgcnn_k,\n","                 node_feat_size, hid_channels, conv1d_kernels, ffn_layer_size, strides):\n","\n","        super(DGCNN_Model, self).__init__()\n","        self.GNN_layers = GNN_layers\n","        self.output_dim = GNN_layers[-1]\n","        self.num_GNN_layers = len(GNN_layers)\n","        self.mlp_dropout_rate = mlp_dropout_rate\n","        self.Bias = Bias\n","        self.Weight_Initializer = Weight_Initializer\n","        self.dgcnn_k = dgcnn_k\n","        self.node_feat_size = node_feat_size\n","        self.num_classes = num_classes\n","        self.hid_channels = hid_channels\n","        self.conv1d_kernels = conv1d_kernels\n","        self.ffn_layer_size = ffn_layer_size\n","        self.strides = strides\n","\n","        self.gnn_layers = dgcnn_gnn_layers(GNN_layers=[32, 32, 32, 7], node_feat_size=self.node_feat_size,\n","                                                            Bias=self.Bias, dgcnn_act_fun=dgcnn_act_fun)\n","\n","        self.sort_pool = SortPooling_updated(self.dgcnn_k, node_feat_size=self.node_feat_size)\n","\n","        self.classic_conv = MLP_DGCNN(num_class=self.num_classes, node_feat_size=self.node_feat_size,\n","                                                mlp_act_fun=mlp_act_fun, dropout_rate=self.mlp_dropout_rate,\n","                                                hid_channels=self.hid_channels, conv1d_kernels=self.conv1d_kernels,\n","                                                dgcnn_k=self.dgcnn_k, ffn_layer_size=self.ffn_layer_size, Bias=self.Bias,\n","                                                strides=self.strides)\n","        if dgcnn_act_fun == 'ReLu':\n","            self.dgcnn_act_fun = F.relu\n","            print('ReLu is Selected.')\n","        elif dgcnn_act_fun == 'eLu':\n","            self.dgcnn_act_fun = nn.functional.elu\n","            print('eLu is Selected.')\n","        elif dgcnn_act_fun == 'tanh':\n","            self.dgcnn_act_fun = torch.tanh\n","            print('tanh is Selected.')\n","\n","\n","\n","        mean = 0\n","        std = 0.1\n","        #self.initialize_weights(Weight_Initializer, Bias, mean, std)\n","\n","\n","    def initialize_weights(model, Weight_Initializer, Bias, mean, std):\n","        # 1. Xavier Normal_.  2. Kaiming Normal_.  3. Uniform (0,0.1std)\n","        if Weight_Initializer == 1:                                             #.      1. Xavier Normal_.\n","            for i,layers in enumerate(model.children()):\n","                if isinstance(layers, dgcnn_gnn_layers.dgcnn_gnn_layers):\n","                    for j, layer in enumerate(layers.modules()):\n","                        if isinstance(layer, nn.Linear):\n","                            torch.nn.init.xavier_normal_(layer.weight.data)\n","                            if Bias:\n","                                layer.bias.data.zero_()\n","                        if isinstance(layer, dgcnn_layer.GNN_DGCNN):\n","                            torch.nn.init.xavier_normal_(layer.conv_params.weight)\n","                            if Bias:\n","                                layer.conv_params.bias.data.zero_()\n","                        else:\n","                            pass\n","                if isinstance(layers, torch.nn.Linear):\n","                    torch.nn.init.xavier_normal_(layers.weight)\n","                    if Bias:\n","                        layers.bias.data.zero_()\n","                if isinstance(layers, (mlp_dgcnn.MLP_DGCNN)):\n","                    torch.nn.init.xavier_normal_(layers.conv1d_1.weight)\n","                    torch.nn.init.xavier_normal_(layers.conv1d_2.weight)\n","                    torch.nn.init.xavier_normal_(layers.linear1.weight)\n","                    torch.nn.init.xavier_normal_(layers.linear2.weight)\n","\n","                elif isinstance(layers, (GlobalMeanPool)):\n","                    pass\n","                elif isinstance(layers, (IdenticalPool)):\n","                    pass\n","\n","        if Weight_Initializer == 2:                                             #.      2. Kaiming Normal_.\n","            for i,layers in enumerate(model.children()):\n","                if isinstance(layers, dgcnn_gnn_layers.dgcnn_gnn_layers):\n","                    for j, layer in enumerate(layers.modules()):\n","                        if isinstance(layer, nn.Linear):\n","                            torch.nn.init.kaiming_normal_(layer.weight.data)\n","                            if Bias:\n","                                layer.bias.data.zero_()\n","                        if isinstance(layer, dgcnn_layer.GNN_DGCNN):\n","                            torch.nn.init.kaiming_normal_(layer.conv_params.weight)\n","                            if Bias:\n","                                layer.conv_params.bias.data.zero_()\n","                        else:\n","                            pass\n","                if isinstance(layers, torch.nn.Linear):\n","                    torch.nn.init.kaiming_normal_(layers.weight)\n","                    if Bias:\n","                        layers.bias.data.zero_()\n","                if isinstance(layers, (mlp_dgcnn.MLP_DGCNN)):\n","                    torch.nn.init.kaiming_normal_(layers.conv1d_1.weight)\n","                    torch.nn.init.kaiming_normal_(layers.conv1d_2.weight)\n","                    torch.nn.init.kaiming_normal_(layers.linear1.weight)\n","                    torch.nn.init.kaiming_normal_(layers.linear2.weight)\n","\n","                elif isinstance(layers, (GlobalMeanPool)):\n","                    pass\n","                elif isinstance(layers, (IdenticalPool)):\n","                    pass\n","\n","        if Weight_Initializer == 3:                                             #.      3. Uniform (0,0.1std)\n","            for i,layers in enumerate(model.children()):\n","                if isinstance(layers, dgcnn_gnn_layers.dgcnn_gnn_layers):\n","                    for j, layer in enumerate(layers.modules()):\n","                        #print(\"here2\")\n","                        if isinstance(layer, nn.Linear):\n","                            torch.nn.init.normal_(layer.weight.data, mean, std)\n","                            if Bias:\n","                                layer.bias.data.zero_()\n","                        if isinstance(layer, dgcnn_layer.GNN_DGCNN):\n","                            torch.nn.init.normal_(layer.conv_params.weight, mean, std)\n","                            if Bias:\n","                                layer.conv_params.bias.data.zero_()\n","                        else:\n","                            pass\n","                if isinstance(layers, torch.nn.Linear):\n","                    torch.nn.init.normal_(layers.weight, mean, std)\n","                    if Bias:\n","                        layers.bias.data.zero_()\n","                if isinstance(layers, (mlp_dgcnn.MLP_DGCNN)):\n","                    torch.nn.init.normal_(layers.conv1d_1.weight, mean, std)\n","                    torch.nn.init.normal_(layers.conv1d_2.weight, mean, std)\n","                    torch.nn.init.normal_(layers.linear1.weight, mean, std)\n","                    torch.nn.init.normal_(layers.linear2.weight, mean, std)\n","                elif isinstance(layers, (GlobalMeanPool)):\n","                    pass\n","                elif isinstance(layers, (IdenticalPool)):\n","                    pass\n","\n","\n","    def forward(self, graph, edge_mask):\n","\n","        if graph.batch is not None:\n","            graph_sizes = [len(graph[i].x) for i in range(len(graph))]\n","        else:\n","            graph_sizes = [len(graph.x)]\n","\n","\n","        Output_of_GNN_Layers = self.gnn_layers(graph, edge_mask)\n","\n","\n","\n","        Output_of_GNN_Layers.retain_grad()\n","\n","\n","        sortpooled_embedings = self.sort_pool(output_of_dgcnn_layer=Output_of_GNN_Layers, batch_graphs=graph)\n","\n","        sortpooled_embedings.retain_grad()\n","\n","\n","        output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, ffn_1, dropout_ffn_1, ffn_2, softmaxed_ffn_2 = self.classic_conv(sortpooled_embedings=sortpooled_embedings, graph_sizes=graph_sizes)\n","\n","        return Output_of_GNN_Layers, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, ffn_1, dropout_ffn_1, ffn_2, softmaxed_ffn_2\n","\n","\n","\n","\n","\n","node_feat_size = len(dataset[0].x[0])\n","k=20\n","dgcnn_model_example = DGCNN_Model(GNN_layers=[32, 32, 32, 7], num_classes=2, mlp_act_fun='ReLu', dgcnn_act_fun='tanh',\n","                                  mlp_dropout_rate=0.5, Weight_Initializer=2, Bias=False, dgcnn_k=k, node_feat_size=node_feat_size,\n","                                  hid_channels=[16,32], conv1d_kernels=[2,5], ffn_layer_size=128, strides=[2,1])\n"],"metadata":{"id":"E-2sfO4z0MQZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713310185790,"user_tz":-120,"elapsed":8,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"e641cef6-1ae6-4e3c-a60f-2c1d348e98a2"},"execution_count":119,"outputs":[{"output_type":"stream","name":"stdout","text":["tanh is Selected.\n","tanh is Selected.\n"]}]},{"cell_type":"code","source":["import sys\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/'\n","sys.path.insert(0,py_path)"],"metadata":{"id":"BK3XQVjfEuGB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import DGCNN as dgcnn_model\n","reload(dgcnn_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iryEhuG0EaYt","executionInfo":{"status":"ok","timestamp":1694645824512,"user_tz":-120,"elapsed":536,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"2e125f39-b7bc-4b5b-ee81-16b9179102be"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'DGCNN' from '/content/drive/MyDrive/Explainability Methods/Models/Script/DGCNN.py'>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["dgcnn_model_example = dgcnn_model.DGCNN_Model(GNN_layers=[32, 32, 32, 7], num_classes=2, mlp_act_fun='ReLu', dgcnn_act_fun='tanh',\n","                                              mlp_dropout_rate=0.5, Weight_Initializer=2, Bias=True, dgcnn_k=17, node_feat_size=7,\n","                                              hid_channels=[16,32], conv1d_kernels=[2,5], ffn_layer_size=128, strides=[2,1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jOLa_KozEzVj","executionInfo":{"status":"ok","timestamp":1694645825264,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"ced7ab80-5efa-4c3f-bd52-b6ef92bce68d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tanh is Selected.\n","tanh is Selected.\n"]}]},{"cell_type":"code","source":["GNN_Model_optimizer = torch.optim.Adam(dgcnn_model_example.parameters(), lr=0.01, weight_decay=1e-4)"],"metadata":{"id":"3nI5OPDaGjT0","executionInfo":{"status":"ok","timestamp":1713310218336,"user_tz":-120,"elapsed":238,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":["## **Train to check**"],"metadata":{"id":"ubJngAv1FSvh"}},{"cell_type":"code","source":["from torch_geometric.loader import DataLoader\n","dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n","BATCH_SIZE = 64\n","size_of_hidden_layers = 7\n","\n","batched_dataset = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"],"metadata":{"id":"8sX8I4jfFVX4","executionInfo":{"status":"ok","timestamp":1713310202631,"user_tz":-120,"elapsed":201,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.CrossEntropyLoss()\n","def loss_calculations(preds, gtruth):\n","    loss_per_epoch = criterion(preds, gtruth)\n","    return loss_per_epoch\n"],"metadata":{"id":"xxOnKmnvFeUb","executionInfo":{"status":"ok","timestamp":1713310205391,"user_tz":-120,"elapsed":2,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["def train_step():\n","    GNN_Model_loss_batch = []\n","    Pred_Labels = []\n","    Real_Labels = []\n","\n","    dgcnn_model_example.train()\n","    dgcnn_model_example.zero_grad()\n","    torch.autograd.set_detect_anomaly(True)\n","    for batch_of_graphs in batched_dataset:\n","\n","        final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, softmaxed_h2 = dgcnn_model_example(batch_of_graphs, None)\n","        batch_loss = loss_calculations(softmaxed_h2, batch_of_graphs.y)\n","\n","\n","        Pred_Labels.extend(softmaxed_h2.argmax(dim=1).detach().tolist())\n","        Real_Labels.extend(batch_of_graphs.y.detach().tolist())\n","        GNN_Model_loss_batch.append(batch_loss)\n","\n","        batch_loss.backward()\n","        GNN_Model_optimizer.step()\n","\n","    return torch.mean(torch.tensor(GNN_Model_loss_batch)), metrics.accuracy_score(Real_Labels, Pred_Labels)\n"],"metadata":{"id":"jqt-ygvgFhHE","executionInfo":{"status":"ok","timestamp":1713310206529,"user_tz":-120,"elapsed":240,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["#from IPython.display import Javascript  # Restrict height of output cell.\n","#display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","\n","SA_Model_training_time_per_epoch = []\n","SA_Model_training_Acc_per_epoch = []\n","\n","def train(EPOCHS, load_index):\n","    SA_training_loss_per_epoch = []\n","\n","    for epoch in range(EPOCHS):\n","\n","        start_generation = perf_counter()\n","        SA_model_training_loss, training_acc = train_step()\n","        SA_Model_training_time_per_epoch.append(perf_counter() - start_generation)\n","        SA_Model_training_Acc_per_epoch.append(training_acc)\n","\n","        print(f'Epoch: {epoch+1:03d}, Model Loss: {SA_model_training_loss:.4f} Accuracy: {training_acc}')\n","\n","        SA_training_loss_per_epoch.append(SA_model_training_loss)\n","\n","\n","        #if (epoch + load_index + 1) % Visualization_Parameter == 0 and epoch > 0:\n","        #    visualize_losses(SA_training_loss_per_epoch, epoch + load_index + 1)\n","        #if (epoch + load_index + 1) % Model_Saving_Parameter == 0 and epoch > 0:\n","        #    torch.save({'epoch': epoch+load_index+1, 'model_state_dict': GNN_Model.state_dict(), 'optimizer_state_dict': GNN_Model_optimizer.state_dict(), 'loss': SA_training_loss_per_epoch,}, \"/content/drive/My Drive/Explainability Methods/\" + str(Explainability_name) + \" on \" + str(Task_name) + \"/Model/\" + File_Name + str(epoch + load_index + 1)+\".pt\")\n","\n","\n","\n"],"metadata":{"id":"p_1B22-AFj_G","executionInfo":{"status":"ok","timestamp":1713310208392,"user_tz":-120,"elapsed":237,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":123,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 3\n","load_index = 0\n","if load_index != 0:\n","    model_GCN, optimizer, load_index = loading_model(load_index)\n","train(EPOCHS, load_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aqrAV-f1FriO","executionInfo":{"status":"ok","timestamp":1713310230077,"user_tz":-120,"elapsed":1765,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"8ae25305-8ea0-4cea-af30-93659dd11409"},"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 001, Model Loss: 0.6556 Accuracy: 0.5691489361702128\n","Epoch: 002, Model Loss: 0.6334 Accuracy: 0.6648936170212766\n","Epoch: 003, Model Loss: 0.5162 Accuracy: 0.8085106382978723\n"]}]},{"cell_type":"markdown","source":["## **check grads**"],"metadata":{"id":"P-P2E-rpFF7B"}},{"cell_type":"code","source":["def compute_grad(model, graph, with_respect):\n","\n","    final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, soft = model(graph, None)\n","    if with_respect == 1:\n","        loss = loss_calculations(soft, graph.y)\n","        #print(loss)\n","    elif with_respect == 2:\n","        loss = loss_calculations(soft, torch.tensor([0]))\n","        #print(loss)\n","    elif with_respect == 3:\n","        loss = loss_calculations(soft, torch.tensor([1]))\n","        #print(loss)\n","\n","    return torch.autograd.grad(loss, list(model.parameters()), allow_unused=True)\n","\n","def remove_nones(sample_grads):\n","    sample_grads2 = []\n","    for item in sample_grads:\n","        Each_Graph = []\n","        for item2 in item:\n","            if item2 != None:\n","                Each_Graph.append(torch.tensor(item2.clone().detach().requires_grad_(True), requires_grad=True))\n","            else:\n","                Each_Graph.append(torch.tensor(0))\n","        sample_grads2.append(Each_Graph)\n","    return sample_grads2\n","\n","def compute_sample_grads(model, test_dataset, with_respect):\n","\n","    sample_grads = [compute_grad(model, graph, with_respect) for graph in test_dataset]\n","\n","    sample_grads = remove_nones(sample_grads)\n","    sample_grads = zip(*sample_grads)\n","    sample_grads = [torch.stack(shards) for shards in sample_grads]\n","\n","    return sample_grads\n","\n","per_sample_grads_wrt_class_one = compute_sample_grads(dgcnn_model_example, [dataset[0]], 3)\n","per_sample_grads_wrt_class_zero = compute_sample_grads(dgcnn_model_example, [dataset[0]], 2)\n","per_sample_grads_wrt_graph_label = compute_sample_grads(dgcnn_model_example, [dataset[0]], 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_qhM_nELAXrR","executionInfo":{"status":"ok","timestamp":1694645899597,"user_tz":-120,"elapsed":621,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"d387aa55-5e4a-4c22-ca00-e41fa2c2a13d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-99ef7ecbecd5>:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  Each_Graph.append(torch.tensor(item2.clone().detach().requires_grad_(True), requires_grad=True))\n"]}]},{"cell_type":"code","source":["print(len(per_sample_grads_wrt_class_one))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10-DC4Oucvib","executionInfo":{"status":"ok","timestamp":1694645903185,"user_tz":-120,"elapsed":251,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"c2fa96f3-c684-4302-c7c3-65d7e8ce83ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["16\n"]}]},{"cell_type":"code","source":["print(per_sample_grads_wrt_class_one)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMhy2wzwd9Fm","executionInfo":{"status":"ok","timestamp":1694645904336,"user_tz":-120,"elapsed":4,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"4b54dbd6-ecd9-4bbd-da7e-bd9afa7ef5a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([[[0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0.]]], grad_fn=<StackBackward0>), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<StackBackward0>), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<StackBackward0>), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<StackBackward0>), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<StackBackward0>), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<StackBackward0>), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0.]]], grad_fn=<StackBackward0>), tensor([[0., 0., 0., 0., 0., 0., 0.]], grad_fn=<StackBackward0>), tensor([[[[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]],\n","\n","         [[0., 0.]]]], grad_fn=<StackBackward0>), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","       grad_fn=<StackBackward0>), tensor([[[[0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.]],\n","\n","         [[0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.]],\n","\n","         [[0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.]],\n","\n","         ...,\n","\n","         [[0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.]],\n","\n","         [[0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.]],\n","\n","         [[0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.],\n","          [0., 0., 0., 0., 0.]]]], grad_fn=<StackBackward0>), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<StackBackward0>), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<StackBackward0>), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<StackBackward0>), tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6052e-45, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0829e-44, 6.0256e-44,\n","          3.0829e-44, 0.0000e+00, 1.4013e-45, 0.0000e+00, 6.8664e-44,\n","          0.0000e+00, 7.0065e-45, 1.4013e-45, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 5.6052e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          6.7262e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8664e-44,\n","          3.2230e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          6.7262e-44, 0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00,\n","          7.0065e-44, 0.0000e+00, 6.5861e-44, 3.0829e-44, 0.0000e+00,\n","          0.0000e+00, 4.9045e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          1.4013e-44, 0.0000e+00, 0.0000e+00, 1.4013e-45, 0.0000e+00,\n","          0.0000e+00, 3.2230e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3631e-44,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2612e-44, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 2.8026e-44, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 3.3631e-44, 6.8664e-44, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0829e-44, 2.8026e-45,\n","          0.0000e+00, 4.6243e-44, 0.0000e+00],\n","         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","          0.0000e+00, 0.0000e+00, 0.0000e+00]]], grad_fn=<StackBackward0>), tensor([[1.4013e-45, 0.0000e+00]], grad_fn=<StackBackward0>)]\n"]}]},{"cell_type":"code","source":["for p in dgcnn_model_example.parameters():\n","    print(p.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMp0YDUbHNWm","executionInfo":{"status":"ok","timestamp":1694645931114,"user_tz":-120,"elapsed":255,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"136ed705-7456-42cb-b63e-5475436754f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-2.3054e-12, -2.2559e-12, -2.7526e-12,  1.9104e-20, -4.3428e-32,\n","          2.6479e-26,  0.0000e+00],\n","        [ 4.1306e-12,  4.5618e-12,  5.5606e-12, -3.2547e-20,  7.9759e-32,\n","         -4.7281e-26,  0.0000e+00],\n","        [-3.4390e-12, -4.2794e-12, -5.2468e-12,  2.5296e-20, -6.4087e-32,\n","          4.0355e-26,  0.0000e+00],\n","        [-7.4334e-12, -8.8228e-12, -1.0814e-11,  6.0219e-20, -1.4083e-31,\n","          8.1337e-26,  0.0000e+00],\n","        [-3.5135e-12, -3.5920e-12, -4.3334e-12,  2.9667e-20, -6.1338e-32,\n","          3.8073e-26,  0.0000e+00],\n","        [-2.0913e-12, -2.3918e-12, -2.9663e-12,  1.6003e-20, -2.8588e-32,\n","          2.4334e-26,  0.0000e+00],\n","        [-8.6118e-12, -9.0746e-12, -1.0981e-11,  7.0795e-20, -1.4947e-31,\n","          9.2818e-26,  0.0000e+00],\n","        [-5.3819e-12, -5.8601e-12, -7.1126e-12,  4.6427e-20, -9.3636e-32,\n","          6.1674e-26,  0.0000e+00],\n","        [ 1.0522e-11,  1.0711e-11,  1.2929e-11, -8.7515e-20,  1.8070e-31,\n","         -1.1488e-25,  0.0000e+00],\n","        [ 5.6290e-12,  5.9928e-12,  7.3063e-12, -4.4794e-20,  1.0181e-31,\n","         -6.1903e-26,  0.0000e+00],\n","        [-8.1670e-12, -8.7568e-12, -1.0566e-11,  7.2144e-20, -1.4410e-31,\n","          9.1342e-26,  0.0000e+00],\n","        [-6.3157e-12, -6.8213e-12, -8.2619e-12,  5.9755e-20, -1.1061e-31,\n","          6.9778e-26,  0.0000e+00],\n","        [-1.0641e-11, -1.1620e-11, -1.4132e-11,  8.9418e-20, -1.9113e-31,\n","          1.1988e-25,  0.0000e+00],\n","        [-5.9747e-12, -5.9683e-12, -7.2382e-12,  5.1245e-20, -1.2211e-31,\n","          6.3537e-26,  0.0000e+00],\n","        [-2.9334e-13, -9.9100e-14, -8.0865e-14,  5.7556e-21, -4.4983e-34,\n","          9.4901e-28,  0.0000e+00],\n","        [ 1.1510e-11,  1.3547e-11,  1.6454e-11, -1.0100e-19,  1.9216e-31,\n","         -1.2882e-25,  0.0000e+00],\n","        [-8.7333e-12, -9.3676e-12, -1.1385e-11,  6.9135e-20, -1.5115e-31,\n","          9.8019e-26,  0.0000e+00],\n","        [-4.7008e-12, -4.0859e-12, -4.8513e-12,  3.8550e-20, -7.7507e-32,\n","          4.7771e-26,  0.0000e+00],\n","        [ 5.9779e-12,  5.9617e-12,  7.1990e-12, -5.0787e-20,  1.1192e-31,\n","         -6.7290e-26,  0.0000e+00],\n","        [ 2.2316e-12,  1.5171e-12,  1.7189e-12, -2.0338e-20,  4.3126e-32,\n","         -2.0348e-26,  0.0000e+00],\n","        [ 7.2396e-12,  6.9405e-12,  8.3250e-12, -6.1132e-20,  1.2602e-31,\n","         -7.7555e-26,  0.0000e+00],\n","        [-1.5350e-12, -1.3155e-12, -1.5601e-12,  1.3523e-20, -2.2450e-32,\n","          1.6656e-26,  0.0000e+00],\n","        [-1.2983e-12, -1.3327e-12, -1.6072e-12,  9.6644e-21, -2.6260e-32,\n","          1.4732e-26,  0.0000e+00],\n","        [-9.1227e-12, -9.9586e-12, -1.2042e-11,  7.5452e-20, -1.5424e-31,\n","          1.0436e-25,  0.0000e+00],\n","        [-7.3457e-12, -7.5419e-12, -9.1161e-12,  5.9931e-20, -1.2525e-31,\n","          7.6018e-26,  0.0000e+00],\n","        [-5.5373e-12, -5.5325e-12, -6.6950e-12,  4.3764e-20, -8.8238e-32,\n","          5.8407e-26,  0.0000e+00],\n","        [-5.9880e-12, -5.8317e-12, -7.0341e-12,  5.2885e-20, -1.0343e-31,\n","          6.3779e-26,  0.0000e+00],\n","        [-1.3384e-11, -1.3263e-11, -1.6052e-11,  1.1148e-19, -2.1697e-31,\n","          1.4114e-25,  0.0000e+00],\n","        [-9.6373e-12, -1.0419e-11, -1.2669e-11,  7.8015e-20, -1.6431e-31,\n","          1.0890e-25,  0.0000e+00],\n","        [-3.5626e-12, -3.3806e-12, -4.0343e-12,  3.0830e-20, -5.6664e-32,\n","          3.5374e-26,  0.0000e+00],\n","        [-1.6634e-12, -1.6779e-12, -2.0365e-12,  1.2618e-20, -3.1111e-32,\n","          1.9293e-26,  0.0000e+00],\n","        [ 6.8078e-12,  7.4948e-12,  9.0846e-12, -5.5296e-20,  1.1418e-31,\n","         -7.4604e-26,  0.0000e+00]])\n","tensor([-2.9227e-12,  5.6552e-12, -5.1367e-12, -1.0721e-11, -4.5328e-12,\n","        -3.0190e-12, -1.1410e-11, -7.3631e-12,  1.3572e-11,  7.4680e-12,\n","        -1.0883e-11, -8.4878e-12, -1.4468e-11, -7.4959e-12, -1.7688e-13,\n","         1.6488e-11, -1.1740e-11, -5.3722e-12,  7.5616e-12,  2.0901e-12,\n","         8.8695e-12, -1.6969e-12, -1.6737e-12, -1.2323e-11, -9.5152e-12,\n","        -7.1267e-12, -7.4557e-12, -1.6899e-11, -1.3019e-11, -4.3580e-12,\n","        -2.1886e-12,  9.3256e-12])\n","tensor([[-4.1953e-12,  4.9590e-12, -4.6384e-13,  ...,  2.7433e-12,\n","         -6.5026e-12,  4.0715e-12],\n","        [ 2.3103e-12, -2.7811e-12,  4.6367e-13,  ..., -1.3330e-12,\n","          3.7358e-12, -2.4613e-12],\n","        [ 2.6744e-12, -3.1204e-12,  1.2568e-13,  ..., -1.8944e-12,\n","          4.0175e-12, -2.4163e-12],\n","        ...,\n","        [-1.4284e-12,  1.7052e-12, -2.4456e-13,  ...,  8.4141e-13,\n","         -2.3270e-12,  1.4987e-12],\n","        [-4.7160e-12,  5.6210e-12, -7.3583e-13,  ...,  2.8916e-12,\n","         -7.4868e-12,  4.8092e-12],\n","        [-4.9148e-12,  5.8268e-12, -7.0079e-13,  ...,  3.0477e-12,\n","         -7.7922e-12,  4.9569e-12]])\n","tensor([ 1.1553e-11, -6.4411e-12, -7.3105e-12, -1.0342e-12,  1.4965e-12,\n","        -1.6902e-12,  1.3793e-11,  6.8014e-13,  6.1852e-12, -1.0723e-11,\n","         2.9263e-12, -9.3721e-12, -6.1798e-12,  5.0200e-12, -4.8694e-12,\n","        -1.3864e-12, -4.5489e-12,  1.6893e-11,  1.0143e-11, -1.4187e-12,\n","         3.6331e-12,  1.5929e-11, -1.1541e-11, -1.4613e-11, -4.3399e-12,\n","        -4.7386e-12,  3.5328e-12, -4.7800e-12,  1.0868e-11,  4.0885e-12,\n","         1.3112e-11,  1.3764e-11])\n","tensor([[ 4.3588e-13, -1.2068e-12, -2.9153e-12,  ...,  9.2912e-13,\n","          1.1180e-12,  1.4573e-12],\n","        [-2.2191e-12,  2.9088e-12,  5.8208e-12,  ..., -5.0605e-13,\n","         -3.1719e-12, -3.6794e-12],\n","        [-8.4940e-13,  8.0920e-13,  1.3791e-12,  ...,  2.1640e-13,\n","         -9.9676e-13, -1.0421e-12],\n","        ...,\n","        [-7.9097e-13,  6.9349e-13,  1.1944e-12,  ...,  2.4713e-13,\n","         -9.0578e-13, -9.2283e-13],\n","        [ 9.4181e-13, -1.0572e-12, -1.9602e-12,  ..., -2.3445e-14,\n","          1.2017e-12,  1.3533e-12],\n","        [-1.4742e-12,  2.5104e-12,  5.4523e-12,  ..., -1.0758e-12,\n","         -2.5539e-12, -3.1018e-12]])\n","tensor([ 5.7596e-12, -1.0253e-11, -2.1631e-12, -1.2053e-12,  3.4472e-12,\n","        -6.4646e-12,  4.5901e-12,  8.7861e-12, -1.1871e-11, -5.2038e-12,\n","         4.4028e-12, -1.2757e-11,  1.3202e-11, -1.2672e-12,  8.2731e-12,\n","        -3.8486e-12, -8.7424e-12,  8.5047e-12,  7.5142e-12,  9.4526e-12,\n","         4.0247e-12, -6.7989e-12, -1.4631e-11,  5.5055e-12,  1.8467e-12,\n","         1.0023e-11, -2.9832e-12,  9.8906e-12, -1.0994e-12, -1.9298e-12,\n","         3.2617e-12, -1.0166e-11])\n","tensor([[-7.8625e-13,  6.0188e-13, -7.1278e-13,  9.8209e-14,  4.5035e-13,\n","          8.7195e-13, -8.2519e-13, -6.2731e-13,  6.9590e-13, -4.2101e-13,\n","         -8.3989e-13,  8.0453e-13, -1.4326e-12, -7.0402e-13, -2.7741e-13,\n","         -3.7342e-13,  7.7388e-13, -3.3064e-13, -6.2724e-13, -7.7677e-13,\n","         -2.7344e-13,  5.1535e-13,  7.1935e-13, -1.4594e-13, -3.1673e-14,\n","         -9.3397e-13,  6.8142e-13, -7.7771e-13,  2.5108e-13,  8.8584e-14,\n","         -8.4580e-15,  7.2162e-13],\n","        [ 8.7574e-12, -1.7080e-11, -1.7733e-12, -1.6751e-12, -1.2739e-11,\n","         -1.3091e-11,  6.4403e-12,  1.0897e-11, -2.5931e-11,  8.1789e-12,\n","         -2.7958e-12, -2.7105e-11,  2.1912e-11,  1.0129e-11,  1.6604e-11,\n","         -3.6214e-13, -9.1930e-12,  8.5385e-12,  4.6256e-12,  1.6757e-11,\n","          1.0881e-11, -1.5410e-11, -1.3301e-11,  1.5625e-11, -5.8285e-12,\n","          3.1507e-11, -1.4617e-11,  1.8182e-11, -9.3018e-12, -6.4382e-12,\n","         -7.0131e-12, -1.6603e-11],\n","        [ 7.8410e-12, -1.5323e-11, -1.5761e-12, -1.5226e-12, -1.1384e-11,\n","         -1.1697e-11,  5.7567e-12,  9.7609e-12, -2.3190e-11,  7.3121e-12,\n","         -2.4960e-12, -2.4262e-11,  1.9544e-11,  9.0424e-12,  1.4859e-11,\n","         -3.0852e-13, -8.2416e-12,  7.6238e-12,  4.1960e-12,  1.5020e-11,\n","          9.7606e-12, -1.3820e-11, -1.1892e-11,  1.4034e-11, -5.2329e-12,\n","          2.8157e-11, -1.3081e-11,  1.6276e-11, -8.3342e-12, -5.7685e-12,\n","         -6.2227e-12, -1.4805e-11],\n","        [-7.6342e-12,  1.2433e-11, -9.8921e-13,  1.3925e-12,  9.0756e-12,\n","          1.0582e-11, -6.3778e-12, -8.5845e-12,  1.8072e-11, -6.1823e-12,\n","         -6.4354e-13,  1.9270e-11, -1.7781e-11, -8.2503e-12, -1.1088e-11,\n","         -8.8240e-13,  7.9537e-12, -6.2170e-12, -4.9106e-12, -1.2768e-11,\n","         -7.5943e-12,  1.1109e-11,  1.0299e-11, -1.0264e-11,  3.5861e-12,\n","         -2.2214e-11,  1.1014e-11, -1.3588e-11,  6.4931e-12,  4.2371e-12,\n","          4.0990e-12,  1.2199e-11],\n","        [-8.9790e-12,  1.7552e-11,  1.8064e-12,  1.7754e-12,  1.2956e-11,\n","          1.3329e-11, -6.5268e-12, -1.1146e-11,  2.6428e-11, -8.3477e-12,\n","          2.7928e-12,  2.7660e-11, -2.2303e-11, -1.0260e-11, -1.6930e-11,\n","          3.3498e-13,  9.4410e-12, -8.6307e-12, -4.8341e-12, -1.7157e-11,\n","         -1.1161e-11,  1.5807e-11,  1.3539e-11, -1.6078e-11,  5.9844e-12,\n","         -3.2081e-11,  1.4941e-11, -1.8547e-11,  9.5244e-12,  6.5792e-12,\n","          6.9899e-12,  1.6795e-11],\n","        [ 1.3390e-12, -9.6977e-14,  2.2797e-12, -1.3148e-13,  2.9277e-15,\n","         -1.2641e-12,  1.8358e-12,  7.6800e-13,  4.5009e-13,  3.2584e-13,\n","          2.6217e-12,  1.2429e-13,  2.2101e-12,  1.0885e-12, -7.9430e-13,\n","          1.1234e-12, -1.3404e-12,  1.8814e-13,  1.5137e-12,  7.3629e-13,\n","         -2.4685e-13, -2.1879e-15, -8.3076e-13, -1.0562e-12,  6.2995e-13,\n","         -2.6559e-13, -5.4836e-13,  5.8943e-13,  1.9584e-13,  3.8444e-13,\n","          7.8029e-13, -4.6448e-13],\n","        [-1.7898e-12,  3.8151e-12,  6.7674e-13,  3.1981e-13,  2.9884e-12,\n","          2.8461e-12, -1.3047e-12, -2.4012e-12,  6.0378e-12, -1.8365e-12,\n","          1.0851e-12,  6.2677e-12, -4.5954e-12, -2.2658e-12, -3.9671e-12,\n","          2.4339e-13,  1.8761e-12, -2.0445e-12, -8.2500e-13, -3.7268e-12,\n","         -2.5069e-12,  3.5072e-12,  2.9789e-12, -3.6584e-12,  1.4127e-12,\n","         -7.2913e-12,  3.2440e-12, -4.1436e-12,  2.1455e-12,  1.5482e-12,\n","          1.8879e-12,  3.8790e-12]])\n","tensor([-1.7956e-12,  3.5747e-11,  3.2289e-11, -2.3159e-11, -3.6286e-11,\n","        -1.8655e-12, -5.6840e-12])\n","tensor([[[-3.4976e-13, -4.5394e-13]],\n","\n","        [[ 1.9291e-14, -9.6222e-14]],\n","\n","        [[ 1.5922e-11,  1.8491e-11]],\n","\n","        [[-2.1134e-11, -2.4505e-11]],\n","\n","        [[ 8.0991e-12, -3.3204e-13]],\n","\n","        [[ 1.7507e-11,  1.4600e-11]],\n","\n","        [[ 2.3349e-11,  8.2382e-12]],\n","\n","        [[ 0.0000e+00,  0.0000e+00]],\n","\n","        [[-1.2347e-13,  2.9382e-14]],\n","\n","        [[ 0.0000e+00,  0.0000e+00]],\n","\n","        [[ 1.8113e-11, -7.3702e-12]],\n","\n","        [[ 4.5474e-13, -3.1501e-12]],\n","\n","        [[-2.8768e-11, -1.1123e-12]],\n","\n","        [[ 0.0000e+00,  0.0000e+00]],\n","\n","        [[-3.3111e-11, -6.3810e-12]],\n","\n","        [[-2.3453e-11, -2.0943e-11]]])\n","tensor([-1.0231e-12, -1.2456e-13,  1.9698e-10,  1.7042e-10,  2.6299e-11,\n","         2.1037e-10,  2.1850e-10,  0.0000e+00,  2.4086e-13,  0.0000e+00,\n","         1.7066e-10,  9.4931e-12,  1.8604e-10,  0.0000e+00,  2.1517e-10,\n","         1.6928e-10])\n","tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n","\n","        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n","\n","        [[-2.2856e-18,  0.0000e+00, -5.0957e-18,  0.0000e+00, -2.2781e-18],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [-1.4880e-17,  3.8068e-31, -1.3367e-17, -1.3377e-18, -1.4868e-17],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [-1.4714e-17, -1.5270e-17, -1.0849e-17, -1.9855e-17, -1.5254e-17],\n","         [-1.7146e-17, -2.0611e-17, -1.2859e-17, -1.9617e-17, -2.0606e-17]],\n","\n","        ...,\n","\n","        [[ 1.1105e-12,  1.2550e-12,  1.2222e-12,  6.5568e-13,  6.0930e-13],\n","         [ 2.5117e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 1.5032e-11,  1.7436e-11,  1.4855e-11,  1.4302e-11,  1.4735e-11],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 3.4663e-11,  3.2885e-11,  3.2271e-11,  3.2205e-11,  3.1193e-11],\n","         [ 4.6351e-11,  4.5207e-11,  4.4896e-11,  4.4439e-11,  4.3869e-11]],\n","\n","        [[-2.3399e-13, -7.4819e-14, -1.4064e-13, -8.2554e-14, -1.8793e-14],\n","         [-1.8751e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [-3.1849e-13,  4.3936e-13, -5.5213e-13,  1.2597e-13,  5.1062e-14],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 3.1800e-13,  8.9315e-14,  3.1690e-13,  1.2699e-13,  1.6825e-13],\n","         [ 6.5085e-13,  2.4420e-13,  4.6269e-13,  3.3420e-13,  3.8627e-13]],\n","\n","        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         ...,\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n","tensor([ 0.0000e+00,  0.0000e+00, -2.2555e-17,  9.7514e-11,  0.0000e+00,\n","         0.0000e+00, -1.9723e-14,  0.0000e+00, -9.2428e-15,  0.0000e+00,\n","         0.0000e+00,  9.1373e-11,  7.7744e-11,  0.0000e+00,  0.0000e+00,\n","         8.3914e-13,  0.0000e+00,  7.2332e-11,  0.0000e+00,  9.3119e-11,\n","         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.6350e-21, -1.9783e-13,\n","         9.8437e-11,  5.5963e-12,  2.1138e-14,  6.6304e-11,  6.2744e-11,\n","         7.1358e-13,  0.0000e+00])\n","tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]])\n","tensor([ 1.2264e-12,  0.0000e+00,  0.0000e+00,  4.9051e-12, -2.0898e-15,\n","         0.0000e+00,  0.0000e+00,  9.1707e-15, -3.2024e-12,  7.2767e-18,\n","         6.6300e-12,  0.0000e+00, -8.2033e-13,  0.0000e+00,  1.4223e-11,\n","         0.0000e+00,  5.1888e-13, -1.7676e-12,  0.0000e+00,  0.0000e+00,\n","         2.6295e-15,  0.0000e+00,  3.4436e-14,  9.5553e-25,  0.0000e+00,\n","         1.7021e-14,  0.0000e+00,  1.9205e-11,  0.0000e+00,  0.0000e+00,\n","         0.0000e+00,  4.5104e-15,  5.1843e-18,  0.0000e+00,  0.0000e+00,\n","         0.0000e+00,  7.5809e-15,  0.0000e+00,  0.0000e+00, -1.0372e-14,\n","        -1.3800e-15,  0.0000e+00,  1.1470e-16,  0.0000e+00, -4.1776e-14,\n","        -4.9289e-12,  0.0000e+00,  0.0000e+00,  1.3876e-13,  0.0000e+00,\n","        -1.4730e-14,  5.3318e-15, -4.2636e-14,  7.2046e-16,  0.0000e+00,\n","        -1.6160e-16,  0.0000e+00,  1.8154e-11, -4.6651e-14,  0.0000e+00,\n","         0.0000e+00,  1.6775e-13,  0.0000e+00,  0.0000e+00,  1.6432e-12,\n","        -1.7587e-13, -1.1681e-15,  1.4142e-17,  2.2092e-14,  0.0000e+00,\n","         0.0000e+00, -1.3791e-12,  0.0000e+00,  2.4359e-12,  3.7118e-14,\n","         0.0000e+00,  0.0000e+00, -2.0457e-13,  0.0000e+00, -4.2601e-16,\n","         0.0000e+00,  0.0000e+00, -2.3807e-13,  0.0000e+00,  0.0000e+00,\n","         0.0000e+00,  0.0000e+00,  1.4703e-12,  0.0000e+00, -4.1834e-14,\n","         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0158e-12, -1.8037e-17,\n","        -1.1465e-14,  0.0000e+00,  0.0000e+00, -6.1231e-16,  0.0000e+00,\n","         1.7239e-14,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","         2.3538e-12,  0.0000e+00,  9.8185e-12, -1.4961e-14,  0.0000e+00,\n","        -4.5453e-13, -1.1010e-14, -3.8307e-14,  0.0000e+00,  0.0000e+00,\n","         0.0000e+00, -3.0452e-13,  1.3808e-11,  0.0000e+00,  0.0000e+00,\n","         0.0000e+00,  1.2770e-16,  0.0000e+00, -3.2932e-15, -3.0032e-14,\n","         0.0000e+00, -4.2422e-14,  0.0000e+00])\n","tensor([[-1.0730e-11,  0.0000e+00,  0.0000e+00, -3.2482e-10,  4.4488e-12,\n","          0.0000e+00,  0.0000e+00, -2.9204e-11, -8.7204e-10, -6.8596e-16,\n","         -8.3788e-10,  0.0000e+00, -2.4150e-11,  0.0000e+00, -1.9691e-09,\n","          0.0000e+00, -4.0354e-10, -1.9828e-11,  0.0000e+00,  0.0000e+00,\n","          3.4341e-14,  0.0000e+00, -6.2400e-13, -1.3296e-24,  0.0000e+00,\n","         -9.2830e-15,  0.0000e+00, -1.8255e-09,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  1.3563e-14,  2.0592e-17,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  5.9729e-13,  0.0000e+00,  0.0000e+00,  4.0544e-12,\n","          1.5396e-13,  0.0000e+00,  2.9153e-17,  0.0000e+00,  3.7360e-12,\n","         -1.0245e-09,  0.0000e+00,  0.0000e+00, -2.7596e-11,  0.0000e+00,\n","          1.2401e-12, -1.3782e-13,  3.2962e-13,  3.4850e-13,  0.0000e+00,\n","          1.5809e-14,  0.0000e+00, -1.8703e-09, -1.5551e-11,  0.0000e+00,\n","          0.0000e+00,  2.6935e-11,  0.0000e+00,  0.0000e+00, -1.8219e-09,\n","         -6.2335e-12,  1.2147e-13,  2.9406e-16,  5.3229e-13,  0.0000e+00,\n","          0.0000e+00, -9.9568e-10,  0.0000e+00, -7.1211e-11,  4.0995e-13,\n","          0.0000e+00,  0.0000e+00, -1.6826e-14,  0.0000e+00,  2.1592e-14,\n","          0.0000e+00,  0.0000e+00,  2.8560e-11,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00, -5.7392e-12,  0.0000e+00,  3.0341e-12,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0162e-11,  5.1907e-15,\n","          2.5913e-12,  0.0000e+00,  0.0000e+00,  2.1030e-13,  0.0000e+00,\n","          7.7043e-14,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","         -3.8824e-11,  0.0000e+00, -8.3659e-10,  2.7472e-12,  0.0000e+00,\n","         -1.0168e-09,  1.8833e-11,  3.6024e-12,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  2.3115e-11, -1.6620e-09,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  6.6666e-14,  0.0000e+00,  2.5430e-13, -1.6038e-12,\n","          0.0000e+00,  2.2350e-11,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00]])\n","tensor([-7.7627e-11,  0.0000e+00])\n"]}]},{"cell_type":"code","source":["for name, param in dgcnn_model_example.named_parameters():\n","    print('Name: ', name,  'Requires_Grad:' , param.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsHc4tOkLFvC","executionInfo":{"status":"ok","timestamp":1694552040300,"user_tz":-120,"elapsed":257,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"ce9bb38f-61ef-41d7-add2-9ee41fddeaaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name:  gnn_layers.gnn_layers.0.conv_params.weight Requires_Grad: True\n","Name:  gnn_layers.gnn_layers.1.conv_params.weight Requires_Grad: True\n","Name:  gnn_layers.gnn_layers.2.conv_params.weight Requires_Grad: True\n","Name:  gnn_layers.gnn_layers.3.conv_params.weight Requires_Grad: True\n","Name:  classic_conv.conv1d_1.weight Requires_Grad: True\n","Name:  classic_conv.conv1d_2.weight Requires_Grad: True\n","Name:  classic_conv.linear1.weight Requires_Grad: True\n","Name:  classic_conv.linear2.weight Requires_Grad: True\n"]}]},{"cell_type":"code","source":["print(dgcnn_model_example)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0OaMo4SBKSR","executionInfo":{"status":"ok","timestamp":1694539887824,"user_tz":-120,"elapsed":247,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"216772ae-c091-456c-a69c-dd1dd4904b32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DGCNN_Model(\n","  (gnn_layers): dgcnn_gnn_layers(\n","    (gnn_layers): Sequential(\n","      (0): GNN_DGCNN(\n","        (conv_params): Linear(in_features=7, out_features=32, bias=False)\n","      )\n","      (1): GNN_DGCNN(\n","        (conv_params): Linear(in_features=32, out_features=32, bias=False)\n","      )\n","      (2): GNN_DGCNN(\n","        (conv_params): Linear(in_features=32, out_features=32, bias=False)\n","      )\n","      (3): GNN_DGCNN(\n","        (conv_params): Linear(in_features=32, out_features=7, bias=False)\n","      )\n","    )\n","  )\n","  (sort_pool): SortPooling_updated()\n","  (classic_conv): MLP_DGCNN(\n","    (conv1d_1): Conv1d(1, 16, kernel_size=(2,), stride=(2,), bias=False)\n","    (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv1d_2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), bias=False)\n","    (linear1): Linear(in_features=800, out_features=128, bias=False)\n","    (linear2): Linear(in_features=128, out_features=2, bias=False)\n","    (dropout_linear1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["from torch_geometric.loader import DataLoader\n","dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n","batched_dataset = DataLoader(dataset, batch_size=20, shuffle=False)\n","print(dgcnn_model_example.classic_conv)"],"metadata":{"id":"WeIupBhDH6ev","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694478328320,"user_tz":-120,"elapsed":225,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"3c5eb88e-b03e-4016-acd2-3f3106fe72eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP_DGCNN(\n","  (conv1d_1): Conv1d(1, 16, kernel_size=(2,), stride=(2,), bias=False)\n","  (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv1d_2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), bias=False)\n","  (linear1): Linear(in_features=128, out_features=128, bias=False)\n","  (linear2): Linear(in_features=128, out_features=2, bias=False)\n","  (dropout_linear1): Dropout(p=0.5, inplace=False)\n",")\n"]}]},{"cell_type":"code","source":["for batch in batched_dataset:\n","    final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, ffn_1, dropout_ffn_1, ffn_2, softmaxed_ffn_2 = dgcnn_model_example(batch, None)\n","    print(final_GNN_layer_output.size(), sortpooled_embedings.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qi9Edbas9AzX","executionInfo":{"status":"ok","timestamp":1694478330431,"user_tz":-120,"elapsed":582,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"ec62f838-96a9-489f-98b4-c034dedc549e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","torch.Size([1, 17, 7]) torch.Size([20, 5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([20, 5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([20, 5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([20, 5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([20, 5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([20, 5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([20, 5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([20, 5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([20, 5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([8, 5, 7])\n"]}]},{"cell_type":"code","source":["for batch in dataset:\n","    final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, ffn_1, dropout_ffn_1, ffn_2, softmaxed_ffn_2 = dgcnn_model_example(batch, None)\n","    #print(final_GNN_layer_output)\n","    print(final_GNN_layer_output.size(), sortpooled_embedings.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NzyJuepUMMeI","executionInfo":{"status":"ok","timestamp":1694478354264,"user_tz":-120,"elapsed":1204,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"fae9d20e-3c97-4fd4-b58c-61cb34214f70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n","True\n","torch.Size([1, 17, 7]) torch.Size([5, 7])\n"]}]},{"cell_type":"code","source":["criterion = torch.nn.CrossEntropyLoss()\n","def loss_calculations(preds, gtruth):\n","    loss_per_epoch = criterion(preds, gtruth)\n","    return loss_per_epoch\n"],"metadata":{"id":"7tOsOzQ01MrS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier_lr = 0.001\n","classifier_dropout = 0.1\n","classifier_weight_decay = 1e-6\n","GNN_Model_optimizer = torch.optim.Adam(dgcnn_model_example.parameters(), lr=classifier_lr, weight_decay=classifier_weight_decay)"],"metadata":{"id":"b_Atetnv5Ynf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(dgcnn_model_example.state_dict().keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TIpAkfB7eg9","executionInfo":{"status":"ok","timestamp":1694507943948,"user_tz":-120,"elapsed":328,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"605c98f8-54b6-4260-dd68-8736d60874fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["odict_keys(['gnn_layers.gnn_layers.0.conv_params.weight', 'gnn_layers.gnn_layers.1.conv_params.weight', 'gnn_layers.gnn_layers.2.conv_params.weight', 'gnn_layers.gnn_layers.3.conv_params.weight', 'classic_conv.conv1d_1.weight', 'classic_conv.conv1d_2.weight', 'classic_conv.linear1.weight', 'classic_conv.linear2.weight'])\n"]}]},{"cell_type":"code","source":["#print(batched_dataset.batch_size)\n","dgcnn_model_example.train()\n","dgcnn_model_example.zero_grad()\n","for batch in batched_dataset:\n","    #print(batch)\n","\n","    final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, ffn_1, dropout_ffn_1, ffn_2, softmaxed_ffn_2 = dgcnn_model_example(batch, None)\n","\n","    #print(softmaxed_ffn_2)\n","    #break\n","    #print(\"output_conv1d_2: \", output_conv1d_2)\n","    #print(\"to_dense: \", to_dense)\n","    #print(\"ffn_1: \", ffn_1)\n","    #print(\"dropout_ffn_1: \", dropout_ffn_1)\n","    #print(final_GNN_layer_output)\n","\n","    batch_loss = loss_calculations(softmaxed_ffn_2, batch.y)\n","    #print(\"batch_loss\", batch_loss)\n","    #print(final_GNN_layer_output)\n","\n","    batch_loss.backward()\n","    #nn.utils.clip_grad_norm_(dgcnn_model_example.parameters(), 1)\n","    #print(\"here: \",dgcnn_model_example.state_dict()['gnn_layers.gnn_layers.3.conv_params.weight'].grad)\n","    #print(\"classic_conv.conv1d_1.weight: \", dgcnn_model_example.state_dict()['classic_conv.linear2.weight'].grad)\n","    #print(dgcnn_model_example.state_dict()['dgcnn_layers.0.conv_params.weight'])\n","    GNN_Model_optimizer.step()\n","\n","    #Pred_Labels.extend(softmaxed_ffn_2.argmax(dim=1).detach().tolist())\n","    #Real_Labels.extend(batch_of_graphs.y.detach().tolist())\n","    #GNN_Model_loss_batch.append(batch_loss)\n","    #print(\"softmax: \", softmaxed_ffn_2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6Z3krgMIFQM","executionInfo":{"status":"ok","timestamp":1694508164471,"user_tz":-120,"elapsed":500,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"97e97387-544e-4a4a-9b95-a15c9c18e38b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n"]}]},{"cell_type":"code","source":["from torch_geometric.loader import DataLoader\n","dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n","batched_dataset = DataLoader(dataset, batch_size=20, shuffle=False)"],"metadata":{"id":"RAPqQ6d3Wn25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def computational_matrices(batched_graphs, edge_mask):\n","    if edge_mask == None:\n","        tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())))\n","    else:\n","        tilda_adjacency_matrix = torch.tensor(csr_matrix((np.array(edge_mask), (np.array(batched_graphs.edge_index[0]), np.array(batched_graphs.edge_index[1])))).todense()) + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())))\n","    tilda_adjacency_matrix = tilda_adjacency_matrix.type(torch.float32)\n","\n","    if batched_graphs.batch is not None:\n","        graph_sizes = [len(batched_graphs[i].x) for i in range(len(batched_graphs))]\n","        batch_size = batched_graphs.num_graphs\n","    else:\n","        graph_sizes = [len(batched_graphs.x)]\n","        batch_size = 1\n","    max_number_of_nodes_in_batch_of_graphs = max(graph_sizes)\n","\n","    new_number_of_nodes = int(tilda_adjacency_matrix.size()[0] / batch_size)\n","\n","    adjacency_list = []\n","    degree_list = []\n","    feature_list = []\n","    for i in range(batch_size):\n","        start = i * graph_sizes[i]\n","        end = (i + 1) * graph_sizes[i]\n","        un_padded_adj = tilda_adjacency_matrix[start:end, start:end]\n","        off_set = max_number_of_nodes_in_batch_of_graphs - un_padded_adj.size()[0]\n","        if un_padded_adj.size()[0] < max_number_of_nodes_in_batch_of_graphs:\n","            un_padded_adj = un_padded_adj.numpy()\n","            un_padded_adj = np.pad(un_padded_adj, [(0, off_set), (0, off_set)], mode='constant', constant_values=np.zeros(1,dtype=np.float32))\n","            un_padded_adj = torch.from_numpy(un_padded_adj)\n","\n","            tilda_degree_vector = torch.sum(un_padded_adj, dim=1)\n","            num_nodes = tilda_degree_vector.size(0)\n","            tilda_degree_matrix = torch.zeros(num_nodes, num_nodes)\n","            tilda_degree_matrix.as_strided([num_nodes], [num_nodes + 1]).copy_(tilda_degree_vector)\n","        tilda_degree_matrix = tilda_degree_matrix.type(torch.float32)\n","        un_padded_adj = un_padded_adj.type(torch.float32)\n","        adjacency_list.append(un_padded_adj)\n","        degree_list.append(tilda_degree_matrix)\n","\n","        un_padded_feat = batched_graphs.x[start:end, :].detach().numpy()\n","        un_padded_feat = torch.from_numpy(np.pad(un_padded_feat, [(0, off_set), (0, 0)], mode='constant', constant_values=np.zeros(1,dtype=np.float32)))\n","        feature_list.append(un_padded_feat)\n","\n","\n","    adjacency_list = list(map(lambda x: torch.unsqueeze(x, 0), adjacency_list))\n","    degree_list = list(map(lambda x: torch.unsqueeze(x, 0), degree_list))\n","    feature_list = list(map(lambda x: torch.unsqueeze(x, 0), feature_list))\n","\n","    new_adjacecny = torch.cat(adjacency_list, dim=0)\n","    new_degree = torch.cat(degree_list, dim=0)\n","    new_features = torch.cat(feature_list, dim=0)\n","\n","\n","    return new_adjacecny, new_degree, new_features"],"metadata":{"id":"P37a2rWoWAoe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batch in batched_dataset:\n","    tilda_adjacency_matrix, tilda_degree_matrix, reciprocal_tilda_degree_matrix = computational_matrices(batch, None)\n","    print(\"tilda_adjacency_matrix: \", tilda_adjacency_matrix.size())\n","    print(\"tilda_degree_matrix: \", tilda_degree_matrix.size())\n","    print(\"new_features: \", reciprocal_tilda_degree_matrix.size())\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJ24vea6WDOa","executionInfo":{"status":"ok","timestamp":1693521948554,"user_tz":-120,"elapsed":439,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"64855181-80d8-47f0-ea1c-fccb9faf820d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tilda_adjacency_matrix:  torch.Size([20, 28, 28])\n","tilda_degree_matrix:  torch.Size([20, 28, 28])\n","new_features:  torch.Size([20, 28, 7])\n"]}]},{"cell_type":"code","source":["\n","if batched_graphs.batch is not None:\n","    graph_sizes = [len(batched_graphs[i].x) for i in range(len(batched_graphs))]\n","    batch_size = batched_graphs.num_graphs\n","else:\n","    graph_sizes = [len(batched_graphs.x)]\n","    batch_size = 1\n","max_number_of_nodes_in_batch_of_graphs = max(graph_sizes)\n","\n","new_number_of_nodes = int(joint_tilda_adjacency_matrix.size()[0] / batch_size)\n","\n","adjacency_list = []\n","degree_list = []\n","feature_list = []\n","for i in range(batch_size):\n","    start = i * graph_sizes[i]\n","    end = (i + 1) * graph_sizes[i]\n","    un_padded_adj = joint_tilda_adjacency_matrix[start:end, start:end]\n","    off_set = max_number_of_nodes_in_batch_of_graphs - un_padded_adj.size()[0]\n","    if un_padded_adj.size()[0] < max_number_of_nodes_in_batch_of_graphs:\n","        un_padded_adj = un_padded_adj.numpy()\n","        un_padded_adj = np.pad(un_padded_adj, [(0, off_set), (0, off_set)], mode='constant', constant_values=np.zeros(1,dtype=np.float32))\n","        un_padded_adj = torch.from_numpy(un_padded_adj)\n","\n","        tilda_degree_vector = torch.sum(tilda_adjacency_matrix, dim=1)\n","        num_nodes = tilda_degree_vector.size(0)\n","        tilda_degree_matrix = torch.zeros(num_nodes, num_nodes)\n","        tilda_degree_matrix.as_strided([num_nodes], [num_nodes + 1]).copy_(tilda_degree_vector)\n","    tilda_degree_matrix = tilda_degree_matrix.type(torch.float32)\n","    un_padded_adj = un_padded_adj.type(torch.float32)\n","    adjacency_list.append(un_padded_adj)\n","    degree_list.append(tilda_degree_matrix)\n","\n","    un_padded_feat = batched_graphs.x[start:end, :].detach().numpy()\n","    un_padded_feat = torch.from_numpy(np.pad(un_padded_feat, [(0, off_set), (0, 0)], mode='constant', constant_values=np.zeros(1,dtype=np.float32)))\n","    feature_list.append(un_padded_feat)\n","\n","\n","adjacency_list = list(map(lambda x: torch.unsqueeze(x, 0), adjacency_list))\n","degree_list = list(map(lambda x: torch.unsqueeze(x, 0), degree_list))\n","feature_list = list(map(lambda x: torch.unsqueeze(x, 0), feature_list))\n","\n","new_adjacecny = torch.cat(adjacency_list, dim=0)\n","new_degree = torch.cat(degree_list, dim=0)\n","new_features = torch.cat(feature_list, dim=0)\n"],"metadata":{"id":"_YQe3DcxiaUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(dgcnn_model_example.state_dict()[\"classic_conv.conv1d_1.weight\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23KkMvUNB5em","executionInfo":{"status":"ok","timestamp":1692113362345,"user_tz":-120,"elapsed":29,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"b90f86b4-2f3e-4528-cf3a-c977bfaa1baa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"code","source":["print(dgcnn_model_example)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdFv5kPgBvLD","executionInfo":{"status":"ok","timestamp":1692100132706,"user_tz":-120,"elapsed":8,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"d7c37059-6091-4148-8268-4f4b612b75f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DGCNN_Model(\n","  (dgcnn_layers): ModuleList(\n","    (0): GNN_DGCNN(\n","      (conv_params): Linear(in_features=7, out_features=32, bias=False)\n","    )\n","    (1-2): 2 x GNN_DGCNN(\n","      (conv_params): Linear(in_features=32, out_features=32, bias=False)\n","    )\n","    (3): GNN_DGCNN(\n","      (conv_params): Linear(in_features=32, out_features=7, bias=False)\n","    )\n","  )\n","  (sort_pool): SortPooling()\n","  (classic_conv): MLP_DGCNN(\n","    (conv1d_1): Conv1d(1, 16, kernel_size=(2,), stride=(2,), bias=False)\n","    (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv1d_2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), bias=False)\n","    (linear1): Linear(in_features=992, out_features=128, bias=False)\n","    (linear2): Linear(in_features=128, out_features=2, bias=False)\n","    (dropout_linear1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["sum=0\n","for i in range(20):\n","    sum = sum + len(dataset[i].x)\n","    print(len(dataset[i].x))\n","print(sum)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdZOHGld3SG2","executionInfo":{"status":"ok","timestamp":1677434177509,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"d5d4adca-a389-4164-ceee-083cc19a99e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["17\n","13\n","13\n","19\n","11\n","28\n","16\n","20\n","12\n","17\n","17\n","20\n","22\n","13\n","19\n","22\n","11\n","17\n","13\n","18\n","338\n"]}]},{"cell_type":"code","source":["k = min(20, len(dataset[0].x))\n","dgcnn_layers = DGCNN_Model(GNN_layers=[32, 32, 32, 7], num_classes=2, mlp_act_fun='ReLu', dgcnn_act_fun='tanh', mlp_dropout_rate=0.5, Weight_Initializer=3, Bias=True, dgcnn_k=k)\n","print(dgcnn_layers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1FDipFq7X79","executionInfo":{"status":"ok","timestamp":1677433423887,"user_tz":-60,"elapsed":475,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"7b168de3-faec-41ed-cc2a-dee4e92d689d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tanh is Selected.\n","DGCNN_Model(\n","  (dgcnn_layers): ModuleList(\n","    (0): GNN_DGCNN(\n","      (conv_params): Linear(in_features=7, out_features=32, bias=False)\n","    )\n","    (1): GNN_DGCNN(\n","      (conv_params): Linear(in_features=32, out_features=32, bias=False)\n","    )\n","    (2): GNN_DGCNN(\n","      (conv_params): Linear(in_features=32, out_features=32, bias=False)\n","    )\n","    (3): GNN_DGCNN(\n","      (conv_params): Linear(in_features=32, out_features=7, bias=False)\n","    )\n","  )\n","  (sort_pool): SortPooling()\n","  (classic_conv): MLP_DGCNN(\n","    (conv1d_1): Conv1d(1, 16, kernel_size=(2,), stride=(2,), padding=(3,))\n","    (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv1d_2): Conv1d(16, 32, kernel_size=(5,), stride=(1,))\n","    (linear1): Linear(in_features=864, out_features=128, bias=True)\n","    (linear2): Linear(in_features=128, out_features=2, bias=True)\n","    (dropout_linear1): Dropout(p=0.5, inplace=False)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["print(len(dataset[0].x))\n","final_GNN_layer_output, sortpooled_embedings, final_output = dgcnn_layers(dataset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":215},"id":"G3s3VPI_7q4P","executionInfo":{"status":"error","timestamp":1677388089705,"user_tz":-60,"elapsed":409,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"7183051a-34bd-4eae-f650-19a2b6b1a282"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["17\n","None\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-532de9fd2b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinal_GNN_layer_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msortpooled_embedings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgcnn_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"]}]},{"cell_type":"code","source":["print(final_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X3LvChgRUyow","executionInfo":{"status":"ok","timestamp":1677382640859,"user_tz":-60,"elapsed":252,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"0a7ad3e2-d33e-4982-fa55-2fff96aa5dca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.2232, 0.7768], grad_fn=<SoftmaxBackward0>)\n"]}]},{"cell_type":"code","source":["print(final_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TAn4Y9WUDC5B","executionInfo":{"status":"ok","timestamp":1677105051221,"user_tz":-60,"elapsed":247,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"17a60346-e579-433e-cb9a-eeafc4030176"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.20715013146400452, -0.0289221853017807, -0.02776801586151123, 0.11429049074649811, -0.0, 0.25220391154289246, -0.02400323748588562, -0.23237444460391998, -0.04584074020385742, 0.023032985627651215, 0.02451241761445999, -0.144331157207489, 0.24520671367645264, 0.07532962411642075]]\n"]}]},{"cell_type":"code","source":["class GraphConvolutionLayers_DGCNN(nn.Module):\n","    '''\n","        DGCNN Model\n","    '''\n","    def __init__(self, GNN_layers, mlp_act_fun, dgcnn_act_fun, dropout_rate, Weight_Initializer, Bias, num_classes, dgcnn_k):"],"metadata":{"id":"WmKqJA1G_O_7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.nn.Linear(bias=True, we)"],"metadata":{"id":"rkrCMrjuZLgY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''class MySpMM(torch.autograd.Function):\n","\t@staticmethod\n","\tdef forward(ctx, sp_mat, dense_mat):\n","\t\tctx.save_for_backward(sp_mat, dense_mat)\n","\t\treturn torch.mm(sp_mat, dense_mat)\n","\n","\t@staticmethod\n","\tdef backward(ctx, grad_output):\n","\t\tsp_mat, dense_mat = ctx.saved_variables\n","\t\tgrad_matrix1 = grad_matrix2 = None\n","\n","\t\tassert not ctx.needs_input_grad[0]\n","\t\tif ctx.needs_input_grad[1]:\n","\t\t\tgrad_matrix2 = Variable(torch.mm(sp_mat.data.t(), grad_output.data))\n","\n","\t\treturn grad_matrix1, grad_matrix2\n","\n","\n","def gnn_spmm(sp_mat, dense_mat):\n","\treturn MySpMM.apply(sp_mat, dense_mat)'''"],"metadata":{"id":"fIf6rkq-hs2d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","import os\n","import sys\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","class SortPooling_updated(nn.Module):\n","    def __init__(self, sort_pooling_k, node_feat_size):\n","        super(SortPooling_updated, self).__init__()\n","        self.sort_pooling_k, = sort_pooling_k,\n","        self.node_feat_size = node_feat_size\n","\n","\n","    def max_sort(self, row):\n","        return max(row)\n","\n","\n","    def forward(self, output_of_dgcnn_layer, batch_graphs):\n","        if batch_graphs.batch is not None:\n","            graph_sizes = [len(batch_graphs[i].x) for i in range(len(batch_graphs))]\n","        else:\n","            graph_sizes = [len(batch_graphs.x)]\n","        batch_sortpooling_zero_graphs = torch.zeros(len(graph_sizes), self.sort_pooling_k, self.node_feat_size)\n","        #print(\"batch of graphs reshaped: \", batch_sortpooling_zero_graphs.size())\n","\n","        start_index = 0\n","        batch_graphs_ready_to_sort = []\n","        if batch_graphs.batch is not None:\n","            for i in range(batch_graphs.num_graphs):\n","                #graph_to_sort = output_of_dgcnn_layer[start_index: start_index + graph_sizes[i]]\n","                #graph_to_sort = torch.reshape(graph_to_sort, (graph_sizes[i], self.node_feat_size))\n","\n","                sorted_graph = torch.Tensor(sorted(output_of_dgcnn_layer[i].detach().numpy(), key = lambda row : max(row), reverse=True))\n","                if sorted_graph.size()[0] >= self.sort_pooling_k:\n","                    batch_sortpooling_zero_graphs[i][:self.sort_pooling_k, 0:self.node_feat_size] = sorted_graph[:self.sort_pooling_k, 0:self.node_feat_size]\n","                else:\n","                    batch_sortpooling_zero_graphs[i][:sorted_graph.size()[0], 0:self.node_feat_size] = sorted_graph[:sorted_graph.size()[0], 0:self.node_feat_size]\n","                sorted_graph.requires_grad = True\n","                batch_graphs_ready_to_sort.append(sorted_graph)\n","                #strat_index = start_index + graph_sizes[i]\n","        else:\n","            for i in range(len([batch_graphs])):\n","                #graph_to_sort = output_of_dgcnn_layer[start_index: start_index + graph_sizes[i]]\n","                #graph_to_sort = torch.reshape(graph_to_sort, (graph_sizes[i], self.node_feat_size))\n","\n","                sorted_graph = torch.Tensor(sorted(output_of_dgcnn_layer[i].cpu().detach().tolist(), key = lambda row : max(row), reverse=True))\n","                if sorted_graph.size()[0] >= self.sort_pooling_k:\n","                    batch_sortpooling_zero_graphs[i][:self.sort_pooling_k, 0:self.node_feat_size] = sorted_graph[:self.sort_pooling_k, 0:self.node_feat_size]\n","                else:\n","                    batch_sortpooling_zero_graphs[i][:sorted_graph.size()[0], 0:self.node_feat_size] = sorted_graph[:sorted_graph.size()[0], 0:self.node_feat_size]\n","\n","                batch_graphs_ready_to_sort.append(sorted_graph)\n","                #strat_index = start_index + graph_sizes[i]\n","\n","        return batch_sortpooling_zero_graphs\n","'''"],"metadata":{"id":"J71o03yjQIkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import math\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","from torch_geometric.utils.convert import to_scipy_sparse_matrix\n","from torch_geometric.utils.train_test_split_edges import torch_geometric\n","import networkx as nx\n","import numpy as np\n","from torch_geometric.nn import GCNConv\n","import sys\n","from torch_geometric.datasets import TUDataset\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","#import matrix_util as Mat_Util\n","#import DGCNN_layer as dgcnn_layer\n","#import DGCNN_GNN_Layers as dgcnn_gnn_layers\n","#import SortPooling_Layer as sortpooling_layer\n","#import MLP_DGCNN as mlp_dgcnn\n","\n","class GlobalMeanPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return gnn.global_mean_pool(x, batch)\n","################################################################################\n","class IdenticalPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return x\n","\n","################################################################################\n","class DGCNN_Model(nn.Module):\n","    '''\n","        DGCNN Layers using sparse adjacency matrix\n","    '''\n","    def __init__(self, GNN_layers, mlp_act_fun, dgcnn_act_fun, mlp_dropout_rate, Weight_Initializer, Bias, num_classes, dgcnn_k,\n","                 node_feat_size, hid_channels, conv1d_kernels, ffn_layer_size, strides):\n","\n","        super(DGCNN_Model, self).__init__()\n","        self.GNN_layers = GNN_layers\n","        self.output_dim = GNN_layers[-1]\n","        self.num_GNN_layers = len(GNN_layers)\n","        self.mlp_dropout_rate = mlp_dropout_rate\n","        self.Bias = Bias\n","        self.Weight_Initializer = Weight_Initializer\n","        self.dgcnn_k = dgcnn_k\n","        self.node_feat_size = node_feat_size\n","        self.num_classes = num_classes\n","        self.hid_channels = hid_channels\n","        self.conv1d_kernels = conv1d_kernels\n","        self.ffn_layer_size = ffn_layer_size\n","        self.strides = strides\n","\n","        self.gnn_layers = dgcnn_gnn_layers(GNN_layers=[32, 32, 32, 7], node_feat_size=self.node_feat_size,\n","                                                            Bias=self.Bias, dgcnn_act_fun=dgcnn_act_fun)\n","\n","        self.sort_pool = SortPooling_updated(self.dgcnn_k, node_feat_size=self.node_feat_size)\n","\n","        self.classic_conv = MLP_DGCNN(num_class=self.num_classes, node_feat_size=self.node_feat_size,\n","                                                mlp_act_fun=mlp_act_fun, dropout_rate=self.mlp_dropout_rate,\n","                                                hid_channels=self.hid_channels, conv1d_kernels=self.conv1d_kernels,\n","                                                dgcnn_k=self.dgcnn_k, ffn_layer_size=self.ffn_layer_size, Bias=self.Bias,\n","                                                strides=self.strides)\n","        if dgcnn_act_fun == 'ReLu':\n","            self.dgcnn_act_fun = F.relu\n","            print('ReLu is Selected.')\n","        elif dgcnn_act_fun == 'eLu':\n","            self.dgcnn_act_fun = nn.functional.elu\n","            print('eLu is Selected.')\n","        elif dgcnn_act_fun == 'tanh':\n","            self.dgcnn_act_fun = torch.tanh\n","            print('tanh is Selected.')\n","\n","\n","\n","        mean = 0\n","        std = 0.1\n","        #self.initialize_weights(Weight_Initializer, Bias, mean, std)\n","\n","\n","    def initialize_weights(model, Weight_Initializer, Bias, mean, std):\n","        # 1. Xavier Normal_.  2. Kaiming Normal_.  3. Uniform (0,0.1std)\n","        if Weight_Initializer == 1:                                             #.      1. Xavier Normal_.\n","            for i,layers in enumerate(model.children()):\n","                if isinstance(layers, dgcnn_gnn_layers.dgcnn_gnn_layers):\n","                    for j, layer in enumerate(layers.modules()):\n","                        if isinstance(layer, nn.Linear):\n","                            torch.nn.init.xavier_normal_(layer.weight.data)\n","                            if Bias:\n","                                layer.bias.data.zero_()\n","                        if isinstance(layer, dgcnn_layer.GNN_DGCNN):\n","                            torch.nn.init.xavier_normal_(layer.conv_params.weight)\n","                            if Bias:\n","                                layer.conv_params.bias.data.zero_()\n","                        else:\n","                            pass\n","                if isinstance(layers, torch.nn.Linear):\n","                    torch.nn.init.xavier_normal_(layers.weight)\n","                    if Bias:\n","                        layers.bias.data.zero_()\n","                if isinstance(layers, (mlp_dgcnn.MLP_DGCNN)):\n","                    torch.nn.init.xavier_normal_(layers.conv1d_1.weight)\n","                    torch.nn.init.xavier_normal_(layers.conv1d_2.weight)\n","                    torch.nn.init.xavier_normal_(layers.linear1.weight)\n","                    torch.nn.init.xavier_normal_(layers.linear2.weight)\n","\n","                elif isinstance(layers, (GlobalMeanPool)):\n","                    pass\n","                elif isinstance(layers, (IdenticalPool)):\n","                    pass\n","\n","        if Weight_Initializer == 2:                                             #.      2. Kaiming Normal_.\n","            for i,layers in enumerate(model.children()):\n","                if isinstance(layers, dgcnn_gnn_layers.dgcnn_gnn_layers):\n","                    for j, layer in enumerate(layers.modules()):\n","                        if isinstance(layer, nn.Linear):\n","                            torch.nn.init.kaiming_normal_(layer.weight.data)\n","                            if Bias:\n","                                layer.bias.data.zero_()\n","                        if isinstance(layer, dgcnn_layer.GNN_DGCNN):\n","                            torch.nn.init.kaiming_normal_(layer.conv_params.weight)\n","                            if Bias:\n","                                layer.conv_params.bias.data.zero_()\n","                        else:\n","                            pass\n","                if isinstance(layers, torch.nn.Linear):\n","                    torch.nn.init.kaiming_normal_(layers.weight)\n","                    if Bias:\n","                        layers.bias.data.zero_()\n","                if isinstance(layers, (mlp_dgcnn.MLP_DGCNN)):\n","                    torch.nn.init.kaiming_normal_(layers.conv1d_1.weight)\n","                    torch.nn.init.kaiming_normal_(layers.conv1d_2.weight)\n","                    torch.nn.init.kaiming_normal_(layers.linear1.weight)\n","                    torch.nn.init.kaiming_normal_(layers.linear2.weight)\n","\n","                elif isinstance(layers, (GlobalMeanPool)):\n","                    pass\n","                elif isinstance(layers, (IdenticalPool)):\n","                    pass\n","\n","        if Weight_Initializer == 3:                                             #.      3. Uniform (0,0.1std)\n","            for i,layers in enumerate(model.children()):\n","                if isinstance(layers, dgcnn_gnn_layers.dgcnn_gnn_layers):\n","                    for j, layer in enumerate(layers.modules()):\n","                        #print(\"here2\")\n","                        if isinstance(layer, nn.Linear):\n","                            torch.nn.init.normal_(layer.weight.data, mean, std)\n","                            if Bias:\n","                                layer.bias.data.zero_()\n","                        if isinstance(layer, dgcnn_layer.GNN_DGCNN):\n","                            torch.nn.init.normal_(layer.conv_params.weight, mean, std)\n","                            if Bias:\n","                                layer.conv_params.bias.data.zero_()\n","                        else:\n","                            pass\n","                if isinstance(layers, torch.nn.Linear):\n","                    torch.nn.init.normal_(layers.weight, mean, std)\n","                    if Bias:\n","                        layers.bias.data.zero_()\n","                if isinstance(layers, (mlp_dgcnn.MLP_DGCNN)):\n","                    torch.nn.init.normal_(layers.conv1d_1.weight, mean, std)\n","                    torch.nn.init.normal_(layers.conv1d_2.weight, mean, std)\n","                    torch.nn.init.normal_(layers.linear1.weight, mean, std)\n","                    torch.nn.init.normal_(layers.linear2.weight, mean, std)\n","                elif isinstance(layers, (GlobalMeanPool)):\n","                    pass\n","                elif isinstance(layers, (IdenticalPool)):\n","                    pass\n","\n","\n","    def forward(self, graph, edge_mask):\n","        #x, edge_index, batch, y = graph.x, graph.edge_index, graph.batch, graph.y\n","\n","        if graph.batch is not None:\n","            graph_sizes = [len(graph[i].x) for i in range(len(graph))]\n","        else:\n","            graph_sizes = [len(graph.x)]\n","\n","\n","        #x = x.type(torch.float32)\n","\n","        Output_of_GNN_Layers = self.gnn_layers(graph, edge_mask)\n","        #final_GNN_layer_output = Output_of_GNN_Layers[-1]\n","\n","\n","        Output_of_GNN_Layers.retain_grad()\n","        #print(len(Output_of_GNN_Layers[0]))\n","        #print(\"final_GNN_layer_output: \",final_GNN_layer_output.size())\n","\n","        sortpooled_embedings = self.sort_pool(output_of_dgcnn_layer=Output_of_GNN_Layers, batch_graphs=graph)\n","        #print(\"sortpooling: \",sortpooled_embedings.size())\n","        #print(\"sortpooled_embedings: \",sortpooled_embedings)\n","        sortpooled_embedings.retain_grad()\n","\n","\n","        output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, ffn_1, dropout_ffn_1, ffn_2, softmaxed_ffn_2 = self.classic_conv(sortpooled_embedings=sortpooled_embedings, graph_sizes=graph_sizes)\n","\n","        return Output_of_GNN_Layers, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, ffn_1, dropout_ffn_1, ffn_2, softmaxed_ffn_2\n","\n","\n","\n","\n","\n","node_feat_size = len(dataset[0].x[0])\n","k=20\n","dgcnn_model_example = DGCNN_Model(GNN_layers=[32, 32, 32, 7], num_classes=2, mlp_act_fun='ReLu', dgcnn_act_fun='tanh',\n","                                  mlp_dropout_rate=0.5, Weight_Initializer=2, Bias=False, dgcnn_k=k, node_feat_size=node_feat_size,\n","                                  hid_channels=[16,32], conv1d_kernels=[2,5], ffn_layer_size=128, strides=[2,1])\n","\n","#print(dgcnn_model_example)\n","#final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, softmaxed_h2 = dgcnn_model_example(dataset[0])\n","#print(softmaxed_h2)'''"],"metadata":{"id":"JfBmnVNvIlBu"},"execution_count":null,"outputs":[]}]}