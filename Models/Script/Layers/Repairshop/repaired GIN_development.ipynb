{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOPmRFBxOHbC+AjyxzTs483"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdC-8f8gbMgp","executionInfo":{"status":"ok","timestamp":1713989448265,"user_tz":-120,"elapsed":61542,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"84d55ed4-3c0c-4e8b-bb2e-0e3bfe37178e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.1+cu121\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKnGS7OrKgDz","executionInfo":{"status":"ok","timestamp":1713989471291,"user_tz":-120,"elapsed":23030,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"5eb8bf6c-c69f-4de6-c666-067c9572c8d5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from torch_geometric.utils import dropout\n","from torch_geometric.loader import DataLoader\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import math\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","from torch_geometric.utils.convert import to_scipy_sparse_matrix\n","import torch_geometric\n","import networkx as nx\n","import numpy as np\n","from torch_geometric.nn import GCNConv\n","import sys\n","from torch_geometric.datasets import TUDataset\n","from torch_geometric.nn import global_add_pool\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","import GIN_MLP_Layers as gin_mlp_layers\n","from scipy.sparse import csr_matrix\n","from sklearn import metrics\n","from time import perf_counter"],"metadata":{"id":"irQWh6uobTsZ","executionInfo":{"status":"ok","timestamp":1713989562203,"user_tz":-120,"elapsed":4225,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["'''class GIN_MLPs(nn.Module):\n","    def __init__(self, num_slp_layers, mlp_input_dim, mlp_hid_dim, mlp_output_dim, mlp_act_fun, Bias):\n","        super(GIN_MLPs, self).__init__()\n","        self.mlp_input_dim = mlp_input_dim\n","        self.mlp_hid_dim = mlp_hid_dim\n","        self.mlp_output_dim = mlp_output_dim\n","        self.num_slp_layers = num_slp_layers\n","        self.Bias = Bias\n","\n","        if mlp_act_fun == 'ReLu':\n","            self.mlp_act_fun = F.relu\n","        elif mlp_act_fun == 'eLu':\n","            self.mlp_act_fun = nn.functional.elu\n","        elif mlp_act_fun == 'tanh':\n","            self.mlp_act_fun = torch.tanh\n","\n","        self.gin_mlp_layers = torch.nn.ModuleList()\n","        self.gin_batch_normalization = torch.nn.ModuleList()\n","\n","\n","        if self.num_slp_layers == 1:\n","            self.gin_mlp_layers.append(nn.Linear(in_features=self.mlp_input_dim, out_features=self.mlp_output_dim, bias=self.Bias))\n","            self.gin_batch_normalization.append(nn.BatchNorm1d(self.mlp_output_dim))\n","        elif self.num_slp_layers > 1:\n","            for i in range(self.num_slp_layers):\n","                if i == 0:\n","                    self.gin_mlp_layers.append(nn.Linear(in_features=self.mlp_input_dim, out_features=self.mlp_hid_dim, bias=self.Bias))\n","                    self.gin_batch_normalization.append(nn.BatchNorm1d(self.mlp_hid_dim))\n","                elif i == self.num_slp_layers-1:\n","                    self.gin_mlp_layers.append(nn.Linear(in_features=self.mlp_hid_dim, out_features=self.mlp_output_dim, bias=self.Bias))\n","                    #self.gin_batch_normalization.append(nn.BatchNorm1d(self.mlp_output_dim))\n","                elif 0 < i < self.num_slp_layers-1:\n","                    self.gin_mlp_layers.append(nn.Linear(in_features=self.mlp_hid_dim, out_features=self.mlp_hid_dim, bias=self.Bias))\n","                    #self.gin_batch_normalization.append(nn.BatchNorm1d(self.mlp_hid_dim))\n","        else:\n","            print(\"please enter layer config\")\n","\n","    def forward(self, h):\n","\n","        for i in range(self.num_slp_layers):\n","            if i == 0:\n","                layer = self.gin_mlp_layers[i](h)\n","                #layer = layer.permute(0, 2, 1)\n","                bnorm = self.gin_batch_normalization[i](layer)\n","                #bnorm = bnorm.permute(0, 2, 1)\n","                h = self.mlp_act_fun(bnorm)\n","            else:\n","                h = self.mlp_act_fun(self.gin_mlp_layers[i](h))\n","        return h\n","'''"],"metadata":{"id":"M6kRCdBkbbGZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GIN_MLPs(nn.Module):\n","    def __init__(self, num_slp_layers, mlp_input_dim, mlp_hid_dim, mlp_output_dim, mlp_act_fun, Bias):\n","        super(GIN_MLPs, self).__init__()\n","        self.mlp_input_dim = mlp_input_dim\n","        self.mlp_hid_dim = mlp_hid_dim\n","        self.mlp_output_dim = mlp_output_dim\n","        self.num_slp_layers = num_slp_layers\n","        self.Bias = Bias\n","\n","        if mlp_act_fun == 'ReLu':\n","            self.mlp_act_fun = F.relu\n","        elif mlp_act_fun == 'eLu':\n","            self.mlp_act_fun = nn.functional.elu\n","        elif mlp_act_fun == 'tanh':\n","            self.mlp_act_fun = torch.tanh\n","\n","        self.gin_mlp_layers = torch.nn.ModuleList()\n","        self.gin_batch_normalization = torch.nn.ModuleList()\n","\n","\n","        if self.num_slp_layers == 1:\n","            self.gin_mlp_layers.append(nn.Linear(in_features=self.mlp_input_dim, out_features=self.mlp_output_dim, bias=self.Bias))\n","            self.gin_batch_normalization.append(nn.BatchNorm1d(self.mlp_output_dim))\n","        elif self.num_slp_layers > 1:\n","            for i in range(self.num_slp_layers):\n","                if i == 0:\n","                    self.gin_mlp_layers.append(nn.Linear(in_features=self.mlp_input_dim, out_features=self.mlp_hid_dim, bias=self.Bias))\n","                    self.gin_batch_normalization.append(nn.BatchNorm1d(num_features=self.mlp_hid_dim))\n","                elif i == self.num_slp_layers-1:\n","                    self.gin_mlp_layers.append(nn.Linear(in_features=self.mlp_hid_dim, out_features=self.mlp_output_dim, bias=self.Bias))\n","                    self.gin_batch_normalization.append(nn.BatchNorm1d(self.mlp_output_dim))\n","                elif 0 < i < self.num_slp_layers-1:\n","                    self.gin_mlp_layers.append(nn.Linear(in_features=self.mlp_hid_dim, out_features=self.mlp_hid_dim, bias=self.Bias))\n","                    self.gin_batch_normalization.append(nn.BatchNorm1d(self.mlp_hid_dim))\n","        else:\n","            print(\"please enter layer config\")\n","\n","    def forward(self, h):\n","\n","        for i in range(self.num_slp_layers):\n","            if i == 0:\n","                layer = self.gin_mlp_layers[i](h)\n","                #layer = layer.permute(0, 2, 1)\n","                bnorm = self.gin_batch_normalization[i](layer)\n","                #bnorm = bnorm.permute(0, 2, 1)\n","                h = self.mlp_act_fun(bnorm)\n","            else:\n","                h = self.mlp_act_fun(self.gin_mlp_layers[i](h))\n","        return h\n","\n","\n","mlp_example = GIN_MLPs(num_slp_layers=2, mlp_input_dim=7, mlp_hid_dim=7, mlp_output_dim=7, mlp_act_fun=\"ReLu\", Bias=True)\n","x = torch.rand(20,7)\n","#x = x.permute(0, 2, 1)\n","y = mlp_example(x)\n","print(y.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbGruDICiE4o","executionInfo":{"status":"ok","timestamp":1713991185132,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"d2d3c010-1810-473b-8870-76c6a54840c2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 7])\n"]}]},{"cell_type":"code","source":["# With Learnable Parameters\n","#m = nn.BatchNorm1d(100)\n","# Without Learnable Parameters\n","m = nn.BatchNorm1d(7, affine=False)\n","input = torch.randn(300, 100, 7)\n","input = input.permute(0, 2, 1)\n","output = m(input)\n","output = output.permute(0, 2, 1)\n","print(output.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPI3YxVB8HwN","executionInfo":{"status":"ok","timestamp":1694972770150,"user_tz":-120,"elapsed":360,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"e197dda6-fded-42f1-b116-c14f54fc90ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([300, 100, 7])\n"]}]},{"cell_type":"code","source":["class GlobalSUMPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return torch_geometric.nn.global_add_pool(x, batch)\n","################################################################################\n","class IdenticalPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return x\n","\n","################################################################################"],"metadata":{"id":"wOUiMbu00GJE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_sum_pool = GlobalSUMPool()"],"metadata":{"id":"DU3D9D1P0H5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.arange(140)\n","x = x.view(2,10, 7)\n","print(x)\n","x = x.permute()\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":599},"id":"bwvPXa6a0Nwg","executionInfo":{"status":"error","timestamp":1694967574982,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"001adbd2-066a-4348-b704-bd1e825e1593"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[  0,   1,   2,   3,   4,   5,   6],\n","         [  7,   8,   9,  10,  11,  12,  13],\n","         [ 14,  15,  16,  17,  18,  19,  20],\n","         [ 21,  22,  23,  24,  25,  26,  27],\n","         [ 28,  29,  30,  31,  32,  33,  34],\n","         [ 35,  36,  37,  38,  39,  40,  41],\n","         [ 42,  43,  44,  45,  46,  47,  48],\n","         [ 49,  50,  51,  52,  53,  54,  55],\n","         [ 56,  57,  58,  59,  60,  61,  62],\n","         [ 63,  64,  65,  66,  67,  68,  69]],\n","\n","        [[ 70,  71,  72,  73,  74,  75,  76],\n","         [ 77,  78,  79,  80,  81,  82,  83],\n","         [ 84,  85,  86,  87,  88,  89,  90],\n","         [ 91,  92,  93,  94,  95,  96,  97],\n","         [ 98,  99, 100, 101, 102, 103, 104],\n","         [105, 106, 107, 108, 109, 110, 111],\n","         [112, 113, 114, 115, 116, 117, 118],\n","         [119, 120, 121, 122, 123, 124, 125],\n","         [126, 127, 128, 129, 130, 131, 132],\n","         [133, 134, 135, 136, 137, 138, 139]]])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-246-80c1d86d2981>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 2"]}]},{"cell_type":"code","source":["from IPython.core.display import deepcopy\n","class GlobalSUMPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return torch_geometric.nn.global_add_pool(x, batch)\n","################################################################################\n","class IdenticalPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return x\n","\n","################################################################################\n","class GIN_Model(nn.Module):\n","    def __init__(self, num_mlp_layers, Bias, num_slp_layers, mlp_input_dim, mlp_hid_dim, mlp_output_dim, mlp_act_fun, num_classes,\n","                 dropout_rate, Weight_Initializer):\n","        super(GIN_Model, self).__init__()\n","\n","        self.mlp_input_dim = mlp_input_dim\n","        self.mlp_hid_dim = mlp_hid_dim\n","        self.mlp_output_dim = mlp_output_dim\n","        self.num_slp_layers = num_slp_layers\n","        self.mlp_act_fun = mlp_act_fun\n","        self.lin_act_fun = mlp_act_fun\n","        self.num_classes = num_classes\n","        self.dropout_rate = dropout_rate\n","        self.Weight_Initializer = Weight_Initializer\n","\n","        self.num_mlp_layers = num_mlp_layers\n","        self.Bias = Bias\n","\n","        self.eps = nn.Parameter(torch.zeros(self.num_mlp_layers),requires_grad=True)\n","        self.gin_mlp_layers = nn.ModuleList()\n","        self.global_summing = GlobalSUMPool()\n","\n","        self.lin1 = nn.Linear(in_features=self.mlp_output_dim * (self.num_mlp_layers + 1), out_features=self.mlp_input_dim * (self.num_mlp_layers + 1))\n","        self.lin2 = nn.Linear(in_features=self.mlp_input_dim * (self.num_mlp_layers + 1), out_features=self.num_classes)\n","        self.dorpout = nn.Dropout(p=dropout_rate)\n","        self.act_fun_softmax = F.softmax\n","        self.the_first_layer = nn.Linear(in_features=self.mlp_input_dim, out_features=self.mlp_output_dim, bias=self.Bias)\n","\n","        for i in range(self.num_mlp_layers):\n","            self.gin_mlp_layers.append(GIN_MLPs(num_slp_layers=self.num_slp_layers, mlp_input_dim=self.mlp_output_dim,\n","                                                               mlp_hid_dim=self.mlp_hid_dim, mlp_output_dim=self.mlp_output_dim,\n","                                                               mlp_act_fun=self.mlp_act_fun, Bias=self.Bias))\n","\n","        if self.lin_act_fun == 'ReLu':\n","            self.lin_act_fun = F.relu\n","            #print('ReLu is Selected.')\n","        elif self.lin_act_fun == 'eLu':\n","            self.lin_act_fun = nn.functional.elu\n","            #print('eLu is Selected.')\n","        elif self.lin_act_fun == 'tanh':\n","            self.lin_act_fun = torch.tanh\n","            #print('tanh is Selected.')\n","\n","        mean = 0\n","        std = 0.1\n","        self.initialize_weights(self.Weight_Initializer, Bias, mean, std)\n","\n","    def initialize_weights(model, Weight_Initializer, Bias, mean, std):\n","        # 1. Xavier Normal_.  2. Kaiming Normal_.  3. Uniform (0,0.1std)\n","        if Weight_Initializer == 1:                                             #.      1. Xavier Normal_.\n","            for i, modules in enumerate(model.children()):\n","                if isinstance(modules, torch.nn.ModuleList):\n","                    for module in modules:\n","                        if isinstance(module, gin_mlp_layers.GIN_MLPs):\n","                            for final_module in module.children():\n","                                if isinstance(final_module, torch.nn.ModuleList):\n","                                    for layers in final_module:\n","                                        if isinstance(layers, torch.nn.Linear):\n","                                            torch.nn.init.xavier_normal_(layers.weight)\n","                                            #layers.weight.data.zero_()\n","                                            #print(layers.weight)\n","                                            if Bias:\n","                                                layers.bias.data.zero_()\n","                                                #print(\"ok\")\n","                                        elif isinstance(layers, torch.nn.BatchNorm1d):\n","                                            #print(\"ok\")\n","                                            pass\n","                elif isinstance(modules, torch.nn.Linear):\n","                    #print(\"predict layer\")\n","                    #modules.weight.data.zero_()\n","                    #print(modules.weight)\n","                    torch.nn.init.xavier_normal_(modules.weight)\n","                elif isinstance(modules, GlobalSUMPool):\n","                    #print(\"GlobalSUMPool\")\n","                    #print(modules)\n","                    pass\n","                elif isinstance(modules, nn.Dropout):\n","                    #print(\"Dropout\")\n","                    #print(modules)\n","                    pass\n","                else:\n","                    pass\n","\n","        if Weight_Initializer == 2:                                             #.      2. Kaiming Normal_.\n","            for i, modules in enumerate(model.children()):\n","                if isinstance(modules, torch.nn.ModuleList):\n","                    for module in modules:\n","                        if isinstance(module, gin_mlp_layers.GIN_MLPs):\n","                            for final_module in module.children():\n","                                if isinstance(final_module, torch.nn.ModuleList):\n","                                    for layers in final_module:\n","                                        if isinstance(layers, torch.nn.Linear):\n","                                            torch.nn.init.kaiming_normal_(layers.weight)\n","                                            #layers.weight.data.zero_()\n","                                            #print(layers.weight)\n","                                            if Bias:\n","                                                layers.bias.data.zero_()\n","                                                #print(\"ok\")\n","                                        elif isinstance(layers, torch.nn.BatchNorm1d):\n","                                            #print(\"ok\")\n","                                            pass\n","                elif isinstance(modules, torch.nn.Linear):\n","                    #print(\"predict layer\")\n","                    #modules.weight.data.zero_()\n","                    #print(modules.weight)\n","                    torch.nn.init.kaiming_normal_(modules.weight)\n","                elif isinstance(modules, GlobalSUMPool):\n","                    #print(\"GlobalSUMPool\")\n","                    #print(modules)\n","                    pass\n","                elif isinstance(modules, nn.Dropout):\n","                    #print(\"Dropout\")\n","                    #print(modules)\n","                    pass\n","                else:\n","                    pass\n","\n","        if Weight_Initializer == 3:                                             #.      3. Uniform (0,0.1std)\n","            for i, modules in enumerate(model.children()):\n","                if isinstance(modules, torch.nn.ModuleList):\n","                    for module in modules:\n","                        if isinstance(module, gin_mlp_layers.GIN_MLPs):\n","                            for final_module in module.children():\n","                                if isinstance(final_module, torch.nn.ModuleList):\n","                                    for layers in final_module:\n","                                        if isinstance(layers, torch.nn.Linear):\n","                                            torch.nn.init.normal_(layers.weight, mean=mean, std=std)\n","                                            #layers.weight.data.zero_()\n","                                            #print(layers.weight)\n","                                            if Bias:\n","                                                layers.bias.data.zero_()\n","                                                #print(\"ok\")\n","                                        elif isinstance(layers, torch.nn.BatchNorm1d):\n","                                            #print(\"ok\")\n","                                            pass\n","                elif isinstance(modules, torch.nn.Linear):\n","                    #print(\"predict layer\")\n","                    #modules.weight.data.zero_()\n","                    #print(modules.weight)\n","                    torch.nn.init.normal_(modules.weight, mean=mean, std=std)\n","                elif isinstance(modules, GlobalSUMPool):\n","                    #print(\"GlobalSUMPool\")\n","                    #print(modules)\n","                    pass\n","                elif isinstance(modules, nn.Dropout):\n","                    #print(\"Dropout\")\n","                    #print(modules)\n","                    pass\n","                else:\n","                    pass\n","\n","\n","    def gin_neighborhood_aggregation(self, new_adjacecny, new_features):\n","        pooled = torch.mm(new_adjacecny, new_features)\n","        return pooled\n","\n","\n","    def gin_layer_process_eps(self, hid_rep, layer, new_adjacecny):\n","\n","        pooled = self.gin_neighborhood_aggregation(new_adjacecny, hid_rep)\n","        pooled = pooled + (1 + self.eps[layer])*hid_rep\n","        pooled_rep = self.gin_mlp_layers[layer](pooled)\n","\n","        return pooled_rep\n","\n","    def merging_process(self, one_mlp, graph_sizes):\n","        new=[]\n","        start=0\n","        for j in range(len(graph_sizes)):\n","            end = start + graph_sizes[j]\n","            new.append(one_mlp[start:end])\n","            start = end\n","        return new\n","\n","    def reshape_mlps_outputs(self, mlps_output_embeds, graph_sizes):\n","        merged_mlps_output_embeds = []\n","        for i in range(len(graph_sizes)):\n","            merged_mlps_output_embeds.append([])\n","\n","        for i in range(len(mlps_output_embeds)):\n","            for j in range(len(mlps_output_embeds[i])):\n","                merged_mlps_output_embeds[j].extend(mlps_output_embeds[i][j])\n","        return merged_mlps_output_embeds\n","\n","    def computational_matrix(self, batched_graphs, edge_mask):\n","\n","        if edge_mask == None:\n","            joint_tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())\n","        else:\n","            joint_tilda_adjacency_matrix = torch.tensor(csr_matrix((np.array(edge_mask), (np.array(batched_graphs.edge_index[0]), np.array(batched_graphs.edge_index[1])))).todense())\n","        joint_tilda_adjacency_matrix = joint_tilda_adjacency_matrix.type(torch.float32)\n","\n","        return joint_tilda_adjacency_matrix\n","\n","    def reshape_batchs_by_graph_sizes(self, hid_rep, batch_size, graph_sizes):\n","        batch_mlps_output_embeds_shape_saved = []\n","        start = 0\n","        for i in range(batch_size):\n","            end = start + graph_sizes[i]\n","            un_padded_feat = hid_rep[start:end, start:end]#.unsqueeze(0)\n","            batch_mlps_output_embeds_shape_saved.append(un_padded_feat)\n","            start = end\n","        return batch_mlps_output_embeds_shape_saved\n","\n","    def forward(self, batched_graphs, edge_mask):\n","\n","        if batched_graphs.batch is not None:\n","            graph_sizes = [len(batched_graphs[i].x) for i in range(len(batched_graphs))]\n","            batch_size = batched_graphs.num_graphs\n","        else:\n","            graph_sizes = [len(batched_graphs.x)]\n","            batch_size = 1\n","\n","        mlps_output_embeds = []\n","        mlps_output_embeds_shape_saved = []\n","\n","        new_adjacecny = self.computational_matrix(batched_graphs, edge_mask)\n","        hid_rep = self.the_first_layer(batched_graphs.x)\n","        mlps_output_embeds.append(hid_rep)\n","\n","        for layer in range(self.num_mlp_layers):\n","            hid_rep = self.gin_layer_process_eps(hid_rep, layer, new_adjacecny)\n","            mlps_output_embeds.append(hid_rep)\n","            mlps_output_embeds_shape_saved.append(self.reshape_batchs_by_graph_sizes(hid_rep, batch_size, graph_sizes))\n","\n","        mlps_output_embeds_stacked = torch.stack(mlps_output_embeds)\n","        mlp_outputs_globalSUMpooled = self.global_summing(mlps_output_embeds_stacked, batched_graphs.batch)\n","\n","        if batched_graphs.batch == None:\n","            merged_mlps_output_embeds_reshaped = torch.unsqueeze(mlp_outputs_globalSUMpooled, dim=1).view(1, -1)\n","        else:\n","            merged_mlps_output_embeds_reshaped = mlp_outputs_globalSUMpooled.view(mlp_outputs_globalSUMpooled.size()[1], -1)\n","\n","        lin1_output = self.lin1(merged_mlps_output_embeds_reshaped)\n","\n","        lin1_output = self.lin_act_fun(lin1_output)\n","\n","        lin1_output_dropouted = self.dorpout(lin1_output)\n","\n","        lin2_output = self.lin2(lin1_output_dropouted)\n","        lin2_output_softmaxed = self.act_fun_softmax(lin2_output, dim=1)\n","\n","        return mlps_output_embeds_shape_saved, mlps_output_embeds_stacked, mlp_outputs_globalSUMpooled, merged_mlps_output_embeds_reshaped, lin1_output, lin1_output_dropouted, lin2_output, lin2_output_softmaxed\n","\n","node_feat_size=7\n","gin_model_example = GIN_Model(num_mlp_layers=4, Bias=False, num_slp_layers=2, mlp_input_dim=node_feat_size, mlp_hid_dim=17,\n","                              mlp_output_dim=19, mlp_act_fun=\"ReLu\", num_classes=2, dropout_rate=0.5, Weight_Initializer=3)\n"],"metadata":{"id":"aLT-uUXqq_nX","executionInfo":{"status":"ok","timestamp":1714000087555,"user_tz":-120,"elapsed":391,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n","batch_size = 11\n","node_feat_size = len(dataset[0].x[0])\n","batched_dataset = DataLoader(dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"ixxjDUJzeaUW","executionInfo":{"status":"ok","timestamp":1713999350206,"user_tz":-120,"elapsed":261,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["GNN_Model_optimizer = torch.optim.Adam(gin_model_example.parameters(), lr=0.01, weight_decay=1e-4)"],"metadata":{"id":"10VWs9CayvgG","executionInfo":{"status":"ok","timestamp":1713989591564,"user_tz":-120,"elapsed":293,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["for batched_graphs in batched_dataset:\n","    #x, edge_index, batch, y = batched_graphs.x, batched_graphs.edge_index, batched_graphs.batch, batched_graphs.y\n","    mlps_output_embeds, mlps_output_embeds_stacked, mlps_output_embeds_pooled, mlps_output_embeds_pooled_stacked, lin1_output, lin1_output_dropouted, lin2_output, lin2_output_softmaxed = gin_model_example(batched_graphs, None)\n","    print(\"lin2_output_softmaxed: \", lin2_output_softmaxed.size())\n","    print(lin2_output_softmaxed)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsMxycm1eVGU","executionInfo":{"status":"ok","timestamp":1714000097778,"user_tz":-120,"elapsed":257,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"9e460c27-368b-4822-9e65-f7c26f901964"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["mlp_outputs_globalSUMpooled:  torch.Size([5, 11, 19])\n","merged_mlps_output_embeds_reshaped:  torch.Size([11, 95])\n","lin2_output_softmaxed:  torch.Size([11, 2])\n","tensor([[3.3732e-01, 6.6268e-01],\n","        [6.7942e-01, 3.2058e-01],\n","        [8.6440e-01, 1.3560e-01],\n","        [8.5527e-01, 1.4473e-01],\n","        [9.5747e-01, 4.2531e-02],\n","        [1.1380e-04, 9.9989e-01],\n","        [1.9320e-01, 8.0680e-01],\n","        [3.4980e-01, 6.5020e-01],\n","        [4.0564e-01, 5.9436e-01],\n","        [5.2087e-01, 4.7913e-01],\n","        [4.2795e-02, 9.5721e-01]], grad_fn=<SoftmaxBackward0>)\n"]}]},{"cell_type":"code","source":["criterion = torch.nn.CrossEntropyLoss()\n","def loss_calculations(preds, gtruth):\n","    loss_per_epoch = criterion(preds, gtruth)\n","    return loss_per_epoch\n"],"metadata":{"id":"J4fbv6JNMzDB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_step():\n","    GNN_Model_loss_batch = []\n","    Pred_Labels = []\n","    Real_Labels = []\n","\n","    gin_model_example.train()\n","    gin_model_example.zero_grad()\n","    #torch.autograd.set_detect_anomaly(True)\n","    for batch_of_graphs in batched_dataset:\n","\n","        mlps_output_embeds, mlps_output_embeds_stacked, mlp_outputs_globalSUMpooled, merged_mlps_output_embeds_reshaped, lin1_output, lin1_output_dropouted, lin2_output, softmaxed_h2 = gin_model_example(batch_of_graphs, None)\n","        batch_loss = loss_calculations(softmaxed_h2, batch_of_graphs.y)\n","\n","        #print(softmaxed_h2, softmaxed_h2.argmax(dim=1))\n","        Pred_Labels.extend(softmaxed_h2.argmax(dim=1).detach().tolist())\n","        Real_Labels.extend(batch_of_graphs.y.detach().tolist())\n","        GNN_Model_loss_batch.append(batch_loss)\n","\n","        batch_loss.backward()\n","        #print(gin_model_example.state_dict()['gin_mlp_layers.0.gin_mlp_layers.0.weight'])\n","        GNN_Model_optimizer.step()\n","\n","    return torch.mean(torch.tensor(GNN_Model_loss_batch)), metrics.accuracy_score(Real_Labels, Pred_Labels)\n"],"metadata":{"id":"9UkhcEcwy0Mh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#from IPython.display import Javascript  # Restrict height of output cell.\n","#display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","\n","SA_Model_training_time_per_epoch = []\n","SA_Model_training_Acc_per_epoch = []\n","\n","def train(EPOCHS, load_index):\n","    SA_training_loss_per_epoch = []\n","\n","    for epoch in range(EPOCHS):\n","\n","        start_generation = perf_counter()\n","        SA_model_training_loss, training_acc = train_step()\n","        SA_Model_training_time_per_epoch.append(perf_counter() - start_generation)\n","        SA_Model_training_Acc_per_epoch.append(training_acc)\n","\n","        print(f'Epoch: {epoch+1:03d}, Model Loss: {SA_model_training_loss:.4f} Accuracy: {training_acc}')\n","\n","        SA_training_loss_per_epoch.append(SA_model_training_loss)\n","\n","\n","        #if (epoch + load_index + 1) % Visualization_Parameter == 0 and epoch > 0:\n","        #    visualize_losses(SA_training_loss_per_epoch, epoch + load_index + 1)\n","        #if (epoch + load_index + 1) % Model_Saving_Parameter == 0 and epoch > 0:\n","        #    torch.save({'epoch': epoch+load_index+1, 'model_state_dict': GNN_Model.state_dict(), 'optimizer_state_dict': GNN_Model_optimizer.state_dict(), 'loss': SA_training_loss_per_epoch,}, \"/content/drive/My Drive/Explainability Methods/\" + str(Explainability_name) + \" on \" + str(Task_name) + \"/Model/\" + File_Name + str(epoch + load_index + 1)+\".pt\")\n","\n","\n","\n"],"metadata":{"id":"3O8obnFXzNLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(gin_model_example.state_dict()['gin_mlp_layers.0.gin_mlp_layers.0.weight'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"efdJvO11L8qD","executionInfo":{"status":"ok","timestamp":1694981647877,"user_tz":-120,"elapsed":243,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"6c5f774f-62f9-4d8f-e552-dbd3bad11102"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.1422, -0.2985,  0.0476,  0.0016, -0.2277, -0.2507,  0.0462],\n","        [ 0.3015, -0.1660,  0.2494,  0.2973, -0.1908, -0.3775,  0.1546],\n","        [ 0.2464,  0.1836,  0.0328,  0.3602, -0.2848,  0.3500, -0.0623],\n","        [ 0.1666, -0.0877, -0.3480,  0.1254,  0.2744,  0.1182,  0.0087],\n","        [ 0.1682,  0.0576, -0.3607,  0.0985,  0.2092, -0.2570, -0.0953],\n","        [ 0.2103, -0.1325, -0.3326, -0.2916,  0.0700, -0.2710,  0.3406],\n","        [-0.2629, -0.3371,  0.2206, -0.2819,  0.3126, -0.0363,  0.1584]])\n"]}]},{"cell_type":"code","source":["EPOCHS = 300\n","load_index = 0\n","\n","train(EPOCHS, load_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"alNoSkvzzPQa","executionInfo":{"status":"ok","timestamp":1694981685867,"user_tz":-120,"elapsed":37109,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"71a255f4-cd62-47f9-de1e-1a7df3bf2bb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 001, Model Loss: 0.7860 Accuracy: 0.5053191489361702\n","Epoch: 002, Model Loss: 0.6709 Accuracy: 0.6542553191489362\n","Epoch: 003, Model Loss: 0.6672 Accuracy: 0.6648936170212766\n","Epoch: 004, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 005, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 006, Model Loss: 0.6662 Accuracy: 0.6648936170212766\n","Epoch: 007, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 008, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 009, Model Loss: 0.6657 Accuracy: 0.6648936170212766\n","Epoch: 010, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 011, Model Loss: 0.6657 Accuracy: 0.6648936170212766\n","Epoch: 012, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 013, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 014, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 015, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 016, Model Loss: 0.6660 Accuracy: 0.6648936170212766\n","Epoch: 017, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 018, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 019, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 020, Model Loss: 0.6632 Accuracy: 0.6648936170212766\n","Epoch: 021, Model Loss: 0.6656 Accuracy: 0.6648936170212766\n","Epoch: 022, Model Loss: 0.6705 Accuracy: 0.6595744680851063\n","Epoch: 023, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 024, Model Loss: 0.6685 Accuracy: 0.6595744680851063\n","Epoch: 025, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 026, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 027, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 028, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 029, Model Loss: 0.6671 Accuracy: 0.6648936170212766\n","Epoch: 030, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 031, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 032, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 033, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 034, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 035, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 036, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 037, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 038, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 039, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 040, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 041, Model Loss: 0.6664 Accuracy: 0.6648936170212766\n","Epoch: 042, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 043, Model Loss: 0.6657 Accuracy: 0.6648936170212766\n","Epoch: 044, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 045, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 046, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 047, Model Loss: 0.6657 Accuracy: 0.6648936170212766\n","Epoch: 048, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 049, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 050, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 051, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 052, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 053, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 054, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 055, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 056, Model Loss: 0.6670 Accuracy: 0.6648936170212766\n","Epoch: 057, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 058, Model Loss: 0.6666 Accuracy: 0.6648936170212766\n","Epoch: 059, Model Loss: 0.6634 Accuracy: 0.6648936170212766\n","Epoch: 060, Model Loss: 0.6634 Accuracy: 0.6648936170212766\n","Epoch: 061, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 062, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 063, Model Loss: 0.6671 Accuracy: 0.6648936170212766\n","Epoch: 064, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 065, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 066, Model Loss: 0.6657 Accuracy: 0.6648936170212766\n","Epoch: 067, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 068, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 069, Model Loss: 0.6633 Accuracy: 0.6648936170212766\n","Epoch: 070, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 071, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 072, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 073, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 074, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 075, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 076, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 077, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 078, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 079, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 080, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 081, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 082, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 083, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 084, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 085, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 086, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 087, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 088, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 089, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 090, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 091, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 092, Model Loss: 0.6657 Accuracy: 0.6648936170212766\n","Epoch: 093, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 094, Model Loss: 0.6632 Accuracy: 0.6648936170212766\n","Epoch: 095, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 096, Model Loss: 0.6658 Accuracy: 0.6648936170212766\n","Epoch: 097, Model Loss: 0.6653 Accuracy: 0.6648936170212766\n","Epoch: 098, Model Loss: 0.6630 Accuracy: 0.6648936170212766\n","Epoch: 099, Model Loss: 0.6591 Accuracy: 0.6648936170212766\n","Epoch: 100, Model Loss: 0.6566 Accuracy: 0.6648936170212766\n","Epoch: 101, Model Loss: 0.6484 Accuracy: 0.6702127659574468\n","Epoch: 102, Model Loss: 0.6578 Accuracy: 0.6276595744680851\n","Epoch: 103, Model Loss: 0.6723 Accuracy: 0.6329787234042553\n","Epoch: 104, Model Loss: 0.6515 Accuracy: 0.6595744680851063\n","Epoch: 105, Model Loss: 0.6495 Accuracy: 0.6648936170212766\n","Epoch: 106, Model Loss: 0.6538 Accuracy: 0.6648936170212766\n","Epoch: 107, Model Loss: 0.6537 Accuracy: 0.6648936170212766\n","Epoch: 108, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 109, Model Loss: 0.6532 Accuracy: 0.6648936170212766\n","Epoch: 110, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 111, Model Loss: 0.6520 Accuracy: 0.6648936170212766\n","Epoch: 112, Model Loss: 0.6448 Accuracy: 0.6648936170212766\n","Epoch: 113, Model Loss: 0.6515 Accuracy: 0.6648936170212766\n","Epoch: 114, Model Loss: 0.6498 Accuracy: 0.6648936170212766\n","Epoch: 115, Model Loss: 0.6553 Accuracy: 0.6595744680851063\n","Epoch: 116, Model Loss: 0.6510 Accuracy: 0.6648936170212766\n","Epoch: 117, Model Loss: 0.6497 Accuracy: 0.6648936170212766\n","Epoch: 118, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 119, Model Loss: 0.6484 Accuracy: 0.6648936170212766\n","Epoch: 120, Model Loss: 0.6502 Accuracy: 0.6648936170212766\n","Epoch: 121, Model Loss: 0.6517 Accuracy: 0.6648936170212766\n","Epoch: 122, Model Loss: 0.6529 Accuracy: 0.6648936170212766\n","Epoch: 123, Model Loss: 0.6515 Accuracy: 0.6648936170212766\n","Epoch: 124, Model Loss: 0.6502 Accuracy: 0.6648936170212766\n","Epoch: 125, Model Loss: 0.6480 Accuracy: 0.6648936170212766\n","Epoch: 126, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 127, Model Loss: 0.6533 Accuracy: 0.6648936170212766\n","Epoch: 128, Model Loss: 0.6475 Accuracy: 0.6648936170212766\n","Epoch: 129, Model Loss: 0.6504 Accuracy: 0.6648936170212766\n","Epoch: 130, Model Loss: 0.6478 Accuracy: 0.6648936170212766\n","Epoch: 131, Model Loss: 0.6509 Accuracy: 0.6648936170212766\n","Epoch: 132, Model Loss: 0.6510 Accuracy: 0.6648936170212766\n","Epoch: 133, Model Loss: 0.6518 Accuracy: 0.6648936170212766\n","Epoch: 134, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 135, Model Loss: 0.6543 Accuracy: 0.6648936170212766\n","Epoch: 136, Model Loss: 0.6482 Accuracy: 0.6648936170212766\n","Epoch: 137, Model Loss: 0.6514 Accuracy: 0.6648936170212766\n","Epoch: 138, Model Loss: 0.6532 Accuracy: 0.6648936170212766\n","Epoch: 139, Model Loss: 0.6466 Accuracy: 0.6648936170212766\n","Epoch: 140, Model Loss: 0.6529 Accuracy: 0.6648936170212766\n","Epoch: 141, Model Loss: 0.6513 Accuracy: 0.6648936170212766\n","Epoch: 142, Model Loss: 0.6504 Accuracy: 0.6648936170212766\n","Epoch: 143, Model Loss: 0.6492 Accuracy: 0.6648936170212766\n","Epoch: 144, Model Loss: 0.6503 Accuracy: 0.6648936170212766\n","Epoch: 145, Model Loss: 0.6498 Accuracy: 0.6648936170212766\n","Epoch: 146, Model Loss: 0.6514 Accuracy: 0.6648936170212766\n","Epoch: 147, Model Loss: 0.6503 Accuracy: 0.6648936170212766\n","Epoch: 148, Model Loss: 0.6529 Accuracy: 0.6648936170212766\n","Epoch: 149, Model Loss: 0.6513 Accuracy: 0.6648936170212766\n","Epoch: 150, Model Loss: 0.6527 Accuracy: 0.6648936170212766\n","Epoch: 151, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 152, Model Loss: 0.6536 Accuracy: 0.6648936170212766\n","Epoch: 153, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 154, Model Loss: 0.6549 Accuracy: 0.6648936170212766\n","Epoch: 155, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 156, Model Loss: 0.6523 Accuracy: 0.6648936170212766\n","Epoch: 157, Model Loss: 0.6520 Accuracy: 0.6648936170212766\n","Epoch: 158, Model Loss: 0.6519 Accuracy: 0.6648936170212766\n","Epoch: 159, Model Loss: 0.6508 Accuracy: 0.6648936170212766\n","Epoch: 160, Model Loss: 0.6502 Accuracy: 0.6648936170212766\n","Epoch: 161, Model Loss: 0.6510 Accuracy: 0.6648936170212766\n","Epoch: 162, Model Loss: 0.6477 Accuracy: 0.6595744680851063\n","Epoch: 163, Model Loss: 0.6482 Accuracy: 0.6648936170212766\n","Epoch: 164, Model Loss: 0.6457 Accuracy: 0.6648936170212766\n","Epoch: 165, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 166, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 167, Model Loss: 0.6495 Accuracy: 0.6648936170212766\n","Epoch: 168, Model Loss: 0.6556 Accuracy: 0.6648936170212766\n","Epoch: 169, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 170, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 171, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 172, Model Loss: 0.6520 Accuracy: 0.6648936170212766\n","Epoch: 173, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 174, Model Loss: 0.6455 Accuracy: 0.6648936170212766\n","Epoch: 175, Model Loss: 0.6479 Accuracy: 0.6648936170212766\n","Epoch: 176, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 177, Model Loss: 0.6439 Accuracy: 0.6648936170212766\n","Epoch: 178, Model Loss: 0.6480 Accuracy: 0.6648936170212766\n","Epoch: 179, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 180, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 181, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 182, Model Loss: 0.6522 Accuracy: 0.6648936170212766\n","Epoch: 183, Model Loss: 0.6481 Accuracy: 0.6648936170212766\n","Epoch: 184, Model Loss: 0.6454 Accuracy: 0.6648936170212766\n","Epoch: 185, Model Loss: 0.6495 Accuracy: 0.6648936170212766\n","Epoch: 186, Model Loss: 0.6518 Accuracy: 0.6648936170212766\n","Epoch: 187, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 188, Model Loss: 0.6480 Accuracy: 0.6648936170212766\n","Epoch: 189, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 190, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 191, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 192, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 193, Model Loss: 0.6520 Accuracy: 0.6648936170212766\n","Epoch: 194, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 195, Model Loss: 0.6514 Accuracy: 0.6648936170212766\n","Epoch: 196, Model Loss: 0.6549 Accuracy: 0.6648936170212766\n","Epoch: 197, Model Loss: 0.6505 Accuracy: 0.6648936170212766\n","Epoch: 198, Model Loss: 0.6496 Accuracy: 0.6648936170212766\n","Epoch: 199, Model Loss: 0.6477 Accuracy: 0.6648936170212766\n","Epoch: 200, Model Loss: 0.6510 Accuracy: 0.6648936170212766\n","Epoch: 201, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 202, Model Loss: 0.6505 Accuracy: 0.6648936170212766\n","Epoch: 203, Model Loss: 0.6508 Accuracy: 0.6648936170212766\n","Epoch: 204, Model Loss: 0.6481 Accuracy: 0.6648936170212766\n","Epoch: 205, Model Loss: 0.6526 Accuracy: 0.6648936170212766\n","Epoch: 206, Model Loss: 0.6520 Accuracy: 0.6648936170212766\n","Epoch: 207, Model Loss: 0.6510 Accuracy: 0.6648936170212766\n","Epoch: 208, Model Loss: 0.6520 Accuracy: 0.6648936170212766\n","Epoch: 209, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 210, Model Loss: 0.6508 Accuracy: 0.6648936170212766\n","Epoch: 211, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 212, Model Loss: 0.6505 Accuracy: 0.6648936170212766\n","Epoch: 213, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 214, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 215, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 216, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 217, Model Loss: 0.6535 Accuracy: 0.6648936170212766\n","Epoch: 218, Model Loss: 0.6508 Accuracy: 0.6648936170212766\n","Epoch: 219, Model Loss: 0.6484 Accuracy: 0.6648936170212766\n","Epoch: 220, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 221, Model Loss: 0.6520 Accuracy: 0.6648936170212766\n","Epoch: 222, Model Loss: 0.6520 Accuracy: 0.6648936170212766\n","Epoch: 223, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 224, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 225, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 226, Model Loss: 0.6556 Accuracy: 0.6595744680851063\n","Epoch: 227, Model Loss: 0.6382 Accuracy: 0.6702127659574468\n","Epoch: 228, Model Loss: 0.6522 Accuracy: 0.6648936170212766\n","Epoch: 229, Model Loss: 0.6556 Accuracy: 0.6595744680851063\n","Epoch: 230, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 231, Model Loss: 0.6406 Accuracy: 0.675531914893617\n","Epoch: 232, Model Loss: 0.6510 Accuracy: 0.6648936170212766\n","Epoch: 233, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 234, Model Loss: 0.6540 Accuracy: 0.6648936170212766\n","Epoch: 235, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 236, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 237, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 238, Model Loss: 0.6481 Accuracy: 0.6648936170212766\n","Epoch: 239, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 240, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 241, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 242, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 243, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 244, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 245, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 246, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 247, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 248, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 249, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 250, Model Loss: 0.6481 Accuracy: 0.6648936170212766\n","Epoch: 251, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 252, Model Loss: 0.6520 Accuracy: 0.6648936170212766\n","Epoch: 253, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 254, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 255, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 256, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 257, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 258, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 259, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 260, Model Loss: 0.6541 Accuracy: 0.6648936170212766\n","Epoch: 261, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 262, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 263, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 264, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 265, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 266, Model Loss: 0.6480 Accuracy: 0.6648936170212766\n","Epoch: 267, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 268, Model Loss: 0.6522 Accuracy: 0.6648936170212766\n","Epoch: 269, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 270, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 271, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 272, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 273, Model Loss: 0.6508 Accuracy: 0.6648936170212766\n","Epoch: 274, Model Loss: 0.6511 Accuracy: 0.6648936170212766\n","Epoch: 275, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 276, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 277, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 278, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 279, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 280, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 281, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 282, Model Loss: 0.6520 Accuracy: 0.6648936170212766\n","Epoch: 283, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 284, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 285, Model Loss: 0.6514 Accuracy: 0.6648936170212766\n","Epoch: 286, Model Loss: 0.6518 Accuracy: 0.6648936170212766\n","Epoch: 287, Model Loss: 0.6585 Accuracy: 0.6648936170212766\n","Epoch: 288, Model Loss: 0.6511 Accuracy: 0.6648936170212766\n","Epoch: 289, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 290, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 291, Model Loss: 0.6507 Accuracy: 0.6648936170212766\n","Epoch: 292, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 293, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 294, Model Loss: 0.6521 Accuracy: 0.6648936170212766\n","Epoch: 295, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 296, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 297, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 298, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 299, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n","Epoch: 300, Model Loss: 0.6506 Accuracy: 0.6648936170212766\n"]}]},{"cell_type":"code","source":["print(gin_model_example.state_dict()['gin_mlp_layers.0.gin_mlp_layers.0.weight'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4vZ3JkJMHXb","executionInfo":{"status":"ok","timestamp":1694981272104,"user_tz":-120,"elapsed":237,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"b635b73c-8f93-4de3-9762-dac851e4b580"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 2.2462e-01,  5.6337e-02, -1.1318e-01, -1.8438e-03,  3.2128e-40,\n","          2.2555e-03,  4.0256e-03],\n","        [-4.3071e-01, -2.0260e-02,  6.0687e-02,  2.1374e-03,  1.9888e-38,\n","         -2.0845e-03,  1.2141e-06],\n","        [ 4.3454e-01, -5.4688e-01,  2.0320e-01, -4.8693e-04, -1.3865e-38,\n","          4.9105e-02, -9.2754e-06],\n","        [ 7.3214e-01,  1.0336e-01, -6.8947e-02, -9.9545e-05, -4.8786e-40,\n","          6.3891e-05,  1.2414e-01],\n","        [-2.1561e-01, -3.4010e-01, -1.4675e-01,  1.3376e-05,  3.1561e-40,\n","          2.5296e-02, -9.2010e-06],\n","        [-1.5141e-01, -6.7731e-02,  9.4892e-02, -1.1764e-02,  7.6239e-40,\n","          3.0364e-02, -4.1464e-06],\n","        [-7.8182e-02, -3.4878e-02,  2.9040e-01, -1.2821e-02,  3.7489e-40,\n","          1.4177e-01, -2.1827e-05]])\n"]}]},{"cell_type":"code","source":["'''\n","from torch_geometric.utils import dropout\n","from torch_geometric.loader import DataLoader\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import math\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","from torch_geometric.utils.convert import to_scipy_sparse_matrix\n","from torch_geometric.utils.train_test_split_edges import torch_geometric\n","import networkx as nx\n","import numpy as np\n","from torch_geometric.nn import GCNConv\n","import sys\n","from torch_geometric.datasets import TUDataset\n","from torch_geometric.nn import global_add_pool\n","from scipy.sparse import csr_matrix\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/Layers/'\n","sys.path.insert(0,py_path)\n","import GIN_MLP_Layers as gin_mlp_layers\n","\n","\n","class GlobalSUMPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return torch_geometric.nn.global_add_pool(x, batch)\n","################################################################################\n","class IdenticalPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return x\n","\n","################################################################################\n","class GIN_Model(nn.Module):\n","    def __init__(self, num_mlp_layers, Bias, num_slp_layers, mlp_input_dim, mlp_hid_dim, mlp_output_dim, mlp_act_fun, num_classes, dropout_rate, Weight_Initializer):\n","        super(GIN_Model, self).__init__()\n","\n","        self.mlp_input_dim = mlp_input_dim\n","        self.mlp_hid_dim = mlp_hid_dim\n","        self.mlp_output_dim = mlp_output_dim\n","        self.num_slp_layers = num_slp_layers\n","        self.mlp_act_fun = mlp_act_fun\n","        self.lin_act_fun = mlp_act_fun\n","        self.num_classes = num_classes\n","        self.dropout_rate = dropout_rate\n","        self.Weight_Initializer = Weight_Initializer\n","\n","        self.num_mlp_layers = num_mlp_layers\n","        self.Bias = Bias\n","\n","        self.eps = nn.Parameter(torch.zeros(self.num_mlp_layers))\n","        self.gin_mlp_layers = nn.ModuleList()\n","        self.global_summing = GlobalSUMPool()\n","\n","        self.lin1 = nn.Linear(in_features=self.mlp_output_dim * (self.num_mlp_layers + 1), out_features=self.mlp_input_dim * (self.num_mlp_layers + 1))\n","        self.lin2 = nn.Linear(in_features=self.mlp_input_dim * (self.num_mlp_layers + 1), out_features=self.num_classes)\n","        self.dorpout = nn.Dropout(p=dropout_rate)\n","        self.act_fun_softmax = F.softmax\n","\n","        for i in range(self.num_mlp_layers):\n","            self.gin_mlp_layers.append(gin_mlp_layers.GIN_MLPs(num_slp_layers=self.num_slp_layers, mlp_input_dim=self.mlp_input_dim, mlp_hid_dim=self.mlp_hid_dim, mlp_output_dim=self.mlp_output_dim, mlp_act_fun=self.mlp_act_fun, Bias=self.Bias))\n","\n","        if self.lin_act_fun == 'ReLu':\n","            self.lin_act_fun = F.relu\n","            #print('ReLu is Selected.')\n","        elif self.lin_act_fun == 'eLu':\n","            self.lin_act_fun = nn.functional.elu\n","            #print('eLu is Selected.')\n","        elif self.lin_act_fun == 'tanh':\n","            self.lin_act_fun = torch.tanh\n","            #print('tanh is Selected.')\n","\n","        mean = 0\n","        std = 0.1\n","        self.initialize_weights(self.Weight_Initializer, Bias, mean, std)\n","\n","    def initialize_weights(model, Weight_Initializer, Bias, mean, std):\n","        # 1. Xavier Normal_.  2. Kaiming Normal_.  3. Uniform (0,0.1std)\n","        if Weight_Initializer == 1:                                             #.      1. Xavier Normal_.\n","            for i, modules in enumerate(model.children()):\n","                if isinstance(modules, torch.nn.ModuleList):\n","                    for module in modules:\n","                        if isinstance(module, gin_mlp_layers.GIN_MLPs):\n","                            for final_module in module.children():\n","                                if isinstance(final_module, torch.nn.ModuleList):\n","                                    for layers in final_module:\n","                                        if isinstance(layers, torch.nn.Linear):\n","                                            torch.nn.init.xavier_normal_(layers.weight)\n","                                            #layers.weight.data.zero_()\n","                                            #print(layers.weight)\n","                                            if Bias:\n","                                                layers.bias.data.zero_()\n","                                                #print(\"ok\")\n","                                        elif isinstance(layers, torch.nn.BatchNorm1d):\n","                                            #print(\"ok\")\n","                                            pass\n","                elif isinstance(modules, torch.nn.Linear):\n","                    #print(\"predict layer\")\n","                    #modules.weight.data.zero_()\n","                    #print(modules.weight)\n","                    torch.nn.init.xavier_normal_(modules.weight)\n","                elif isinstance(modules, GlobalSUMPool):\n","                    #print(\"GlobalSUMPool\")\n","                    #print(modules)\n","                    pass\n","                elif isinstance(modules, nn.Dropout):\n","                    #print(\"Dropout\")\n","                    #print(modules)\n","                    pass\n","                else:\n","                    pass\n","\n","        if Weight_Initializer == 2:                                             #.      2. Kaiming Normal_.\n","            for i, modules in enumerate(model.children()):\n","                if isinstance(modules, torch.nn.ModuleList):\n","                    for module in modules:\n","                        if isinstance(module, gin_mlp_layers.GIN_MLPs):\n","                            for final_module in module.children():\n","                                if isinstance(final_module, torch.nn.ModuleList):\n","                                    for layers in final_module:\n","                                        if isinstance(layers, torch.nn.Linear):\n","                                            torch.nn.init.kaiming_normal_(layers.weight)\n","                                            #layers.weight.data.zero_()\n","                                            #print(layers.weight)\n","                                            if Bias:\n","                                                layers.bias.data.zero_()\n","                                                #print(\"ok\")\n","                                        elif isinstance(layers, torch.nn.BatchNorm1d):\n","                                            #print(\"ok\")\n","                                            pass\n","                elif isinstance(modules, torch.nn.Linear):\n","                    #print(\"predict layer\")\n","                    #modules.weight.data.zero_()\n","                    #print(modules.weight)\n","                    torch.nn.init.kaiming_normal_(modules.weight)\n","                elif isinstance(modules, GlobalSUMPool):\n","                    #print(\"GlobalSUMPool\")\n","                    #print(modules)\n","                    pass\n","                elif isinstance(modules, nn.Dropout):\n","                    #print(\"Dropout\")\n","                    #print(modules)\n","                    pass\n","                else:\n","                    pass\n","\n","        if Weight_Initializer == 3:                                             #.      3. Uniform (0,0.1std)\n","            for i, modules in enumerate(model.children()):\n","                if isinstance(modules, torch.nn.ModuleList):\n","                    for module in modules:\n","                        if isinstance(module, gin_mlp_layers.GIN_MLPs):\n","                            for final_module in module.children():\n","                                if isinstance(final_module, torch.nn.ModuleList):\n","                                    for layers in final_module:\n","                                        if isinstance(layers, torch.nn.Linear):\n","                                            torch.nn.init.normal_(layers.weight, mean=mean, std=std)\n","                                            #layers.weight.data.zero_()\n","                                            #print(layers.weight)\n","                                            if Bias:\n","                                                layers.bias.data.zero_()\n","                                                #print(\"ok\")\n","                                        elif isinstance(layers, torch.nn.BatchNorm1d):\n","                                            #print(\"ok\")\n","                                            pass\n","                elif isinstance(modules, torch.nn.Linear):\n","                    #print(\"predict layer\")\n","                    #modules.weight.data.zero_()\n","                    #print(modules.weight)\n","                    torch.nn.init.normal_(modules.weight, mean=mean, std=std)\n","                elif isinstance(modules, GlobalSUMPool):\n","                    #print(\"GlobalSUMPool\")\n","                    #print(modules)\n","                    pass\n","                elif isinstance(modules, nn.Dropout):\n","                    #print(\"Dropout\")\n","                    #print(modules)\n","                    pass\n","                else:\n","                    pass\n","\n","\n","    def gin_neighborhood_aggregation(self, h, batched_graphs, edge_mask):\n","\n","        #joint_tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())# + torch.eye(len(torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())))\n","        if edge_mask == None:\n","            joint_tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())\n","        else:\n","            joint_tilda_adjacency_matrix = torch.tensor(csr_matrix((np.array(edge_mask), (np.array(batched_graphs.edge_index[0]), np.array(batched_graphs.edge_index[1])))).todense())\n","\n","        joint_tilda_adjacency_matrix = joint_tilda_adjacency_matrix.type(torch.float32)\n","        if batched_graphs.batch == None:\n","            batch_size = 1\n","        else:\n","            batch_size = batched_graphs.num_graphs\n","\n","        pooled = torch.mm(joint_tilda_adjacency_matrix, batched_graphs.x)\n","\n","\n","        return joint_tilda_adjacency_matrix, pooled\n","\n","\n","    def gin_layer_process_eps(self, h, layer, batched_graphs, edge_mask):\n","\n","        joint_tilda_adjacency_matrix, pooled = self.gin_neighborhood_aggregation(h, batched_graphs, edge_mask)\n","\n","        pooled = pooled + (1 + self.eps[layer])*h\n","        pooled_rep = self.gin_mlp_layers[layer](pooled)\n","\n","\n","        return pooled_rep\n","\n","    def merging_process(self, one_mlp, graph_sizes):\n","        new=[]\n","        start=0\n","        for j in range(len(graph_sizes)):\n","            end = start + graph_sizes[j]\n","            new.append(one_mlp[start:end])\n","            start = end\n","        return new\n","\n","    def reshape_mlps_outputs(self, mlps_output_embeds, graph_sizes):\n","        merged_mlps_output_embeds = []\n","        for i in range(len(graph_sizes)):\n","            merged_mlps_output_embeds.append([])\n","\n","        for i in range(len(mlps_output_embeds)):\n","            for j in range(len(mlps_output_embeds[i])):\n","                merged_mlps_output_embeds[j].extend(mlps_output_embeds[i][j])\n","        return merged_mlps_output_embeds\n","\n","\n","\n","\n","\n","    def forward(self, batched_graphs, edge_mask):\n","        #X_concatinated = [graph for graph in batched_graphs.x]\n","        #X_concatinated = torch.stack(X_concatinated, dim=0)\n","\n","        if batched_graphs.batch is not None:\n","            graph_sizes = [len(batched_graphs[i].x) for i in range(len(batched_graphs))]\n","        else:\n","            graph_sizes = [len(batched_graphs.x)]\n","\n","        mlps_output_embeds = []\n","        mlps_output_embeds.append(batched_graphs.x)\n","        hid_rep = batched_graphs.x\n","\n","        for layer in range(self.num_mlp_layers):\n","            hid_rep = self.gin_layer_process_eps(hid_rep, layer, batched_graphs, edge_mask)\n","            mlps_output_embeds.append(hid_rep)\n","        #print(\"the last mlp's: \",h.size())\n","        #h = torch.split(hid_rep, graph_sizes)\n","\n","\n","        mlps_output_embeds_stacked = torch.stack(mlps_output_embeds)\n","\n","        mlp_outputs_globalSUMpooled = self.global_summing(mlps_output_embeds_stacked, batched_graphs.batch)\n","\n","        #merged_mlps_output_embeds_reshaped = self.reshape_mlps_outputs(mlp_outputs_globalSUMpooled, graph_sizes)\n","        if batched_graphs.batch == None:\n","            #merged_mlps_output_embeds_reshaped = self.reshape_mlps_outputs(mlps_output_embeds, graph_sizes, batched_graphs.batch)\n","            merged_mlps_output_embeds_reshaped = self.reshape_mlps_outputs(torch.unsqueeze(mlp_outputs_globalSUMpooled, dim=1), graph_sizes)\n","        else:\n","            merged_mlps_output_embeds_reshaped = self.reshape_mlps_outputs(mlp_outputs_globalSUMpooled, graph_sizes)\n","        lin1_output = self.lin1(torch.tensor(merged_mlps_output_embeds_reshaped))\n","        lin1_output = self.lin_act_fun(lin1_output)\n","\n","        lin1_output_dropouted = self.dorpout(lin1_output)\n","\n","        lin2_output = self.lin2(lin1_output_dropouted)\n","        lin2_output_softmaxed = self.act_fun_softmax(lin2_output, dim=1)\n","\n","        return mlps_output_embeds, mlps_output_embeds_stacked, mlp_outputs_globalSUMpooled, merged_mlps_output_embeds_reshaped, lin1_output, lin1_output_dropouted, lin2_output, lin2_output_softmaxed\n","\n","\n","\n","#dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n","#batch_size = 20\n","#node_feat_size = len(dataset[0].x[0])\n","#batched_dataset = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","#gin_model_example = GIN_Model(num_mlp_layers=4, Bias=True, num_slp_layers=2, mlp_input_dim=node_feat_size, mlp_hid_dim=7, mlp_output_dim=7, #mlp_act_fun=\"ReLu\", num_classes=2, dropout_rate=0.5, Weight_Initializer=3)\n","#print(gin_model_example)\n","\n","#for batched_graphs in batched_dataset:\n","#    #x, edge_index, batch, y = batched_graphs.x, batched_graphs.edge_index, batched_graphs.batch, batched_graphs.y\n","#    mlps_output_embeds, mlps_output_embeds_stacked, mlp_outputs_globalSUMpooled, merged_mlps_output_embeds_reshaped, lin1_output, #lin1_output_dropouted, lin2_output, lin2_output_softmaxed = gin_model_example(batched_graphs)\n","#    print(\"lin2_output_softmaxed: \", lin2_output_softmaxed.size())\n","#    print(lin2_output_softmaxed)\n","#    break'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4bV5j79e-Tf","executionInfo":{"status":"ok","timestamp":1694978769768,"user_tz":-120,"elapsed":259,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"3751ce71-7eb3-47ab-8663-87e80ffcd46a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GIN_Model(\n","  (gin_mlp_layers): ModuleList(\n","    (0-3): 4 x GIN_MLPs(\n","      (gin_mlp_layers): ModuleList(\n","        (0-1): 2 x Linear(in_features=7, out_features=7, bias=True)\n","      )\n","      (gin_batch_normalization): ModuleList(\n","        (0): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (global_summing): GlobalSUMPool()\n","  (lin1): Linear(in_features=35, out_features=35, bias=True)\n","  (lin2): Linear(in_features=35, out_features=2, bias=True)\n","  (dorpout): Dropout(p=0.5, inplace=False)\n",")\n"]}]},{"cell_type":"code","source":["'''from IPython.core.display import deepcopy\n","class GlobalSUMPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return torch_geometric.nn.global_add_pool(x, batch)\n","################################################################################\n","class IdenticalPool(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x, batch):\n","        return x\n","\n","################################################################################\n","class GIN_Model(nn.Module):\n","    def __init__(self, num_mlp_layers, Bias, num_slp_layers, mlp_input_dim, mlp_hid_dim, mlp_output_dim, mlp_act_fun, num_classes,\n","                 dropout_rate, Weight_Initializer):\n","        super(GIN_Model, self).__init__()\n","\n","        self.mlp_input_dim = mlp_input_dim\n","        self.mlp_hid_dim = mlp_hid_dim\n","        self.mlp_output_dim = mlp_output_dim\n","        self.num_slp_layers = num_slp_layers\n","        self.mlp_act_fun = mlp_act_fun\n","        self.lin_act_fun = mlp_act_fun\n","        self.num_classes = num_classes\n","        self.dropout_rate = dropout_rate\n","        self.Weight_Initializer = Weight_Initializer\n","\n","        self.num_mlp_layers = num_mlp_layers\n","        self.Bias = Bias\n","\n","        self.eps = nn.Parameter(torch.zeros(self.num_mlp_layers))\n","        self.gin_mlp_layers = nn.ModuleList()\n","        self.global_summing = GlobalSUMPool()\n","\n","        self.lin1 = nn.Linear(in_features=self.mlp_output_dim * (self.num_mlp_layers + 1), out_features=self.mlp_input_dim * (self.num_mlp_layers + 1))\n","        self.lin2 = nn.Linear(in_features=self.mlp_input_dim * (self.num_mlp_layers + 1), out_features=self.num_classes)\n","        self.dorpout = nn.Dropout(p=dropout_rate)\n","        self.act_fun_softmax = F.softmax\n","\n","        for i in range(self.num_mlp_layers):\n","            self.gin_mlp_layers.append(GIN_MLPs(num_slp_layers=self.num_slp_layers, mlp_input_dim=self.mlp_input_dim,\n","                                                               mlp_hid_dim=self.mlp_hid_dim, mlp_output_dim=self.mlp_output_dim,\n","                                                               mlp_act_fun=self.mlp_act_fun, Bias=self.Bias))\n","\n","        if self.lin_act_fun == 'ReLu':\n","            self.lin_act_fun = F.relu\n","            #print('ReLu is Selected.')\n","        elif self.lin_act_fun == 'eLu':\n","            self.lin_act_fun = nn.functional.elu\n","            #print('eLu is Selected.')\n","        elif self.lin_act_fun == 'tanh':\n","            self.lin_act_fun = torch.tanh\n","            #print('tanh is Selected.')\n","\n","        mean = 0\n","        std = 0.1\n","        self.initialize_weights(self.Weight_Initializer, Bias, mean, std)\n","\n","    def initialize_weights(model, Weight_Initializer, Bias, mean, std):\n","        # 1. Xavier Normal_.  2. Kaiming Normal_.  3. Uniform (0,0.1std)\n","        if Weight_Initializer == 1:                                             #.      1. Xavier Normal_.\n","            for i, modules in enumerate(model.children()):\n","                if isinstance(modules, torch.nn.ModuleList):\n","                    for module in modules:\n","                        if isinstance(module, gin_mlp_layers.GIN_MLPs):\n","                            for final_module in module.children():\n","                                if isinstance(final_module, torch.nn.ModuleList):\n","                                    for layers in final_module:\n","                                        if isinstance(layers, torch.nn.Linear):\n","                                            torch.nn.init.xavier_normal_(layers.weight)\n","                                            #layers.weight.data.zero_()\n","                                            #print(layers.weight)\n","                                            if Bias:\n","                                                layers.bias.data.zero_()\n","                                                #print(\"ok\")\n","                                        elif isinstance(layers, torch.nn.BatchNorm1d):\n","                                            #print(\"ok\")\n","                                            pass\n","                elif isinstance(modules, torch.nn.Linear):\n","                    #print(\"predict layer\")\n","                    #modules.weight.data.zero_()\n","                    #print(modules.weight)\n","                    torch.nn.init.xavier_normal_(modules.weight)\n","                elif isinstance(modules, GlobalSUMPool):\n","                    #print(\"GlobalSUMPool\")\n","                    #print(modules)\n","                    pass\n","                elif isinstance(modules, nn.Dropout):\n","                    #print(\"Dropout\")\n","                    #print(modules)\n","                    pass\n","                else:\n","                    pass\n","\n","        if Weight_Initializer == 2:                                             #.      2. Kaiming Normal_.\n","            for i, modules in enumerate(model.children()):\n","                if isinstance(modules, torch.nn.ModuleList):\n","                    for module in modules:\n","                        if isinstance(module, gin_mlp_layers.GIN_MLPs):\n","                            for final_module in module.children():\n","                                if isinstance(final_module, torch.nn.ModuleList):\n","                                    for layers in final_module:\n","                                        if isinstance(layers, torch.nn.Linear):\n","                                            torch.nn.init.kaiming_normal_(layers.weight)\n","                                            #layers.weight.data.zero_()\n","                                            #print(layers.weight)\n","                                            if Bias:\n","                                                layers.bias.data.zero_()\n","                                                #print(\"ok\")\n","                                        elif isinstance(layers, torch.nn.BatchNorm1d):\n","                                            #print(\"ok\")\n","                                            pass\n","                elif isinstance(modules, torch.nn.Linear):\n","                    #print(\"predict layer\")\n","                    #modules.weight.data.zero_()\n","                    #print(modules.weight)\n","                    torch.nn.init.kaiming_normal_(modules.weight)\n","                elif isinstance(modules, GlobalSUMPool):\n","                    #print(\"GlobalSUMPool\")\n","                    #print(modules)\n","                    pass\n","                elif isinstance(modules, nn.Dropout):\n","                    #print(\"Dropout\")\n","                    #print(modules)\n","                    pass\n","                else:\n","                    pass\n","\n","        if Weight_Initializer == 3:                                             #.      3. Uniform (0,0.1std)\n","            for i, modules in enumerate(model.children()):\n","                if isinstance(modules, torch.nn.ModuleList):\n","                    for module in modules:\n","                        if isinstance(module, gin_mlp_layers.GIN_MLPs):\n","                            for final_module in module.children():\n","                                if isinstance(final_module, torch.nn.ModuleList):\n","                                    for layers in final_module:\n","                                        if isinstance(layers, torch.nn.Linear):\n","                                            torch.nn.init.normal_(layers.weight, mean=mean, std=std)\n","                                            #layers.weight.data.zero_()\n","                                            #print(layers.weight)\n","                                            if Bias:\n","                                                layers.bias.data.zero_()\n","                                                #print(\"ok\")\n","                                        elif isinstance(layers, torch.nn.BatchNorm1d):\n","                                            #print(\"ok\")\n","                                            pass\n","                elif isinstance(modules, torch.nn.Linear):\n","                    #print(\"predict layer\")\n","                    #modules.weight.data.zero_()\n","                    #print(modules.weight)\n","                    torch.nn.init.normal_(modules.weight, mean=mean, std=std)\n","                elif isinstance(modules, GlobalSUMPool):\n","                    #print(\"GlobalSUMPool\")\n","                    #print(modules)\n","                    pass\n","                elif isinstance(modules, nn.Dropout):\n","                    #print(\"Dropout\")\n","                    #print(modules)\n","                    pass\n","                else:\n","                    pass\n","\n","\n","    def gin_neighborhood_aggregation(self, new_adjacecny, new_features):\n","\n","        pooled = torch.bmm(new_adjacecny, new_features)\n","\n","\n","        return pooled\n","\n","\n","    def gin_layer_process_eps(self, hid_rep, layer, new_adjacecny, new_features):\n","\n","        pooled = self.gin_neighborhood_aggregation(new_adjacecny, new_features)\n","\n","\n","        pooled = pooled + (1 + self.eps[layer])*hid_rep\n","        pooled_rep = self.gin_mlp_layers[layer](pooled)\n","\n","\n","        return pooled_rep\n","\n","    def merging_process(self, one_mlp, graph_sizes):\n","        new=[]\n","        start=0\n","        for j in range(len(graph_sizes)):\n","            end = start + graph_sizes[j]\n","            new.append(one_mlp[start:end])\n","            start = end\n","        return new\n","\n","    def reshape_mlps_outputs(self, mlps_output_embeds, graph_sizes):\n","        merged_mlps_output_embeds = []\n","        for i in range(len(graph_sizes)):\n","            merged_mlps_output_embeds.append([])\n","\n","        for i in range(len(mlps_output_embeds)):\n","            for j in range(len(mlps_output_embeds[i])):\n","                merged_mlps_output_embeds[j].extend(mlps_output_embeds[i][j])\n","        return merged_mlps_output_embeds\n","\n","\n","    def computational_matrix(self, batched_graphs, edge_mask):\n","\n","        if edge_mask == None:\n","            joint_tilda_adjacency_matrix = torch.tensor(to_scipy_sparse_matrix(batched_graphs.edge_index).todense())\n","        else:\n","            joint_tilda_adjacency_matrix = torch.tensor(csr_matrix((np.array(edge_mask), (np.array(batched_graphs.edge_index[0]), np.array(batched_graphs.edge_index[1])))).todense())\n","\n","        joint_tilda_adjacency_matrix = joint_tilda_adjacency_matrix.type(torch.float32)\n","\n","\n","        if batched_graphs.batch is not None:\n","            graph_sizes = [len(batched_graphs[i].x) for i in range(len(batched_graphs))]\n","            batch_size = batched_graphs.num_graphs\n","        else:\n","            graph_sizes = [len(batched_graphs.x)]\n","            batch_size = 1\n","        max_number_of_nodes_in_batch_of_graphs = max(graph_sizes)\n","\n","\n","        adjacency_list = []\n","        feature_list = []\n","        for i in range(batch_size):\n","            start = i * graph_sizes[i]\n","            end = (i + 1) * graph_sizes[i]\n","            un_padded_adj = joint_tilda_adjacency_matrix[start:end, start:end]\n","            off_set = max_number_of_nodes_in_batch_of_graphs - un_padded_adj.size()[0]\n","            if un_padded_adj.size()[0] <= max_number_of_nodes_in_batch_of_graphs:\n","                un_padded_adj = F.pad(un_padded_adj, (0, off_set, 0, off_set), mode='constant', value=0)\n","                un_padded_adj = un_padded_adj.type(torch.float32)\n","\n","            un_padded_adj = un_padded_adj.type(torch.float32)\n","            adjacency_list.append(un_padded_adj)\n","\n","            un_padded_feat = batched_graphs.x[start:end, :]\n","            un_padded_feat = F.pad(un_padded_feat, (0, 0, 0, off_set), mode='constant', value=0)\n","            un_padded_feat = un_padded_feat.type(torch.float32)\n","            un_padded_feat.require_grad = True\n","            feature_list.append(un_padded_feat)\n","\n","        adjacency_list = list(map(lambda x: torch.unsqueeze(x, 0), adjacency_list))\n","        feature_list = list(map(lambda x: torch.unsqueeze(x, 0), feature_list))\n","\n","        new_adjacecny = torch.cat(adjacency_list, dim=0)\n","        new_features = torch.cat(feature_list, dim=0)\n","\n","        return new_adjacecny, new_features\n","\n","\n","    def forward(self, batched_graphs, edge_mask):\n","\n","        if batched_graphs.batch is not None:\n","            graph_sizes = [len(batched_graphs[i].x) for i in range(len(batched_graphs))]\n","        else:\n","            graph_sizes = [len(batched_graphs.x)]\n","        batched_graphs2 = deepcopy(batched_graphs)\n","        print(batched_graphs.batch, batched_graphs.batch.size())\n","        new_adjacecny, new_features = self.computational_matrix(batched_graphs, edge_mask)\n","        mlps_output_embeds = []\n","        mlps_output_embeds.append(new_features)\n","\n","\n","\n","        source = new_features\n","        for layer in range(self.num_mlp_layers):\n","            new_features = self.gin_layer_process_eps(new_features, layer, new_adjacecny, new_features)\n","            source = torch.cat((source, new_features),0)\n","            mlps_output_embeds.append(new_features)\n","\n","        batch_list = []\n","        for i in range(source.size()[0]):\n","            for j in range(source.size()[1]):\n","                batch_list.append(i)\n","        batch_np = np.array(batch_list)\n","        batch_torch = torch.from_numpy(batch_np)\n","        source = source.view(source.size()[0]*source.size()[1], source.size()[2])\n","        print(\"here\", source.size())\n","        print(\"new_features: \", new_features.size())\n","\n","\n","        #mlps_output_embeds_stacked = torch.stack(mlps_output_embeds)\n","        #print(\"mlps_output_embeds_stacked: \", mlps_output_embeds_stacked.size())\n","\n","        mlp_outputs_globalSUMpooled = self.global_summing(source, batch_torch)\n","        print(\"mlp_outputs_globalSUMpooled: \", mlp_outputs_globalSUMpooled.size())\n","\n","        if batched_graphs.batch == None:\n","            merged_mlps_output_embeds_reshaped = self.reshape_mlps_outputs(torch.unsqueeze(mlp_outputs_globalSUMpooled, dim=1), graph_sizes)\n","        else:\n","            merged_mlps_output_embeds_reshaped = self.reshape_mlps_outputs(mlp_outputs_globalSUMpooled, graph_sizes)\n","        lin1_output = self.lin1(torch.tensor(merged_mlps_output_embeds_reshaped))\n","        lin1_output = self.lin_act_fun(lin1_output)\n","\n","        lin1_output_dropouted = self.dorpout(lin1_output)\n","\n","        lin2_output = self.lin2(lin1_output_dropouted)\n","        lin2_output_softmaxed = self.act_fun_softmax(lin2_output, dim=1)\n","\n","        return mlps_output_embeds, mlps_output_embeds_stacked, mlp_outputs_globalSUMpooled, merged_mlps_output_embeds_reshaped, lin1_output, lin1_output_dropouted, lin2_output, lin2_output_softmaxed\n","node_feat_size=7\n","gin_model_example = GIN_Model(num_mlp_layers=4, Bias=True, num_slp_layers=2, mlp_input_dim=node_feat_size, mlp_hid_dim=7,\n","                              mlp_output_dim=7, mlp_act_fun=\"ReLu\", num_classes=2, dropout_rate=0.5, Weight_Initializer=3)\n","#print(gin_model_example)\n","\n","'''"],"metadata":{"id":"J18Hj--7ZWDS"},"execution_count":null,"outputs":[]}]}