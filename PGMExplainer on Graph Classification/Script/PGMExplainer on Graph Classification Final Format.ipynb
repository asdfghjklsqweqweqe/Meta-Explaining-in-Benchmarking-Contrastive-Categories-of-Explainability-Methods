{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdUOaRduvlPua6+QEugWnT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## ***PGMExplainer***\n","\n","\n","> Moduled: Accpeting the four GNNs (GCN+GAP, DGCNN, DIFFPOOL, and GIN)\n","\n","\n","---"],"metadata":{"id":"ALnvuZU_7T8Q"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ya0sDe_aNLA","executionInfo":{"status":"ok","timestamp":1712737307937,"user_tz":-120,"elapsed":91470,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"700ac6c5-7d0c-4158-8113-412f3fde487c"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.1+cu121\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting git+https://github.com/rusty1s/pytorch_geometric.git\n","  Cloning https://github.com/rusty1s/pytorch_geometric.git to /tmp/pip-req-build-d1wgt6fi\n","  Running command git clone --filter=blob:none --quiet https://github.com/rusty1s/pytorch_geometric.git /tmp/pip-req-build-d1wgt6fi\n","  Resolved https://github.com/rusty1s/pytorch_geometric.git to commit e213c297bb2aeb9ac50db258f5ab01ea11aea349\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (3.9.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (3.1.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (1.25.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (2.31.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (1.11.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.6.0) (4.66.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.6.0) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.6.0) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.6.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.6.0) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.6.0) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.6.0) (3.4.0)\n"]}],"source":["# Install required packages.\n","import os\n","\n","#!pip install torch==1.7.0\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install git+https://github.com/rusty1s/pytorch_geometric.git"]},{"cell_type":"code","source":["import argparse\n","import os\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from math import sqrt\n","import math\n","\n","from torch_geometric.datasets import TUDataset\n","\n","import torch as th\n","import torch\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.nn.parameter import Parameter\n","from torch_geometric.nn import GCNConv\n","import torch.nn.functional as F\n","from torch.nn import Linear, LayerNorm\n","from sklearn import metrics\n","from scipy.spatial.distance import hamming\n","import statistics\n","import pandas\n","from time import perf_counter\n","from IPython.core.display import deepcopy\n","from torch_geometric.nn import MessagePassing\n","import copy\n","from torch.nn import ReLU, Sequential\n","from torch import sigmoid\n","from itertools import chain\n","from time import perf_counter\n","from torch_geometric.data import Data, Batch, Dataset\n","from functools import partial\n","from torch_geometric.utils import to_networkx\n","from torch_geometric.utils import remove_self_loops\n","from typing import Callable, Union, Optional\n","#from torch_geometric.utils.num_nodes import maybe_num_nodes\n","import networkx as nx\n","from typing import List, Tuple, Dict\n","from collections import Counter\n","import statistics\n","from scipy import stats\n","import logging\n","import pandas as pd\n","import csv\n","from statistics import mean\n","\n","\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.loader import DataLoader\n","import torch_geometric.nn as gnn"],"metadata":{"id":"8A-GC0XUrrrI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BPNvr2Lmruva","executionInfo":{"status":"ok","timestamp":1712737542587,"user_tz":-120,"elapsed":21774,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"b26c3420-d64b-4423-dc8d-a0337fcda4d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["mutag_dataset = TUDataset(root='data/TUDataset', name='MUTAG')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbjFPZHSrw1r","executionInfo":{"status":"ok","timestamp":1712737549841,"user_tz":-120,"elapsed":2372,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"51b86cad-efd4-4675-a6c1-84ca64b69ab4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n","Processing...\n","Done!\n"]}]},{"cell_type":"code","source":["Explainability_name = 'PGMExplainer'\n","Task_name = 'Graph Classification'\n","checkpoint_directory_Classifier = \"/content/drive/My Drive/Explainability Methods/\" + str(Explainability_name) + \" on \" + str(Task_name) + \"/Model/model_classifier.pt\"\n","DataSet_name = \"MUTAG\"\n","classifier_lr = 0.001\n","classifier_dropout = 0.1\n","classifier_weight_decay = 1e-6\n","classifier_bias = True\n","\n","#File_Name = Model_name + \" \" + Explainability_name + \" \" + Task_name + \" \" + DataSet_name + \" \""],"metadata":{"id":"niO5fFsarzFY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train_dataset, test_dataset = train_test_split(dataset, test_size=0.3, random_state=0, shuffle=True)\n","#print(\"Number of Training Graphs: \", len(train_dataset))\n","#print(\"Number of Test Graphs: \", len(test_dataset))\n","\n","df = pandas.read_csv(\"/content/drive/My Drive/Explainability Methods/Train and Test Indexes on Graph Classification/Experimental Results/train_test_indexes.csv\")\n","\n","read_training_list_indexes__ = df['Train Indexes']\n","read_test_list_indexes__ = df['Test Indexes']\n","read_test_list_indexes__ = read_test_list_indexes__.dropna()\n","read_test_list_indexes = []\n","read_training_list_indexes = []\n","for element in read_test_list_indexes__:\n","    read_test_list_indexes.append(int(element))\n","for element in read_training_list_indexes__:\n","    read_training_list_indexes.append(int(element))\n","\n","\n","print(read_training_list_indexes)\n","print(read_test_list_indexes)\n","\n","mutag_train_dataset = []\n","mutag_test_dataset = []\n","for index in read_training_list_indexes:\n","    mutag_train_dataset.append(mutag_dataset[index])\n","for index in read_test_list_indexes:\n","    mutag_test_dataset.append(mutag_dataset[index])\n","\n","\n","print(f'Number of training graphs: {len(mutag_train_dataset)}')\n","print(f'Number of test graphs: {len(mutag_test_dataset)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AqaWAjKdr19L","executionInfo":{"status":"ok","timestamp":1712737559788,"user_tz":-120,"elapsed":1051,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"101e4598-4742-4453-a5a3-e2d75633c550"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[51, 142, 143, 10, 4, 141, 125, 23, 3, 79, 28, 117, 136, 156, 83, 128, 109, 70, 31, 58, 7, 148, 14, 187, 20, 162, 123, 13, 91, 185, 169, 102, 32, 55, 119, 25, 161, 175, 52, 121, 152, 108, 113, 65, 39, 103, 131, 42, 166, 110, 160, 68, 90, 89, 64, 172, 159, 72, 170, 18, 122, 29, 179, 49, 171, 178, 9, 74, 96, 48, 181, 127, 126, 87, 12, 163, 88, 53, 94, 146, 5, 158, 16, 67, 6, 59, 164, 151, 34, 47, 54, 46, 100, 112, 93, 182, 66, 106, 124, 19, 186, 133, 45, 15, 40, 167, 174, 98, 105, 153, 61, 63, 132, 116, 43, 80, 33, 147, 165, 69, 135, 86, 76, 57, 173, 115, 138, 140, 134, 180, 95, 22, 38, 41, 24, 120, 145, 26, 21, 50, 176, 107, 78, 17, 85, 154, 60, 92, 184, 129]\n","[0, 1, 2, 8, 11, 27, 30, 35, 36, 37, 44, 56, 62, 71, 73, 75, 77, 81, 82, 84, 97, 99, 101, 104, 111, 114, 118, 130, 137, 139, 144, 149, 150, 155, 157, 168, 177, 183]\n","Number of training graphs: 150\n","Number of test graphs: 38\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","\n","mutag_train_dataloader = DataLoader(mutag_train_dataset, batch_size=BATCH_SIZE, shuffle=False) # important to be false\n","mutag_test_dataloader = DataLoader(mutag_test_dataset, batch_size=1, shuffle=False)"],"metadata":{"id":"G8WzZjh6r4vo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch_geometric.datasets import FakeDataset\n","\n","num_graphs = 100\n","avg_num_nodes = 20\n","avg_degree = 15\n","node_feat_dim = 13\n","edge_feat_dim = 0\n","num_classes = 3\n","\n","fake_dataset = FakeDataset(num_graphs=num_graphs, avg_num_nodes=avg_num_nodes, avg_degree=avg_degree, num_channels=node_feat_dim,\n","                           edge_dim=edge_feat_dim, num_classes=num_classes,)\n","Explainability_name = 'PGMExplainer'\n","Task_name = 'Graph Classification'\n","classifier_bias = True\n","DataSet_name = \"Fake\"\n","BATCH_SIZE = 10\n","classifier_lr = 0.001\n","classifier_dropout = 0.1\n","classifier_weight_decay = 1e-6\n","\n","train_ratio = 0.8\n","\n","fake_train_dataset = fake_dataset[:int(len(fake_dataset) * train_ratio)]\n","fake_test_dataset = fake_dataset[len(fake_dataset) - int(len(fake_dataset) * train_ratio):]\n","\n","fake_train_dataloader = DataLoader(fake_train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","fake_test_dataloader = DataLoader(fake_test_dataset, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"id":"ntc7bRGpGrKb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","py_path = '/content/drive/MyDrive/Explainability Methods/Models/Script/'\n","sys.path.insert(0,py_path)\n","\n","#import GCN_plus_GAP as Graph_Network\n","#GNN_Model = Graph_Network.GCN_plus_GAP(model_name='GCN_plus_GAP', model_level='graph', input_dim=13, hidden_dim=13, output_dim=3,\n","#                                       num_hid_layers=3, Bias=classifier_bias, act_fun='ReLu', Weight_Initializer=1,\n","#                                       dropout_rate=classifier_dropout)\n","\n","#import DGCNN as dgcnn_model\n","#GNN_Model = dgcnn_model.DGCNN_Model(GNN_layers=[32, 32, 32, 13], num_classes=3, node_feat_size=13, mlp_act_fun='ReLu',\n","#                                    dgcnn_act_fun='tanh', mlp_dropout_rate=0.5, Weight_Initializer=3, Bias=False, dgcnn_k=17,\n","#                                    hid_channels=[16,32], conv1d_kernels=[2,5], ffn_layer_size=128, strides=[2,1])\n","\n","#import DIFFPOOL as diffpool_model\n","#GNN_Model = diffpool_model.DIFFPOOL_Model(embedding_input_dim=13, embedding_num_block_layers=1, embedding_hid_dim=64,\n","#                                          new_feature_size=64, assignment_input_dim=13, assignment_num_block_layers=1,\n","#                                          assignment_hid_dim=64, max_number_of_nodes=256, prediction_hid_layers=[50],\n","#                                          concat_neighborhood=False, num_classes=3, Weight_Initializer=1, Bias=classifier_bias,\n","#                                          dropout_rate=0, normalize_graphsage=False, aggregation=\"mean\", act_fun=\"ReLu\",\n","#                                          concat_diffpools_outputs=True, num_pooling=1, pooling=\"mean\")\n","\n","import GIN as gin_model\n","GNN_Model = gin_model.GIN_Model(num_mlp_layers=4, mlp_input_dim=13, mlp_hid_dim=20, mlp_output_dim=2, num_slp_layers=2,\n","                                Bias=classifier_bias, mlp_act_fun=\"ReLu\", dropout_rate=classifier_dropout, Weight_Initializer=1,\n","                                joint_embeddings=False)\n","\n","\n","\n","Model_name = GNN_Model.__class__.__name__"],"metadata":{"id":"9WE16dORr7HL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GNN_Model_Optimizer = torch.optim.Adam(GNN_Model.parameters(), lr=classifier_lr, weight_decay=classifier_weight_decay)"],"metadata":{"id":"jNYXiwLvsOUF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.CrossEntropyLoss()\n","def loss_calculations(preds, gtruth):\n","    loss_per_epoch = criterion(preds, gtruth)\n","    return loss_per_epoch"],"metadata":{"id":"HLOqL8O2sQYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualize_losses(GNN_Model_losses, epoch_history):\n","    GNN_Model_losses_list = torch.stack(GNN_Model_losses).cpu().detach().numpy()\n","\n","    fig = plt.figure(figsize=(27,20))\n","\n","    ax = plt.subplot2grid((3, 1), (0, 0), colspan=1)\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title(\" Loss in Epoch: \" + str(epoch_history))\n","\n","    ax.plot(GNN_Model_losses_list, color='r')\n","\n","    #plt.savefig('/content/drive/My Drive/Explainability Methods/'+str(Explainability_name)+' on ' + str(Task_name) + '/Experimental Results/' + File_Name + 'Loss_til_epoch_{:04d}.png'.format(epoch_history))\n","    plt.show()\n"],"metadata":{"id":"yfnOBKFvsSlL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_step(data):\n","    GNN_Model_loss_batch = []\n","    Pred_Labels = []\n","    Real_Labels = []\n","\n","    GNN_Model.train()\n","    GNN_Model.zero_grad()\n","    for batch_of_graphs in data:\n","        if GNN_Model.__class__.__name__ == \"GCN_plus_GAP\":\n","            Output_of_Hidden_Layers, pooling_layer_output, ffn_output, soft = GNN_Model(batch_of_graphs)\n","            batch_loss = loss_calculations(soft, batch_of_graphs.y)\n","            Pred_Labels.extend(soft.argmax(dim=1).detach().tolist())\n","\n","        elif GNN_Model.__class__.__name__ == \"DGCNN_Model\":\n","            final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, softmaxed_h2 = GNN_Model(batch_of_graphs, None)\n","            batch_loss = loss_calculations(softmaxed_h2, batch_of_graphs.y)\n","            Pred_Labels.extend(softmaxed_h2.argmax(dim=1).detach().tolist())\n","\n","        elif GNN_Model.__class__.__name__ == \"DIFFPOOL_Model\":\n","            concatination_list_of_poolings, prediction_output_without_soft, prediction_output = GNN_Model(batch_of_graphs, None)\n","            Pred_Labels.extend(prediction_output.argmax(dim=1).detach().tolist())\n","            batch_loss = loss_calculations(prediction_output, batch_of_graphs.y)\n","\n","        elif GNN_Model.__class__.__name__ == \"GIN_Model\":\n","            mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, lin2_output_softmaxed = GNN_Model(batch_of_graphs, None)\n","            batch_loss = loss_calculations(lin2_output_softmaxed, batch_of_graphs.y)\n","            Pred_Labels.extend(lin2_output_softmaxed.argmax(dim=1).detach().tolist())\n","        else:\n","            raise Exception(\"We cover GCN_plus_GAP, DGCNN, DIFFPOOL, and GIN.\")\n","\n","        Real_Labels.extend(batch_of_graphs.y.detach().tolist())\n","        GNN_Model_loss_batch.append(batch_loss)\n","\n","        batch_loss.backward()\n","        GNN_Model_Optimizer.step()\n","\n","    return torch.mean(torch.tensor(GNN_Model_loss_batch)), metrics.accuracy_score(Real_Labels, Pred_Labels)"],"metadata":{"id":"ly-3iLGasUb5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GNN_Model_training_Acc_per_epoch = []\n","GNN_Model_training_time_per_epoch = []\n","def train(EPOCHS, load_index, data):\n","    GNN_Model_training_loss_per_epoch = []\n","\n","    for epoch in range(EPOCHS):\n","        t1 = perf_counter()\n","        GNN_Model_training_loss, training_acc = train_step(data)\n","        GNN_Model_training_time_per_epoch.append(perf_counter()-t1)\n","        print(f'Epoch: {epoch+1:03d}, Model Loss: {GNN_Model_training_loss:.4f}')\n","\n","        GNN_Model_training_loss_per_epoch.append(GNN_Model_training_loss)\n","        GNN_Model_training_Acc_per_epoch.append(training_acc)\n","        #break\n","\n","        if (epoch + load_index + 1) % 50 == 0 and epoch > 0:\n","            visualize_losses(GNN_Model_training_loss_per_epoch, epoch + load_index + 1)\n","        #if (epoch + load_index + 1) % 100 == 0 and epoch > 0:\n","        #  torch.save({'epoch': epoch+load_index+1, 'model_state_dict': GNN_Model.state_dict(), 'optimizer_state_dict': GNN_Model_Optimizer.state_dict(), 'loss': GNN_Model_training_loss_per_epoch,}, \"/content/drive/My Drive/Explainability Methods/\" + str(Explainability_name) + \" on \" + str(Task_name) + \"/Model/\" + File_Name + str(epoch + load_index + 1)+\".pt\")\n","\n"],"metadata":{"id":"b7OcmZVksWDf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 300\n","load_index = 0\n","\n","train(EPOCHS, load_index, fake_train_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":809},"id":"x9ezj_FisX1T","executionInfo":{"status":"error","timestamp":1712749569157,"user_tz":-120,"elapsed":3467,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"751fa19a-b42b-4731-b49c-f82cb9c178f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 001, Model Loss: 1.1954\n","Epoch: 002, Model Loss: 1.1402\n","Epoch: 003, Model Loss: 1.1483\n","Epoch: 004, Model Loss: 1.1139\n","Epoch: 005, Model Loss: 1.1787\n","Epoch: 006, Model Loss: 1.1013\n","Epoch: 007, Model Loss: 1.0583\n","Epoch: 008, Model Loss: 1.0322\n","Epoch: 009, Model Loss: 1.0363\n","Epoch: 010, Model Loss: 1.0188\n","Epoch: 011, Model Loss: 1.0504\n","Epoch: 012, Model Loss: 1.0698\n","Epoch: 013, Model Loss: 1.0510\n","Epoch: 014, Model Loss: 1.0194\n","Epoch: 015, Model Loss: 1.0082\n","Epoch: 016, Model Loss: 1.0236\n","Epoch: 017, Model Loss: 1.0089\n","Epoch: 018, Model Loss: 1.0113\n","Epoch: 019, Model Loss: 0.9872\n","Epoch: 020, Model Loss: 1.0139\n","Epoch: 021, Model Loss: 0.9949\n","Epoch: 022, Model Loss: 0.9889\n","Epoch: 023, Model Loss: 1.0009\n","Epoch: 024, Model Loss: 1.0083\n","Epoch: 025, Model Loss: 0.9950\n","Epoch: 026, Model Loss: 0.9714\n","Epoch: 027, Model Loss: 0.9808\n","Epoch: 028, Model Loss: 0.9767\n","Epoch: 029, Model Loss: 0.9541\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-112-160e6d1c034c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mload_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_train_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-c8a694549ac4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(EPOCHS, load_index, data)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mGNN_Model_training_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mGNN_Model_training_time_per_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch+1:03d}, Model Loss: {GNN_Model_training_loss:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-1a4c2c05132a>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mGNN_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GIN_Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mmlps_output_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlps_output_embeds_stacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_outputs_globalSUMpooled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_mlps_output_embeds_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlin1_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlin1_output_dropouted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlin2_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlin2_output_softmaxed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGNN_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_of_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_calculations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin2_output_softmaxed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_of_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mPred_Labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin2_output_softmaxed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Explainability Methods/Models/Script/GIN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_graphs, edge_mask)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatched_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mgraph_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mnum_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Explainability Methods/Models/Script/GIN.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatched_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mgraph_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mnum_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 or (isinstance(idx, np.ndarray) and np.isscalar(idx))):\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         elif isinstance(idx, str) or (isinstance(idx, tuple)\n\u001b[1;32m    179\u001b[0m                                       and isinstance(idx[0], str)):\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mget_example\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    122\u001b[0m                  \"'Batch' was not created via 'Batch.from_data_list()'\"))\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         data = separate(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__bases__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["GNN_Model_test_predicted_labels = []\n","def GNN_Model_test(test_loader):\n","    GNN_Model.eval()\n","    correct = 0\n","\n","    for batch_of_graphs in test_loader:\n","        if GNN_Model.__class__.__name__ == \"GCN_plus_GAP\":\n","            Output_of_Hidden_Layers, pooling_layer_output, ffn_output, soft = GNN_Model(batch_of_graphs)\n","            GNN_Model_test_pred = soft.argmax(dim=1)\n","        elif GNN_Model.__class__.__name__ == \"DGCNN_Model\":\n","            final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, soft = GNN_Model(batch_of_graphs, None)\n","            GNN_Model_test_pred = soft.argmax(dim=1)\n","        elif GNN_Model.__class__.__name__ == \"DIFFPOOL_Model\":\n","            concatination_list_of_poolings, prediction_output_without_soft, soft = GNN_Model(batch_of_graphs, None)\n","            GNN_Model_test_pred = soft.argmax(dim=1)\n","        elif GNN_Model.__class__.__name__ == \"GIN_Model\":\n","            mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, soft = GNN_Model(batch_of_graphs, None)\n","            GNN_Model_test_pred = soft.argmax(dim=1)\n","\n","        GNN_Model_test_predicted_labels.append(GNN_Model_test_pred.tolist()[0])\n","        correct += int((GNN_Model_test_pred == batch_of_graphs.y).sum())\n","    return correct / len(test_loader.dataset), GNN_Model_test_predicted_labels"],"metadata":{"id":"iixavDbnG8xt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GNN_Model_test_acc, predicted_labels = GNN_Model_test(fake_test_dataloader)\n","print(f'Test Accuracy: {GNN_Model_test_acc:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-lB7ajZAG_Y8","executionInfo":{"status":"ok","timestamp":1712749162942,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"d5207a48-071d-4cc9-cacb-aef40ffbc9bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.6250\n"]}]},{"cell_type":"code","source":["def power_divergence(X, Y, Z, data_pertubed_Samples, lambda_, significance_level):\n","    if hasattr(Z, \"__iter__\"):\n","        Z = list(Z)\n","    else:\n","        raise (f\"Z must be an iterable. Got object type: {type(Z)}\")\n","\n","    if (X in Z) or (Y in Z):\n","        raise ValueError(f\"The variables X or Y can't be in Z. Found {X if X in Z else Y} in Z.\")\n","    if len(Z) == 0:\n","        chi, p_value, dof, expected = stats.chi2_contingency(\n","            data_pertubed_Samples.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n","        )\n","    else:\n","        chi = 0\n","        dof = 0\n","        for z_state, df in data_pertubed_Samples.groupby(Z):\n","            try:\n","                c, _, d, _ = stats.chi2_contingency(df.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_)\n","                chi += c\n","                dof += d\n","            except ValueError:\n","                if isinstance(z_state, str):\n","                    logging.info(f\"Skipping the test {X} \\u27C2 {Y} | {Z[0]}={z_state}. Not enough samples\")\n","                else:\n","                    z_str = \", \".join([f\"{var}={state}\" for var, state in zip(Z, z_state)])\n","                    logging.info(f\"Skipping the test {X} \\u27C2 {Y} | {z_str}. Not enough samples\")\n","        p_value = 1 - stats.chi2.cdf(chi, df=dof)\n","    return chi, p_value, dof"],"metadata":{"id":"lpZFZWsn53qi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cressie_read(X, Y, Z, data_pertubed_Samples, significance_level):\n","    return power_divergence(X=X, Y=Y, Z=Z, data_pertubed_Samples=data_pertubed_Samples, lambda_=\"cressie-read\", significance_level=significance_level)"],"metadata":{"id":"tIjb7HJb5kl5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = [3.01599503e-05, 0.00000000e+00, 2, 3.01599503e-05, 1]\n","y = np.array(x)\n","print(y)\n","z = np.argsort(y)[-3:]\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzIP245aj_6_","executionInfo":{"status":"ok","timestamp":1686271501739,"user_tz":-120,"elapsed":9,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"9f69442a-3468-4911-bc87-4e79b688f561"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[3.01599503e-05 0.00000000e+00 2.00000000e+00 3.01599503e-05\n"," 1.00000000e+00]\n","[3 4 2]\n"]}]},{"cell_type":"code","source":["if GNN_Model.__class__.__name__ == \"GCN_plus_GAP\":\n","    Output_of_Hidden_Layers, pooling_layer_output, ffn_output, soft = GNN_Model(batch_of_graphs)\n","\n","\n","elif GNN_Model.__class__.__name__ == \"DGCNN_Model\":\n","    final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, softmaxed_h2 = GNN_Model(batch_of_graphs, None)\n","\n","\n","elif GNN_Model.__class__.__name__ == \"DIFFPOOL_Model\":\n","    concatination_list_of_poolings, prediction_output_without_soft, prediction_output = GNN_Model(batch_of_graphs, None)\n","\n","\n","elif GNN_Model.__class__.__name__ == \"GIN_Model\":\n","    mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, lin2_output_softmaxed = GNN_Model(batch_of_graphs, None)\n"],"metadata":{"id":"RupZ1LthLbOW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PGM_Graph_Explainer(object):\n","    def __init__(self, GNN_Model, graph, perturb_feature_list, perturb_mode, perturb_indicator):\n","\n","        self.Task_name = 'Graph Classification'\n","        self.Explainability_name = \"PGMExplainer\"\n","        self.GNN_Model = GNN_Model\n","        self.GNN_Model.eval()\n","\n","        self.graph = graph\n","        self.num_layers = 2\n","        self.perturb_feature_list = perturb_feature_list\n","        self.perturb_mode = perturb_mode\n","        self.perturb_indicator = perturb_indicator\n","        self.node_feat = graph.x.numpy()\n","\n","\n","\n","    def cressie_read(self, X, Y, Z, data_pertubed_Samples, significance_level):\n","        return self.power_divergence(X=X, Y=Y, Z=Z, data_pertubed_Samples=data_pertubed_Samples, lambda_=\"cressie-read\", significance_level=significance_level)\n","\n","    def power_divergence(self, X, Y, Z, data_pertubed_Samples, lambda_, significance_level):\n","        if hasattr(Z, \"__iter__\"):\n","            Z = list(Z)\n","        else:\n","            raise (f\"Z must be an iterable. Got object type: {type(Z)}\")\n","\n","        if (X in Z) or (Y in Z):\n","            raise ValueError(f\"The variables X or Y can't be in Z. Found {X if X in Z else Y} in Z.\")\n","        if len(Z) == 0:\n","            chi, p_value, dof, expected = stats.chi2_contingency(\n","                data_pertubed_Samples.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n","            )\n","        else:\n","            chi = 0\n","            dof = 0\n","            for z_state, df in data_pertubed_Samples.groupby(Z):\n","                try:\n","                    c, _, d, _ = stats.chi2_contingency(df.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_)\n","                    chi += c\n","                    dof += d\n","                except ValueError:\n","                    if isinstance(z_state, str):\n","                        logging.info(f\"Skipping the test {X} \\u27C2 {Y} | {Z[0]}={z_state}. Not enough samples\")\n","                    else:\n","                        z_str = \", \".join([f\"{var}={state}\" for var, state in zip(Z, z_state)])\n","                        logging.info(f\"Skipping the test {X} \\u27C2 {Y} | {z_str}. Not enough samples\")\n","            p_value = 1 - stats.chi2.cdf(chi, df=dof)\n","        return chi, p_value, dof\n","\n","\n","    def perturb_node_features(self, node_feature_matrix, targeted_node_idx, random_perturbation_permission):\n","\n","        graph_node_features = deepcopy(node_feature_matrix)\n","        targeted_node_feat_to_perturb_array = deepcopy(graph_node_features[targeted_node_idx])\n","        # print(\"targeted_node_feat_to_perturb_array: \", targeted_node_feat_to_perturb_array)\n","        epsilon = 0.05 * np.max(self.node_feat, axis = 0)\n","\n","        if random_perturbation_permission == 1:\n","            for i in range(targeted_node_feat_to_perturb_array.shape[0]):\n","                if i in self.perturb_feature_list:\n","                    if self.perturb_mode == \"mean\":\n","                        targeted_node_feat_to_perturb_array[i] = np.mean(node_feature_matrix[:,i])\n","                    elif self.perturb_mode == \"zero\":\n","                        targeted_node_feat_to_perturb_array[i] = 0\n","                    elif self.perturb_mode == \"max\":\n","                        targeted_node_feat_to_perturb_array[i] = np.max(node_feature_matrix[:,i])\n","                    elif self.perturb_mode == \"uniform\":\n","                        targeted_node_feat_to_perturb_array[i] = targeted_node_feat_to_perturb_array[i] + np.random.uniform(low=-epsilon[i], high=epsilon[i])\n","                        if targeted_node_feat_to_perturb_array[i] < 0:\n","                            targeted_node_feat_to_perturb_array[i] = 0\n","                        elif targeted_node_feat_to_perturb_array[i] > np.max(self.node_feat, axis = 0)[i]:\n","                            targeted_node_feat_to_perturb_array[i] = np.max(self.node_feat, axis = 0)[i]\n","\n","        graph_node_features[targeted_node_idx] = targeted_node_feat_to_perturb_array\n","\n","        return graph_node_features\n","\n","    def gather_perturbed_node_features(self, sampling_count, index_to_perturb, noise_offset_percentage, p_value_threshold, class_index):\n","        if self.GNN_Model.__class__.__name__ == \"GCN_plus_GAP\":\n","            Output_of_Hidden_Layers, pooling_layer_output, ffn_output, pred_torch = self.GNN_Model(self.graph)\n","        elif self.GNN_Model.__class__.__name__ == \"DGCNN_Model\":\n","            final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, pred_torch = self.GNN_Model(self.graph, None)\n","        elif self.GNN_Model.__class__.__name__ == \"DIFFPOOL_Model\":\n","            concatination_list_of_poolings, pred_torch_without_soft, pred_torch = self.GNN_Model(self.graph, None)\n","        elif GNN_Model.__class__.__name__ == \"GIN_Model\":\n","            mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, pred_torch = self.GNN_Model(self.graph, None)\n","\n","        #pred_label = pred_torch.argmax(dim=1)\n","        pred_label = pred_torch.detach()[:,class_index].to(torch.float32).tolist()[0]\n","\n","        num_nodes_in_graph = self.node_feat.shape[0]\n","\n","        Samples = []\n","        for iteration in range(sampling_count):\n","            graph_original_features = deepcopy(self.node_feat)\n","            sample = []\n","            for node_index in range(num_nodes_in_graph):\n","                if node_index in index_to_perturb:\n","                    seed = np.random.randint(100)\n","                    if seed < noise_offset_percentage:\n","                        random_perturbation_permission = 1\n","                        graph_perturbed_features = self.perturb_node_features(node_feature_matrix=graph_original_features, targeted_node_idx=node_index,\n","                                                                              random_perturbation_permission=random_perturbation_permission)\n","                    else:\n","                        random_perturbation_permission = 0\n","                else:\n","                    random_perturbation_permission = 0\n","                sample.append(random_perturbation_permission)\n","\n","                perturbed_graph = deepcopy(self.graph)\n","                if random_perturbation_permission:\n","                    graph_perturbed_features_torch =  torch.tensor(graph_perturbed_features, dtype=torch.float)\n","                    perturbed_graph.x = graph_perturbed_features_torch\n","\n","                if self.GNN_Model.__class__.__name__ == \"GCN_plus_GAP\":\n","                    Output_of_Hidden_Layers, pooling_layer_output, ffn_output, pred_perturb_torch = self.GNN_Model(perturbed_graph)\n","                elif self.GNN_Model.__class__.__name__ == \"DGCNN_Model\":\n","                    final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, pred_perturb_torch = self.GNN_Model(perturbed_graph, None)\n","                elif self.GNN_Model.__class__.__name__ == \"DIFFPOOL_Model\":\n","                    concatination_list_of_poolings, pred_torch_without_soft, pred_perturb_torch = self.GNN_Model(perturbed_graph, None)\n","                elif GNN_Model.__class__.__name__ == \"GIN_Model\":\n","                    mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, pred_perturb_torch = self.GNN_Model(perturbed_graph, None)\n","\n","\n","                pred_change = pred_torch.detach()[:,class_index].to(torch.float32).tolist()[0] - pred_perturb_torch.detach()[:,class_index].to(torch.float32).tolist()[0]\n","\n","\n","                sample.append(pred_change)\n","            Samples.append(sample)\n","\n","        Samples = np.asarray(Samples)\n","        if self.perturb_indicator == \"abs\":\n","            Samples = np.abs(Samples)\n","\n","        top = int(sampling_count/8)\n","        top_idx = np.argsort(Samples[:, num_nodes_in_graph])[-top:]\n","\n","        for i in range(sampling_count):\n","            if i in top_idx:\n","                Samples[i,num_nodes_in_graph] = 1\n","            else:\n","                Samples[i,num_nodes_in_graph] = 0\n","\n","        return Samples\n","\n","    def explain(self, num_samples, noise_offset_percentage, top_node, p_value_threshold, class_index):\n","\n","        if top_node == None:\n","            top_node = int(self.node_feat.shape[0]/8)\n","\n","#         Round 1\n","        Samples = self.gather_perturbed_node_features(sampling_count=num_samples, index_to_perturb=range(self.node_feat.shape[0]),\n","                                                      noise_offset_percentage=noise_offset_percentage,\n","                                                      p_value_threshold=p_value_threshold, class_index=class_index)\n","\n","        data_pertubed_Samples1 = pd.DataFrame(Samples)\n","\n","        p_values = []\n","        candidate_nodes = []\n","        # The entry for the graph classification data is at \"num_nodes\"\n","        for node in range(self.node_feat.shape[0]):\n","            chi2, p, dof = self.cressie_read(X=node, Y=self.node_feat.shape[0], Z=[], data_pertubed_Samples=data_pertubed_Samples1, significance_level=0.05)\n","            #print(\"this is returned P: \", p)\n","            p_values.append(p)\n","\n","\n","        number_candidates = top_node\n","        candidate_nodes = np.argpartition(p_values, number_candidates)[0:number_candidates]\n","\n","#         Round 2\n","        Samples = self.gather_perturbed_node_features(sampling_count=num_samples, index_to_perturb=candidate_nodes,\n","                                                      noise_offset_percentage=noise_offset_percentage,\n","                                                      p_value_threshold=p_value_threshold, class_index=class_index)\n","        data = pd.DataFrame(Samples)\n","        #est = ConstraintBasedEstimator(data)\n","\n","        p_values = []\n","        dependent_nodes = []\n","\n","        for node in range(self.node_feat.shape[0]):\n","            chi2, p, dof = self.cressie_read(X=node, Y=self.node_feat.shape[0], Z=[], data_pertubed_Samples=data, significance_level=0.05)\n","            #chi2, p = chi_square(node, target, [], data)\n","            p_values.append(p)\n","            if p < p_value_threshold:\n","                dependent_nodes.append(node)\n","\n","\n","        top_p = np.min((top_node, self.node_feat.shape[0]-1))\n","        ind_top_p = np.argpartition(p_values, top_p)[0:top_p]\n","        pgm_nodes = list(ind_top_p)\n","\n","        return pgm_nodes, p_values, candidate_nodes, dependent_nodes\n","\n","input_graph = fake_test_dataset[0]\n","pgmx = PGM_Graph_Explainer(GNN_Model=GNN_Model, graph=input_graph, perturb_feature_list=[None], perturb_mode = \"mean\",\n","                           perturb_indicator = \"abs\")\n","\n","\n","\n","pgm_nodes, p_values, candidate_nodes, dependent_nodes = pgmx.explain(num_samples=len(input_graph.x), noise_offset_percentage=50,\n","                                                                     top_node=5, p_value_threshold=0.05, class_index=2)\n","print(\"pgm_nodes: \", pgm_nodes, \" p_values: \", p_values, \" candidate_nodes: \", candidate_nodes, \"dependent_nodes: \", dependent_nodes)"],"metadata":{"id":"DZc3q9eAtTCY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712751098523,"user_tz":-120,"elapsed":7964,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"7bd46e95-89d7-4d20-e76a-be7707647e18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pgm_nodes:  [8, 0, 20, 18, 17]  p_values:  [0.4500218182533767, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4500218182533767, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4500218182533767, 1.0, 1.0, 1.0, 1.0]  candidate_nodes:  [ 4  0 10 22 16] dependent_nodes:  []\n"]}]},{"cell_type":"code","source":["pgm_nodes_for_each_graph_correct = []\n","pgm_nodes_for_each_graph_incorrect = []\n","time_consumption = []\n","\n","for i in range(len(test_dataset)):\n","\n","    pgmx = PGM_Graph_Explainer(Model_Name=\"GCN_plus_GAP\", classifier_load_index=200, input_dim=7, hid_dim=7, output_dim=2, graph=test_dataset[i],\n","                           perturb_feature_list=[None], perturb_mode = \"mean\", perturb_indicator = \"abs\")\n","    start_time = perf_counter()\n","    pgm_node_correct, p_values_correct, candidate_nodes_correct, dependent_nodes_correct = pgmx.explain(num_samples=len(test_dataset[i].x), percentage=50,\n","                                                                                                        top_node=3, p_value_threshold=0.05, pred_threshold=0.1,\n","                                                                                                        ctg='correct')\n","    pgm_nodes_for_each_graph_correct.append(pgm_node_correct)\n","    print(pgm_node_correct)\n","    time_consumption.append(perf_counter() - start_time)\n","    pgm_node_incorrect, p_values_incorrect, candidate_nodes_incorrect, dependent_nodes_incorrect = pgmx.explain(num_samples=len(test_dataset[i].x), percentage=50,\n","                                                                                                                top_node=3, p_value_threshold=0.05, pred_threshold=0.1,\n","                                                                                                                ctg='incorrect')\n","    pgm_nodes_for_each_graph_incorrect.append(pgm_node_incorrect)\n","    print(pgm_node_incorrect)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPEefk3_S7lo","executionInfo":{"status":"ok","timestamp":1691345389150,"user_tz":-120,"elapsed":79210,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"93348ed4-858a-444b-ecd7-d243de1cdfdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[0, 4, 12]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 11, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 11, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 10, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[4, 15, 13]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[16, 12, 11]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[8, 16, 14]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[10, 12, 8]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[8, 12, 11]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[0, 12, 10]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 10, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[17, 15, 13]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[15, 0, 14]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[0, 13, 11]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[15, 14, 17]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[4, 6, 8]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[4, 13, 11]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[16, 15, 18]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[12, 13, 11]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[8, 16, 17]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 11, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[12, 13, 11]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[17, 16, 19]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[12, 14, 11]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[11, 12, 10]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 10, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[14, 0, 15]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[4, 15, 13]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 11, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[12, 13, 11]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[12, 13, 11]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 10, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 10, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 10, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[16, 15, 13]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 8, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[9, 11, 7]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n","GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","eLu is Selected.\n","[4, 20, 16]\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"]}]},{"cell_type":"code","source":["print(len(time_consumption))\n","print(\"time_consumption: \", time_consumption)\n","print(statistics.mean(time_consumption))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M8K4yBRwtJDG","executionInfo":{"status":"ok","timestamp":1691345460752,"user_tz":-120,"elapsed":205,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"b025972e-6ec0-4ff0-b29f-6ed0bf4b9902"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["38\n","time_consumption:  [1.2668439719998332, 0.7257683390000693, 0.5176655889999893, 0.4637203419999878, 1.1856211930000882, 0.8756083120001676, 1.43473268799994, 0.784289211999976, 1.206816420999985, 0.9334678580000855, 0.458032158999913, 1.3268337969998356, 1.5880233769998995, 0.782993728000065, 3.1137604319999355, 0.31455042399988997, 0.8084150800000316, 1.8498538839999128, 0.7707757169998786, 1.612811750999981, 0.7144284099999823, 1.040602447999845, 2.000002936000101, 0.879968295000026, 0.6790533230000619, 0.4538765649999732, 1.4987819080001827, 1.5494426990001102, 0.5338968629998817, 0.7835497840001153, 0.786208839999972, 0.4591743739999856, 0.4762122529998578, 0.44717787499985207, 1.190471634000005, 0.7176257379999242, 0.7385628520000864, 1.7875504660000843]\n","1.019925566789461\n"]}]},{"cell_type":"code","source":["test_dataset_dropped_correct = deepcopy(test_dataset)\n","test_dataset_dropped_incorrect = deepcopy(test_dataset)\n","\n","\n","for i in range(len(pgm_nodes_for_each_graph_correct)):\n","    for j in range(len(test_dataset_dropped_correct[i].x)):\n","        if j not in pgm_nodes_for_each_graph_correct[i]:\n","            test_dataset_dropped_correct[i].x[j] = torch.zeros_like(test_dataset_dropped_correct[i].x[j])\n","\n","for i in range(len(pgm_nodes_for_each_graph_incorrect)):\n","    for j in range(len(test_dataset_dropped_incorrect[i].x)):\n","        if j not in pgm_nodes_for_each_graph_incorrect[i]:\n","            test_dataset_dropped_incorrect[i].x[j] = torch.zeros_like(test_dataset_dropped_incorrect[i].x[j])\n"],"metadata":{"id":"OtAIBU5pD-9W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(pgm_nodes_for_each_graph_correct[0])\n","print(test_dataset_dropped_correct[0].x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zM5IVOEyYcUu","executionInfo":{"status":"ok","timestamp":1691345467578,"user_tz":-120,"elapsed":225,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"0489d150-ef56-48b0-8289-7b73759a4bce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 4, 12]\n","tensor([[1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0.]])\n"]}]},{"cell_type":"code","source":["Model_Load_iNdex = 1000\n","GNN_Model = Graph_Network.GCN_plus_GAP(model_name=Model_Name, model_level='graph', input_dim=7, hidden_dim=7, output_dim=2,\n","                                       num_hid_layers=2, Bias=True, act_fun='ReLu', Weight_Initializer=1, dropout_rate=0.1)\n","optimizer = torch.optim.Adam(params=GNN_Model.parameters(), lr=0.001, weight_decay=1e-6)\n","checkpoint = torch.load(\"/content/drive/My Drive/Explainability Methods/\" + str(Explainability_name) + \" on \" + str(Task_name) + \"/Model/\" + str(Model_Name) + \"_Model_classifier\" + str(Model_Load_iNdex)+\".pt\")\n","GNN_Model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l-Kp5c3xRA_2","executionInfo":{"status":"ok","timestamp":1691345479230,"user_tz":-120,"elapsed":825,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"a3b99c6d-89a6-4df4-d512-ae0f6b2bdccf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GCN_plus_GAP Input_Dimension: 7\n","GCN_plus_GAP Hidden_Dimension: 7\n","GCN_plus_GAP Output_Dimension: 2\n","GCN_plus_GAP Number_of_Hidden_Layers: 2\n","ReLu is Selected.\n"]}]},{"cell_type":"code","source":["def Compute_ROC_AUC(your_model, your_dataset, masked):\n","    preds = []\n","    reals = []\n","    if masked == False:\n","        your_model.eval()\n","        for batched_data in your_dataset:\n","            #final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, softmaxed_h2 = your_model(batched_data)\n","            #Grad_CAM_Test_One_Before_Last_Conv, Grad_CAM_Test_Last_Conv, Grad_CAM_Test_GAP, Grad_CAM_Test_out = your_model(batched_data)\n","            Output_of_Hidden_Layers, pooling_layer_output, ffn_output, soft = your_model(batched_data)\n","            #logits = F.log_softmax(Grad_CAM_Test_out, dim=1)\n","            #prob = F.softmax(logits, dim=1)\n","\n","            preds.append(soft.cpu().detach())\n","    else:\n","\n","        your_model.eval()\n","        for masked_batch in masked:\n","            #final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, softmaxed_h2 = your_model(batched_data)\n","            #Grad_CAM_Test_One_Before_Last_Conv, Grad_CAM_Test_Last_Conv, Grad_CAM_Test_GAP, Grad_CAM_Test_out = your_model(batched_data)\n","            Output_of_Hidden_Layers, pooling_layer_output, ffn_output, soft = your_model(masked_batch)\n","            #logits = F.log_softmax(Grad_CAM_Test_out, dim=1)\n","            #prob = F.softmax(logits, dim=1)\n","\n","            preds.append(soft.cpu().detach())\n","\n","\n","\n","\n","    for i, batched_graph in enumerate(your_dataset):\n","        reals.append(batched_graph.y.cpu().detach().tolist())\n","    #preds = torch.cat(preds).cpu().numpy()\n","    #preds = preds[:, 1]\n","    preds = torch.cat(preds)\n","    #print(preds)\n","    preds, max_idxs = torch.max(preds[:], dim=1)\n","    #print(preds)\n","    roc_auc = metrics.roc_auc_score(reals, preds, average='macro')\n","    return roc_auc\n","\n","\n","def Fidelity_computation(your_model, your_dataset, importance_threshold):\n","    auc_roc_before_droping_important_nodes = Compute_ROC_AUC(your_model, your_dataset, False)\n","    print(\"auc_roc_before_droping_important_nodes: \", auc_roc_before_droping_important_nodes)\n","\n","    auc_roc_after_droping_important_nodes = Compute_ROC_AUC(your_model, your_dataset, test_dataset_dropped_correct)\n","    print(\"auc_roc_after_droping_important_nodes: \", auc_roc_after_droping_important_nodes)\n","\n","    return auc_roc_before_droping_important_nodes - auc_roc_after_droping_important_nodes\n","fid0 = Fidelity_computation(GNN_Model, test_dataset, test_dataset_dropped_correct)\n","fid1 = Fidelity_computation(GNN_Model, test_dataset, test_dataset_dropped_incorrect)\n","print(\"Fidelity: \", mean([fid0, fid1]))"],"metadata":{"id":"CtDmeySkbIoF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691345513586,"user_tz":-120,"elapsed":222,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"36b42cc0-2b76-4763-95b1-2688b5ae9c4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["auc_roc_before_droping_important_nodes:  0.5505952380952381\n","auc_roc_after_droping_important_nodes:  0.42857142857142855\n","auc_roc_before_droping_important_nodes:  0.5505952380952381\n","auc_roc_after_droping_important_nodes:  0.42857142857142855\n","Fidelity:  0.12202380952380959\n"]}]},{"cell_type":"code","source":["def crs_subgraph_saliency(your_dataset, masked_data_class0, masked_data_class1):\n","    binary_scores_class0 = []\n","    binary_scores_class1 = []\n","    for graph_main, graph0, graph1 in zip(your_dataset, masked_data_class0, masked_data_class1):\n","        binary_score_class0 = ''\n","        binary_score_class1 = ''\n","        for node_main, node0, node1 in zip(graph_main.x, graph0.x, graph1.x):\n","            if sum(node0) == 0:\n","                binary_score_class0 += '1'\n","            else:\n","                binary_score_class0 += '0'\n","            if sum(node1) == 0:\n","                binary_score_class1 += '1'\n","            else:\n","                binary_score_class1 += '0'\n","        binary_scores_class0.append(binary_score_class0)\n","        binary_scores_class1.append(binary_score_class1)\n","    #print(\"binary_scores_class0: \", binary_scores_class0)\n","    #print(\"binary_scores_class1: \", binary_scores_class1)\n","    return binary_scores_class0, binary_scores_class1\n","\n","def hamming_distance(string1, string2):\n","\n","    distance = 0\n","    L = len(string1)\n","    for i in range(L):\n","        if string1[i] != string2[i]:\n","            distance += 1\n","    return distance\n","\n","def compute_contrastivity(your_dataset, masked_data_class0, masked_data_class1):\n","    binary_scores_class0, binary_scores_class1 = crs_subgraph_saliency(your_dataset, masked_data_class0, masked_data_class1)\n","    h_dist_list = []\n","    for cor_bin_scores, incor_bin_scores in zip(binary_scores_class0, binary_scores_class1):\n","        h_distance = hamming_distance(cor_bin_scores, incor_bin_scores)/len(cor_bin_scores)\n","        h_dist_list.append(h_distance)\n","    return statistics.mean(h_dist_list)\n","\n","\n","\n","crs = compute_contrastivity(test_dataset, test_dataset_dropped_correct, test_dataset_dropped_incorrect)\n","print(\"Contrastivity: \", crs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AXWwflX1jjmG","executionInfo":{"status":"ok","timestamp":1691345619794,"user_tz":-120,"elapsed":201,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"d2981749-2f40-4cd5-e90f-7251a4127ea2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Contrastivity:  0.7479097046940704\n"]}]},{"cell_type":"code","source":["def spr_subgraph_saliency(masked_data_class0, masked_data_class1):\n","    binary_scores_class0 = []\n","    binary_scores_class1 = []\n","    for graph0, graph1 in zip(masked_data_class0, masked_data_class1):\n","        binary_score_class0 = []\n","        binary_score_class1 = []\n","        for node0, node1 in zip(graph0.x, graph1.x):\n","            if sum(node0) == 0:\n","                binary_score_class0.append(1)\n","            else:\n","                binary_score_class0.append(0)\n","            if sum(node1) == 0:\n","                binary_score_class1.append(1)\n","            else:\n","                binary_score_class1.append(0)\n","        binary_scores_class0.append(binary_score_class0)\n","        binary_scores_class1.append(binary_score_class1)\n","\n","    return binary_scores_class0, binary_scores_class1\n","\n","def compute_sparsity(masked_data_class0, masked_data_class1):\n","    binary_scores_class0, binary_scores_class1 = spr_subgraph_saliency(masked_data_class0, masked_data_class1)\n","\n","    sparsity_list = []\n","    for cor_binary_score, incor_binary_score in zip(binary_scores_class0, binary_scores_class1):\n","        sparsity = 1 - ((sum(cor_binary_score) + sum(incor_binary_score))/(2*len(incor_binary_score)))\n","        sparsity_list.append(sparsity)\n","\n","    return statistics.mean(sparsity_list)\n","\n","\n","\n","spr = compute_sparsity(test_dataset_dropped_correct, test_dataset_dropped_incorrect)\n","print(\"Sparsity: \", spr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L8_vZX7SrZCW","executionInfo":{"status":"ok","timestamp":1691345649399,"user_tz":-120,"elapsed":331,"user":{"displayName":"Ehsan Mobaraki","userId":"06314958514195310048"}},"outputId":"7e11ae31-9bd2-4104-ca80-f90084fb6e3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sparsity:  0.5637965676345319\n"]}]},{"cell_type":"code","source":["task_dict = {\"Graph Classification\": \"GC\", \"Node Classification\": \"NC\"}\n","l = [Explainability_name, task_dict[str(Task_name)], \"MUTAG\", \"GCN+GAP\", Auc_Roc, Auc_Prc, GNN_Model_training_Acc_per_epoch[-1], Acc, Acc2, fid, crs, spr, statistics.mean(time_consumption), statistics.mean(GNN_Model_training_time_per_epoch), samples_time]"],"metadata":{"id":"wiw5yj-dGfKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["task_dict = {\"Graph Classification\": \"GC\", \"Node Classification\": \"NC\"}\n","with open(\"/content/drive/My Drive/Explainability Methods/Evaluation of Explicability Methods/Experimental Results/Comparisons_ExMethods_Final_Format.csv\", 'a') as outcsv:\n","    wr = csv.writer(outcsv, dialect='excel', delimiter=',')\n","    wr.writerow(l)"],"metadata":{"id":"OiXBZExMI2si"},"execution_count":null,"outputs":[]}]}