# -*- coding: utf-8 -*-
"""SubGraphX on Graph Classification Final Format.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tKIl731CP0RVFUGDkRWBU5kgm3rujLqK

## ***SubgraphX***


> Moduled: Accpeting the four GNNs (GCN+GAP, DGCNN, DIFFPOOL, and GIN)


---
"""


import argparse
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import numpy as np
from math import sqrt
import math
from statistics import mean
from torch_geometric.datasets import TUDataset
import torch as th
import torch
import torch.nn as nn
from torch import Tensor
from torch.nn.parameter import Parameter
from torch_geometric.nn import GCNConv
import torch.nn.functional as F
from torch.nn import Linear, LayerNorm
from sklearn import metrics
from scipy.spatial.distance import hamming
import statistics
import pandas
from time import perf_counter
from IPython.core.display import deepcopy
from torch_geometric.nn import MessagePassing
import copy
from torch.nn import ReLU, Sequential
from torch import sigmoid
from itertools import chain
from time import perf_counter
from torch_geometric.data import Data, Batch, Dataset
from functools import partial
from torch_geometric.utils import to_networkx
from torch_geometric.utils import remove_self_loops
from typing import Callable, Union, Optional
#from torch_geometric.utils.num_nodes import maybe_num_nodes
import networkx as nx
from typing import List, Tuple, Dict
from collections import Counter
import statistics
import csv
from torch_geometric.nn import GCNConv, global_mean_pool
from torch_geometric.loader import DataLoader
import torch_geometric.nn as gnn



class MarginalSubgraphDataset(object):
    def __init__(self, data, exclude_mask, include_mask):
        self.num_nodes = data.num_nodes
        self.X = data.x
        self.edge_index = data.edge_index
        self.label = data.y

        self.exclude_mask = torch.tensor(exclude_mask).type(torch.float32)
        self.include_mask = torch.tensor(include_mask).type(torch.float32)

    def __len__(self):
        return self.exclude_mask.shape[0]

    def agraph_build_zero_filling(self, X, edge_index, node_mask):
        ret_X = X * node_mask.unsqueeze(1)
        return ret_X, edge_index

    def __getitem__(self, idx):
        exclude_graph_X, exclude_graph_edge_index = self.agraph_build_zero_filling(self.X, self.edge_index, self.exclude_mask[idx])
        include_graph_X, include_graph_edge_index = self.agraph_build_zero_filling(self.X, self.edge_index, self.include_mask[idx])

        exclude_data = Data(x=exclude_graph_X, edge_index=exclude_graph_edge_index)
        include_data = Data(x=include_graph_X, edge_index=include_graph_edge_index)
        return exclude_data, include_data

class MCTS_Node_Attributes(object):
    def __init__(self, coalition, data, ori_graph, ubc1_c_coef, W, N, P, load_dict):
        self.data = data
        self.coalition = coalition
        self.ori_graph = ori_graph

        self.ubc1_c_coef = ubc1_c_coef
        self.children = []
        self.W = W  # sum of node value
        self.N = N  # times of arrival
        self.P = P  # property score (reward)
        if load_dict is not None:
            self.load_info(load_dict)

    def Q(self):
        return self.W / self.N if self.N > 0 else 0

    def U(self, n):
        return self.ubc1_c_coef * self.P * math.sqrt(n) / (1 + self.N)

    @property
    def info(self):
        info_dict = {
            'data': self.data.to('cpu'),
            'coalition': self.coalition,
            'ori_graph': self.ori_graph,
            'W': self.W,
            'N': self.N,
            'P': self.P
        }
        return info_dict

    def load_info(self, info_dict):
        self.W = info_dict['W']
        self.N = info_dict['N']
        self.P = info_dict['P']
        self.coalition = info_dict['coalition']
        self.ori_graph = info_dict['ori_graph']
        self.data = info_dict['data']
        self.children = []
        return self

class Mone_Carlo_Tree_Search(object):

    def __init__(self, X, edge_index, num_hops, n_rollout, min_children_threshold, ubc1_c_coef, expand_count_threshold,
                 high2low, score_func):
        self.X = X
        self.edge_index = edge_index

        self.num_hops = num_hops
        self.data = Data(x=self.X, edge_index=self.edge_index)
        graph_data = Data(x=self.X, edge_index=remove_self_loops(self.edge_index)[0])
        self.graph = to_networkx(graph_data, to_undirected=True)
        self.data = Batch.from_data_list([self.data])
        self.num_nodes = self.graph.number_of_nodes()
        self.score_func = score_func
        self.n_rollout = n_rollout
        self.min_children_threshold = min_children_threshold
        self.ubc1_c_coef = ubc1_c_coef
        self.expand_count_threshold = expand_count_threshold
        self.high2low = high2low
        self.new_node_idx = None

        self.root_coalition = sorted([node for node in range(self.num_nodes)])
        self.MCTSNodeClass = partial(MCTS_Node_Attributes, data=self.data, ori_graph=self.graph, ubc1_c_coef=self.ubc1_c_coef, W=0, N=0, P=0, load_dict=None)
        self.root = self.MCTSNodeClass(self.root_coalition)
        self.state_map = {str(self.root.coalition): self.root}

    def set_score_func(self, score_func):
        self.score_func = score_func

    def k_hop_subgraph_with_default_whole_graph(self, edge_index, node_idx, num_hops, relabel_nodes, num_nodes, flow):

        num_nodes = maybe_num_nodes(edge_index, num_nodes)

        assert flow in ['source_to_target', 'target_to_source']
        if flow == 'target_to_source':
            row, col = edge_index
        else:
            col, row = edge_index  # edge_index 0 to 1, col: source, row: target

        node_mask = row.new_empty(num_nodes, dtype=torch.bool)
        edge_mask = row.new_empty(row.size(0), dtype=torch.bool)

        inv = None

        if node_idx is None:
            subsets = torch.tensor([0])
            cur_subsets = subsets
            while 1:
                node_mask.fill_(False)
                node_mask[subsets] = True
                torch.index_select(node_mask, 0, row, out=edge_mask)
                subsets = torch.cat([subsets, col[edge_mask]]).unique()
                if not cur_subsets.equal(subsets):
                    cur_subsets = subsets
                else:
                    subset = subsets
                    break
        else:
            if isinstance(node_idx, (int, list, tuple)):
                node_idx = torch.tensor([node_idx], device=row.device, dtype=torch.int64).flatten()
            elif isinstance(node_idx, torch.Tensor) and len(node_idx.shape) == 0:
                node_idx = torch.tensor([node_idx])
            else:
                node_idx = node_idx.to(row.device)

            subsets = [node_idx]
            for _ in range(num_hops):
                node_mask.fill_(False)
                node_mask[subsets[-1]] = True
                torch.index_select(node_mask, 0, row, out=edge_mask)
                subsets.append(col[edge_mask])
            subset, inv = torch.cat(subsets).unique(return_inverse=True)
            inv = inv[:node_idx.numel()]

        node_mask.fill_(False)
        node_mask[subset] = True
        edge_mask = node_mask[row] & node_mask[col]

        edge_index = edge_index[:, edge_mask]

        if relabel_nodes:
            node_idx = row.new_full((num_nodes,), -1)
            node_idx[subset] = torch.arange(subset.size(0), device=row.device)
            edge_index = node_idx[edge_index]

        return subset, edge_index, inv, edge_mask

    def compute_scores(self, score_func, children):
        results = []
        for child in children:
            if child.P == 0:
                score = score_func(child.coalition, child.data)
            else:
                score = child.P
            results.append(score)
        return results

    def mcts_rollout(self, tree_node):
        cur_graph_coalition = tree_node.coalition

        if len(cur_graph_coalition) <= self.min_children_threshold:    #            it's considered as a leaf
            return tree_node.P


        if len(tree_node.children) == 0:
            node_degree_list = list(self.graph.subgraph(cur_graph_coalition).degree)
            node_degree_list = sorted(node_degree_list, key=lambda x: x[1], reverse=self.high2low)
            all_nodes = [x[0] for x in node_degree_list]

            if self.new_node_idx:
                expand_nodes = [node for node in all_nodes if node != self.new_node_idx]
            else:
                expand_nodes = all_nodes

            if len(all_nodes) > self.expand_count_threshold:
                expand_nodes = expand_nodes[:self.expand_count_threshold]


            for each_node in expand_nodes:
                subgraph_coalition = [node for node in all_nodes if node != each_node]

                subgraphs = [self.graph.subgraph(c) for c in nx.connected_components(self.graph.subgraph(subgraph_coalition))]

                if self.new_node_idx:
                    for sub in subgraphs:
                        if self.new_node_idx in list(sub.nodes()):
                            main_sub = sub
                else:
                    main_sub = subgraphs[0]

                    for sub in subgraphs:
                        if sub.number_of_nodes() > main_sub.number_of_nodes():
                            main_sub = sub

                new_graph_coalition = sorted(list(main_sub.nodes()))


                find_same = False
                for old_graph_node in self.state_map.values():
                    if Counter(old_graph_node.coalition) == Counter(new_graph_coalition):
                        new_node = old_graph_node
                        find_same = True

                if not find_same:
                    new_node = self.MCTSNodeClass(new_graph_coalition)
                    self.state_map[str(new_graph_coalition)] = new_node

                find_same_child = False
                for cur_child in tree_node.children:
                    if Counter(cur_child.coalition) == Counter(new_graph_coalition):
                        find_same_child = True

                if not find_same_child:
                    tree_node.children.append(new_node)

            scores = self.compute_scores(self.score_func, tree_node.children)
            for child, score in zip(tree_node.children, scores):
                child.P = score

        sum_count = sum([c.N for c in tree_node.children])
        selected_node = max(tree_node.children, key=lambda x: x.Q() + x.U(sum_count))
        v = self.mcts_rollout(selected_node)
        selected_node.W += v
        selected_node.N += 1
        return v

    def mcts(self):
        print(f"The number of nodes in the graph is {self.graph.number_of_nodes()}")
        for rollout_idx in range(self.n_rollout):
            self.mcts_rollout(self.root)
            print(f"At the {rollout_idx} rollout, {len(self.state_map)} states that have been explored.")

        explanations = [node for _, node in self.state_map.items()]
        explanations = sorted(explanations, key=lambda x: x.P, reverse=True)
        return explanations

class SubGraphX(object):
    def __init__(self, GNN_Model, num_classes, num_hops, explain_graph, rollout_count, min_children_threshold,
                 ubc1_c_coef, expand_count_threshold, high2low, sample_num, save_permission_explanations, dataset_name):
        self.Model_Name = GNN_Model.__class__.__name__
        self.GNN_Model = GNN_Model
        self.GNN_Model.eval()
        self.Task_name = "Graph Classification"
        self.dataset_name = dataset_name

        self.num_classes = num_classes
        self.num_hops = self.update_num_hops(num_hops)
        self.explain_graph = explain_graph
        self.save_permission_explanations = save_permission_explanations

        # mcts hyper-parameters
        self.rollout_count = rollout_count
        self.min_children_threshold = min_children_threshold
        self.ubc1_c_coef = ubc1_c_coef
        self.expand_count_threshold = expand_count_threshold
        self.high2low = high2low

        # reward function hyper-parameters
        self.sample_num = sample_num
        self.reward_method = "mc_shapley"
        self.subgraph_building_method = "zero_filling"




    def update_num_hops(self, num_hops):
        if num_hops is not None:
            return num_hops
        k = 0
        for module in self.GNN_Model.modules():
            if isinstance(module, MessagePassing):
                k += 1
        return k

    def graph_build_zero_filling(self, X, edge_index, node_mask):
        ret_X = X * node_mask.unsqueeze(1)
        return ret_X, edge_index

    def get_graph_build_func(self, build_method):
        if build_method == 'zero_filling':
            return self.graph_build_zero_filling
        else:
            print("fail")
    def marginal_contribution(self, data, exclude_mask, include_mask, value_func, subgraph_build_func):
        marginal_subgraph_dataset = MarginalSubgraphDataset(data, exclude_mask, include_mask)

        dataloader = DataLoader(marginal_subgraph_dataset, batch_size=256, shuffle=False, num_workers=0)
        marginal_contribution_list = []

        if self.GNN_Model.__class__.__name__ == "GCN_plus_GAP_Model":
            for exclude_data, include_data in dataloader:
                Output_of_Hidden_Layers, pooling_layer_output, ffn_output, exclude_values = value_func(exclude_data)
                Output_of_Hidden_Layers, pooling_layer_output, ffn_output, include_values = value_func(include_data)
                margin_values = include_values - exclude_values
                marginal_contribution_list.append(margin_values)

        elif self.GNN_Model.__class__.__name__ == "DGCNN_Model":
            for exclude_data, include_data in dataloader:
                final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, exclude_values = value_func(exclude_data)
                final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, include_values = value_func(include_data)
                margin_values = include_values - exclude_values
                marginal_contribution_list.append(margin_values)

        elif self.GNN_Model.__class__.__name__ == "DIFFPOOL_Model":
            for exclude_data, include_data in dataloader:
                concatination_list_of_poolings, prediction_output_without_soft, exclude_values = value_func(exclude_data)
                concatination_list_of_poolings, prediction_output_without_soft, include_values = value_func(include_data)
                margin_values = include_values - exclude_values
                marginal_contribution_list.append(margin_values)

        elif self.GNN_Model.__class__.__name__ == "GIN_Model":
            for exclude_data, include_data in dataloader:
                mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, exclude_values = value_func(exclude_data)
                mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, include_values = value_func(include_data)
                margin_values = include_values - exclude_values
                marginal_contribution_list.append(margin_values)

        marginal_contributions = torch.cat(marginal_contribution_list, dim=0)
        return marginal_contributions

    def mc_shapley(self, coalition, data, value_func, subgraph_building_method, sample_num, class_index):

        subset_build_func = self.get_graph_build_func(subgraph_building_method)

        num_nodes = data.num_nodes
        node_indices = np.arange(num_nodes)
        coalition_placeholder = num_nodes
        set_exclude_masks = []
        set_include_masks = []

        for example_idx in range(sample_num):
            subset_nodes_from = [node for node in node_indices if node not in coalition]
            random_nodes_permutation = np.array(subset_nodes_from + [coalition_placeholder])
            random_nodes_permutation = np.random.permutation(random_nodes_permutation)
            split_idx = np.where(random_nodes_permutation == coalition_placeholder)[0][0]
            selected_nodes = random_nodes_permutation[:split_idx]
            set_exclude_mask = np.zeros(num_nodes)
            set_exclude_mask[selected_nodes] = 1.0
            set_include_mask = set_exclude_mask.copy()
            set_include_mask[coalition] = 1.0

            set_exclude_masks.append(set_exclude_mask)
            set_include_masks.append(set_include_mask)

        exclude_mask = np.stack(set_exclude_masks, axis=0)
        include_mask = np.stack(set_include_masks, axis=0)
        marginal_contributions = self.marginal_contribution(data, exclude_mask, include_mask, value_func, subset_build_func)[:, class_index]
        mc_shapley_value = marginal_contributions.mean().item()

        return mc_shapley_value

    def get_reward_func(self, value_func, class_index, node_idx=None):
        if self.explain_graph:
            node_idx = None
        else:
            assert node_idx is not None
        return partial(self.mc_shapley, value_func=value_func, subgraph_building_method=self.subgraph_building_method,
                       sample_num=self.sample_num, class_index=class_index)

    def GnnNetsGC2valueFunc(self, gnnNets):
        def value_func(batch):

            if self.GNN_Model.__class__.__name__ == "GCN_plus_GAP_Model":
                gnnNets.eval()
                Output_of_Hidden_Layers, pooling_layer_output, ffn_output, score = gnnNets(batch, None)
                return Output_of_Hidden_Layers, pooling_layer_output, ffn_output, score

            elif self.GNN_Model.__class__.__name__ == "DGCNN_Model":
                gnnNets.eval()
                final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, score = gnnNets(batch, None)
                return final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, score

            elif self.GNN_Model.__class__.__name__ == "DIFFPOOL_Model":
                gnnNets.eval()
                concatination_list_of_poolings, prediction_output_without_soft, score = gnnNets(batch, None)
                return concatination_list_of_poolings, prediction_output_without_soft, score

            elif self.GNN_Model.__class__.__name__ == "GIN_Model":
                gnnNets.eval()
                mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, score = gnnNets(batch, None)
                return mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, score

        return value_func

    def read_from_MCTSInfo_list(self, MCTSInfo_list):
        if isinstance(MCTSInfo_list[0], dict):
            ret_list = [MCTS_Node_Attributes(device=self.device).load_info(node_info) for node_info in MCTSInfo_list]
        elif isinstance(MCTSInfo_list[0][0], dict):
            ret_list = []
            for single_label_MCTSInfo_list in MCTSInfo_list:
                single_label_ret_list = [MCTS_Node_Attributes(device=self.device).load_info(node_info) for node_info in single_label_MCTSInfo_list]
                ret_list.append(single_label_ret_list)
        return ret_list

    def write_from_MCTSNode_list(self, MCTSNode_list):
        if isinstance(MCTSNode_list[0], MCTS_Node_Attributes):
            ret_list = [node.info for node in MCTSNode_list]
        elif isinstance(MCTSNode_list[0][0], MCTS_Node_Attributes):
            ret_list = []
            for single_label_MCTSNode_list in MCTSNode_list:
                single_label_ret_list = [node.info for node in single_label_MCTSNode_list]
                ret_list.append(single_label_ret_list)
        return ret_list

    def find_closest_node_result(self, results, max_nodes):
        results = sorted(results, key=lambda x: len(x.coalition))
        result_node = results[0]
        for result_idx in range(len(results)):
            x = results[result_idx]
            if len(x.coalition) <= max_nodes and x.P > result_node.P:
                result_node = x
        return result_node

    def gnn_score(self, coalition, data, value_func, subgraph_building_method):
        num_nodes = data.num_nodes
        subgraph_build_func = self.get_graph_build_func(subgraph_building_method)
        mask = torch.zeros(num_nodes).type(torch.float32).to(data.x.device)
        mask[coalition] = 1.0
        ret_x, ret_edge_index = subgraph_build_func(data.x, data.edge_index, mask)
        mask_data = Data(x=ret_x, edge_index=ret_edge_index)
        mask_data_b = Batch.from_data_list([mask_data])

        if self.GNN_Model.__class__.__name__ == "GCN_plus_GAP_Model":
            Output_of_Hidden_Layers, pooling_layer_output, ffn_output, score = value_func(mask_data_b)

        elif self.GNN_Model.__class__.__name__ == "DGCNN_Model":
            final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, score = value_func(mask_data_b)

        elif self.GNN_Model.__class__.__name__ == "DIFFPOOL_Model":
            concatination_list_of_poolings, prediction_output_without_soft, score = value_func(mask_data_b)

        elif self.GNN_Model.__class__.__name__ == "GIN_Model":
            mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, score = value_func(mask_data_b)

        return score, mask_data_b

    def explain(self, graph, max_nodes, class_index, saved_MCTSInfo_list):

        if self.GNN_Model.__class__.__name__ == "GCN_plus_GAP_Model":
            Output_of_Hidden_Layers, pooling_layer_output, ffn_output, probs = self.GNN_Model(graph, None)

        elif self.GNN_Model.__class__.__name__ == "DGCNN_Model":
            final_GNN_layer_output, sortpooled_embedings, output_conv1d_1, maxpooled_output_conv1d_1, output_conv1d_2, to_dense, output_h1, dropout_output_h1, output_h2, probs = self.GNN_Model(graph, None)

        elif self.GNN_Model.__class__.__name__ == "DIFFPOOL_Model":
            concatination_list_of_poolings, prediction_output_without_soft, probs = self.GNN_Model(graph, None)

        elif self.GNN_Model.__class__.__name__ == "GIN_Model":
            mlps_output_embeds, mlp_outputs_globalSUMpooled, lin1_output, lin1_output_dropouted, lin2_output, probs = self.GNN_Model(graph, None)

        if self.explain_graph:
            if saved_MCTSInfo_list:
                results = self.read_from_MCTSInfo_list(saved_MCTSInfo_list)

            if not saved_MCTSInfo_list:
                value_func = self.GnnNetsGC2valueFunc(self.GNN_Model) # MODEL as output
                score_func = self.get_reward_func(value_func, class_index)        # Shapley value
                self.mcts_state_map = Mone_Carlo_Tree_Search(graph.x, graph.edge_index, score_func=score_func,
                                                             num_hops=self.num_hops, n_rollout=self.rollout_count,
                                                             ubc1_c_coef=self.ubc1_c_coef,
                                                             min_children_threshold=self.min_children_threshold,
                                                             expand_count_threshold=self.expand_count_threshold,
                                                             high2low=self.high2low)

                results = self.mcts_state_map.mcts()


            value_func = self.GnnNetsGC2valueFunc(self.GNN_Model)
            tree_node_x = self.find_closest_node_result(results, max_nodes=max_nodes)
        else:
            print("Node Classification")

        masked_node_list = [node for node in range(tree_node_x.data.x.shape[0])
                            if node in tree_node_x.coalition]
        maskout_node_list = [node for node in range(tree_node_x.data.x.shape[0])
                             if node not in tree_node_x.coalition]


        masked_score, mask_data_b = self.gnn_score(masked_node_list, tree_node_x.data, value_func=value_func, subgraph_building_method=self.subgraph_building_method)

        maskout_score, maskout_data_b = self.gnn_score(maskout_node_list, tree_node_x.data, value_func=value_func, subgraph_building_method=self.subgraph_building_method)

        results = self.write_from_MCTSNode_list(results)
        related_pred = {'masked': masked_score,
                        'maskout': maskout_score,
                        'origin': probs[0, graph.y].item()
                        }

        return results, related_pred, mask_data_b, maskout_data_b, masked_score, maskout_score

    def __call__(self, graph, graph_index):
        t1 = perf_counter
        max_nodes = 5

        labels = tuple(label for label in range(self.num_classes))
        ex_labels = tuple(torch.tensor([label]) for label in labels)
        print("labels: ", labels, "ex_labels: ", ex_labels)

        related_preds = []
        time_list = []
        explanation_results = {}
        for i in range(self.num_classes):
            explanation_results[i] = []


        for category, label in enumerate(ex_labels):
            t1 = perf_counter()
            results, related_pred, mask_data_b, maskout_data_b, masked_pred, maskout_pred = self.explain(graph, max_nodes=max_nodes,
                                                                                                         class_index=category,
                                                                                                         saved_MCTSInfo_list=None)
            related_preds.append(related_pred)

            taken_time = perf_counter() - t1

            mask_tensor = torch.zeros(graph.x.size()[0], dtype=torch.int)
            indices_to_set = results[0]['coalition']
            indices_tensor = torch.tensor(indices_to_set, dtype=torch.long)
            mask_tensor[indices_tensor] = 1
            explanation_results[category].append(mask_tensor)

            # if self.save_permission_explanations:
            #     torch.save({"graph_index": graph_index, "category": category, "mask_data": mask_data_b,
            #                 "maskout_data": maskout_data_b, "masked_pred": masked_pred, "maskout_pred": maskout_pred,
            #                 "input_graph": graph, "sample_specific_Explanation_time": taken_time,
            #                 "explanation_results": mask_tensor, "num_hops": self.num_hops,
            #                 "rollout_count": self.rollout_count, "min_children_threshold": self.min_children_threshold,
            #                 "ubc1_c_coef": self.ubc1_c_coef, "expand_count_threshold": self.expand_count_threshold,
            #                 "high2low": self.high2low, "sample_num": self.sample_num},
            #                os.path.join("SubGraphX" + " on " + str(self.Task_name) + "/Model/temp/",
            #                             "SubGraphX_Explainer_" + self.Model_Name + "_graph_important_for_class_" + str(category) + "_" + str(self.dataset_name) + "_{:d}.pt".format(graph_index + 1)))
            if self.save_permission_explanations:
                torch.save({"graph_index": graph_index, "category": category, "input_graph": graph,
                            "sample_specific_Explanation_time": taken_time, "explanation_results": mask_tensor},
                           os.path.join("/data/cs.aau.dk/ey33jw/SubGraphX_Explanations/" + str(self.Model_Name) + "/",
                                        "SubGraphX_Explainer_" + self.Model_Name + "_graph_important_for_class_" +
                                        str(category) + "_" +
                                        str(self.dataset_name) + "_{:d}.pt".format(graph_index + 1)))

            time_list.append(taken_time)

        return explanation_results, graph_index, graph

#SubGX = SubGraphX(GNN_Model=GNN_Model, num_classes=3, num_hops=2, explain_graph=True, rollout_count=20, min_children_threshold=5,
#                  ubc1_c_coef= 10.0, expand_count_threshold=5, high2low=True, sample_num=100, save_permission_explanations= True)

#graph_index = 0
#explanation_results, related_preds, time = SubGX(graph=dataset[graph_index], graph_index=graph_index)
#print(explanation_results)
#for i, graph in enumerate(fake_test_dataloader):
#    explanation_results, related_preds, time_list = SubGX(graph=graph, graph_index=i)

#print(statistics.mean(time_list))
#attribution_time = statistics.mean(time_list)












class SubGraphX_off_the_fly(object):
    def __init__(self, test_dataset, num_classes, Task_name, dataset_name, Model_Name):
        self.test_dataset = test_dataset
        self.Explainability_name = "SubGraphX"
        self.Task_name = Task_name
        self.num_classes = num_classes
        self.dataset_name = dataset_name
        self.Model_Name = Model_Name

    def reconfig_data(self, your_dataset, Explainability_name, Task_name):
        whole_data = {}
        for i, graph in enumerate(your_dataset):
            whole_data[i] = {}
            for cls in range(self.num_classes):
                explanation_results, graph_index, graph = self.load_data(Explainability_name, Task_name, i, cls)
                whole_data[i][cls] = {}
                whole_data[i][cls]["explanation_results"] = explanation_results
                whole_data[i][cls]["graph_index"] = graph_index
                whole_data[i][cls]["input_graph"] = graph
        return whole_data

    def load_data(self, Explainability_name, Task_name, loading_graph_index, class_index):
        checkpoint = torch.load(str(Explainability_name) + " on " + str(Task_name) + "/Model/temp/SubGraphX_Explainer_" +
                                self.Model_Name + "_graph_important_for_class_" + str(class_index) + "_" +
                                str(self.dataset_name) + "_{:d}.pt".format(loading_graph_index + 1))
        explanation_results = checkpoint['explanation_results']
        graph_index = checkpoint["graph_index"]
        graph = checkpoint["input_graph"]
        return explanation_results, graph_index, graph

    def __call__(self, test_dataset):
        whole_data = self.reconfig_data(test_dataset, self.Explainability_name, self.Task_name)
        return whole_data






